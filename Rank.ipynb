{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9bc3441",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa116d3b-51ac-42de-bf7a-fb55eb148689",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import time\n",
    "from graphviz import *\n",
    "import lightgbm as lgb\n",
    "from hyperopt import hp, tpe, Trials, fmin,STATUS_OK\n",
    "import fasttext as ft\n",
    "# import importlib\n",
    "# importlib.reload(hoge)\n",
    "from my_library.horse import *\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1782806f-f29f-40fe-9c06-7dfca7dd2339",
   "metadata": {},
   "source": [
    "# path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a4008e3-1c76-4f8e-b375-0f3533379d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ubu = '/home/hipro/デスクトップ/Horse/Data/20_21'\n",
    "path_win2 = '/Users/rince/Desktop/Horse/Data/saishin2/'\n",
    "path_win = '/Users/rince/Desktop/Horse/Data/saishin/'\n",
    "path_win = '/Users/Owner/Desktop/program/Horse/Data/saishin/'\n",
    "path_win2 = '/Users/Owner/Desktop/program/Horse/Data/saishin2/'\n",
    "path_ft = '/Users/Owner/Desktop/Horse/ft_data/peds_ft.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a920e716-5257-45d8-9831-2effe586aa2c",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cafb76f-29dc-4841-bb1b-2792c246cd20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = load_csv(path_win+'results.csv')\n",
    "horse_results = load_csv(path_win+'horse_results.csv')\n",
    "peds = load_csv(path_win+'peds.csv')\n",
    "# 何回やってもロードすると, nanが出る\n",
    "peds.fillna('nan',inplace=True)\n",
    "return_tables = load_csv(path_win+'return.csv')\n",
    "return_tables.rename(columns={'0':0,'1':1,'2':2,'3':3},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897b3ed-08f1-452f-bc5c-840f04015aed",
   "metadata": {},
   "source": [
    "# race_id 命名規則"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f840d19f-0d83-4c24-a9d6-245b20e6eac6",
   "metadata": {},
   "source": [
    "race_id 202105040802\\\n",
    "yyyy_pp_xx_xxrr\\\n",
    "y : year\\\n",
    "p : palce\\\n",
    "x : 謎\\\n",
    "r : race番号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c895357f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cdd9e7bf4f4429f8c24591aeedd66b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17dac04fb08c43dd9aa9e3c583f2dfbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pe finish\n",
      "pe regularizrd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1183f04bd57b4df1856abd81f281bc83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c14ee8c9f74651b846eb16fede7b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da72e218ac2489bb18dc865c5ed6e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 47243\n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n"
     ]
    }
   ],
   "source": [
    "ll = LearnLGBM(peds,results,horse_results)\n",
    "ll.path_ft = '/Users/Owner/Desktop/Horse/horse/peds_ft.txt'\n",
    "ll.learn_lgb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27efe69c",
   "metadata": {},
   "source": [
    "# grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32108465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start:                                       \n",
      "  0%|          | 0/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "\n",
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "  0%|          | 0/25 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "\n",
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalid's ndcg@1: 0.540571\tvalid's ndcg@2: 0.52705\tvalid's ndcg@3: 0.517194\n",
      "[10]\tvalid's ndcg@1: 0.535429\tvalid's ndcg@2: 0.524805\tvalid's ndcg@3: 0.515757\n",
      "[15]\tvalid's ndcg@1: 0.542286\tvalid's ndcg@2: 0.526135\tvalid's ndcg@3: 0.517458\n",
      "[20]\tvalid's ndcg@1: 0.537143\tvalid's ndcg@2: 0.524808\tvalid's ndcg@3: 0.517306\n",
      "Early stopping, best iteration is:                    \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536289\tvalid's ndcg@3: 0.522442\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.534857\tvalid's ndcg@2: 0.521557\tvalid's ndcg@3: 0.510685   \n",
      "[10]\tvalid's ndcg@1: 0.543429\tvalid's ndcg@2: 0.53021\tvalid's ndcg@3: 0.519279   \n",
      "[15]\tvalid's ndcg@1: 0.545714\tvalid's ndcg@2: 0.529703\tvalid's ndcg@3: 0.520104  \n",
      "[20]\tvalid's ndcg@1: 0.536\tvalid's ndcg@2: 0.531845\tvalid's ndcg@3: 0.518298     \n",
      "Early stopping, best iteration is:                                               \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536289\tvalid's ndcg@3: 0.522442\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.542286\tvalid's ndcg@2: 0.530172\tvalid's ndcg@3: 0.517032   \n",
      "[10]\tvalid's ndcg@1: 0.533143\tvalid's ndcg@2: 0.521832\tvalid's ndcg@3: 0.5125    \n",
      "[15]\tvalid's ndcg@1: 0.529714\tvalid's ndcg@2: 0.52208\tvalid's ndcg@3: 0.512087   \n",
      "[20]\tvalid's ndcg@1: 0.536571\tvalid's ndcg@2: 0.525645\tvalid's ndcg@3: 0.51417   \n",
      "Early stopping, best iteration is:                                               \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536289\tvalid's ndcg@3: 0.522442\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.544571\tvalid's ndcg@2: 0.529887\tvalid's ndcg@3: 0.517763   \n",
      "[10]\tvalid's ndcg@1: 0.537714\tvalid's ndcg@2: 0.528114\tvalid's ndcg@3: 0.520538  \n",
      "[15]\tvalid's ndcg@1: 0.534857\tvalid's ndcg@2: 0.526886\tvalid's ndcg@3: 0.519291  \n",
      "[20]\tvalid's ndcg@1: 0.537714\tvalid's ndcg@2: 0.526788\tvalid's ndcg@3: 0.519943  \n",
      "Early stopping, best iteration is:                                               \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536289\tvalid's ndcg@3: 0.522442\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.546857\tvalid's ndcg@2: 0.526704\tvalid's ndcg@3: 0.517022   \n",
      "[10]\tvalid's ndcg@1: 0.541714\tvalid's ndcg@2: 0.526006\tvalid's ndcg@3: 0.516762  \n",
      "[15]\tvalid's ndcg@1: 0.537143\tvalid's ndcg@2: 0.527519\tvalid's ndcg@3: 0.519309  \n",
      "[20]\tvalid's ndcg@1: 0.534857\tvalid's ndcg@2: 0.52507\tvalid's ndcg@3: 0.515733   \n",
      "Early stopping, best iteration is:                                               \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536289\tvalid's ndcg@3: 0.522442\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.536\tvalid's ndcg@2: 0.52441\tvalid's ndcg@3: 0.513831       \n",
      "[10]\tvalid's ndcg@1: 0.542286\tvalid's ndcg@2: 0.523285\tvalid's ndcg@3: 0.513573  \n",
      "[15]\tvalid's ndcg@1: 0.529143\tvalid's ndcg@2: 0.523906\tvalid's ndcg@3: 0.515801  \n",
      "[20]\tvalid's ndcg@1: 0.526857\tvalid's ndcg@2: 0.52497\tvalid's ndcg@3: 0.51882    \n",
      "Early stopping, best iteration is:                                               \n",
      "[1]\tvalid's ndcg@1: 0.554857\tvalid's ndcg@2: 0.533901\tvalid's ndcg@3: 0.520605\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.536\tvalid's ndcg@2: 0.522421\tvalid's ndcg@3: 0.51351       \n",
      "[10]\tvalid's ndcg@1: 0.538857\tvalid's ndcg@2: 0.521683\tvalid's ndcg@3: 0.512119  \n",
      "[15]\tvalid's ndcg@1: 0.522286\tvalid's ndcg@2: 0.519922\tvalid's ndcg@3: 0.51339   \n",
      "[20]\tvalid's ndcg@1: 0.539429\tvalid's ndcg@2: 0.524081\tvalid's ndcg@3: 0.51717   \n",
      "Early stopping, best iteration is:                                               \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536289\tvalid's ndcg@3: 0.522442\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.542857\tvalid's ndcg@2: 0.530557\tvalid's ndcg@3: 0.519407   \n",
      "[10]\tvalid's ndcg@1: 0.538286\tvalid's ndcg@2: 0.526067\tvalid's ndcg@3: 0.514072  \n",
      "[15]\tvalid's ndcg@1: 0.538286\tvalid's ndcg@2: 0.524764\tvalid's ndcg@3: 0.514428  \n",
      "[20]\tvalid's ndcg@1: 0.536\tvalid's ndcg@2: 0.524329\tvalid's ndcg@3: 0.513815     \n",
      "Early stopping, best iteration is:                                               \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.534741\tvalid's ndcg@3: 0.521694\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.534857\tvalid's ndcg@2: 0.52927\tvalid's ndcg@3: 0.515126    \n",
      "[10]\tvalid's ndcg@1: 0.534286\tvalid's ndcg@2: 0.528059\tvalid's ndcg@3: 0.512488  \n",
      "[15]\tvalid's ndcg@1: 0.534286\tvalid's ndcg@2: 0.523499\tvalid's ndcg@3: 0.514451  \n",
      "[20]\tvalid's ndcg@1: 0.531429\tvalid's ndcg@2: 0.522852\tvalid's ndcg@3: 0.513889  \n",
      "Early stopping, best iteration is:                                               \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536289\tvalid's ndcg@3: 0.522442\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.533714\tvalid's ndcg@2: 0.523288\tvalid's ndcg@3: 0.514282   \n",
      "[10]\tvalid's ndcg@1: 0.533714\tvalid's ndcg@2: 0.520135\tvalid's ndcg@3: 0.514204  \n",
      "[15]\tvalid's ndcg@1: 0.533714\tvalid's ndcg@2: 0.521601\tvalid's ndcg@3: 0.515993  \n",
      "[20]\tvalid's ndcg@1: 0.541714\tvalid's ndcg@2: 0.527751\tvalid's ndcg@3: 0.521067  \n",
      "Early stopping, best iteration is:                                               \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536289\tvalid's ndcg@3: 0.522442\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.548\tvalid's ndcg@2: 0.526684\tvalid's ndcg@3: 0.513126       \n",
      "[10]\tvalid's ndcg@1: 0.541714\tvalid's ndcg@2: 0.52468\tvalid's ndcg@3: 0.511458    \n",
      "[15]\tvalid's ndcg@1: 0.528571\tvalid's ndcg@2: 0.518111\tvalid's ndcg@3: 0.507449   \n",
      "[20]\tvalid's ndcg@1: 0.532\tvalid's ndcg@2: 0.519852\tvalid's ndcg@3: 0.509041      \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.562286\tvalid's ndcg@2: 0.542796\tvalid's ndcg@3: 0.521401\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.544571\tvalid's ndcg@2: 0.533179\tvalid's ndcg@3: 0.521346    \n",
      "[10]\tvalid's ndcg@1: 0.529143\tvalid's ndcg@2: 0.525208\tvalid's ndcg@3: 0.515979   \n",
      "[15]\tvalid's ndcg@1: 0.532571\tvalid's ndcg@2: 0.524634\tvalid's ndcg@3: 0.513479   \n",
      "[20]\tvalid's ndcg@1: 0.534857\tvalid's ndcg@2: 0.525594\tvalid's ndcg@3: 0.514327   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536289\tvalid's ndcg@3: 0.522442\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.528571\tvalid's ndcg@2: 0.522321\tvalid's ndcg@3: 0.51105     \n",
      "[10]\tvalid's ndcg@1: 0.535429\tvalid's ndcg@2: 0.522128\tvalid's ndcg@3: 0.513914   \n",
      "[15]\tvalid's ndcg@1: 0.534857\tvalid's ndcg@2: 0.526223\tvalid's ndcg@3: 0.517729   \n",
      "[20]\tvalid's ndcg@1: 0.531429\tvalid's ndcg@2: 0.525644\tvalid's ndcg@3: 0.516961   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536289\tvalid's ndcg@3: 0.522442\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.536571\tvalid's ndcg@2: 0.523574\tvalid's ndcg@3: 0.513326    \n",
      "[10]\tvalid's ndcg@1: 0.535429\tvalid's ndcg@2: 0.525723\tvalid's ndcg@3: 0.512846   \n",
      "[15]\tvalid's ndcg@1: 0.533143\tvalid's ndcg@2: 0.524787\tvalid's ndcg@3: 0.515877   \n",
      "[20]\tvalid's ndcg@1: 0.534857\tvalid's ndcg@2: 0.524733\tvalid's ndcg@3: 0.516159   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.555429\tvalid's ndcg@2: 0.534775\tvalid's ndcg@3: 0.520792\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.538286\tvalid's ndcg@2: 0.530512\tvalid's ndcg@3: 0.518409    \n",
      "[10]\tvalid's ndcg@1: 0.525714\tvalid's ndcg@2: 0.523385\tvalid's ndcg@3: 0.511407   \n",
      "[15]\tvalid's ndcg@1: 0.531429\tvalid's ndcg@2: 0.521002\tvalid's ndcg@3: 0.513124   \n",
      "[20]\tvalid's ndcg@1: 0.530857\tvalid's ndcg@2: 0.520652\tvalid's ndcg@3: 0.510221   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536289\tvalid's ndcg@3: 0.522442\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.539429\tvalid's ndcg@2: 0.527676\tvalid's ndcg@3: 0.516763    \n",
      "[10]\tvalid's ndcg@1: 0.537714\tvalid's ndcg@2: 0.524856\tvalid's ndcg@3: 0.514053   \n",
      "[15]\tvalid's ndcg@1: 0.533714\tvalid's ndcg@2: 0.522927\tvalid's ndcg@3: 0.51622    \n",
      "[20]\tvalid's ndcg@1: 0.545143\tvalid's ndcg@2: 0.530703\tvalid's ndcg@3: 0.519553   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536289\tvalid's ndcg@3: 0.522442\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.538286\tvalid's ndcg@2: 0.52189\tvalid's ndcg@3: 0.511055     \n",
      "[10]\tvalid's ndcg@1: 0.533714\tvalid's ndcg@2: 0.52359\tvalid's ndcg@3: 0.511408    \n",
      "[15]\tvalid's ndcg@1: 0.535429\tvalid's ndcg@2: 0.522454\tvalid's ndcg@3: 0.514553   \n",
      "[20]\tvalid's ndcg@1: 0.526286\tvalid's ndcg@2: 0.519222\tvalid's ndcg@3: 0.514261   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536289\tvalid's ndcg@3: 0.522442\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.535429\tvalid's ndcg@2: 0.520104\tvalid's ndcg@3: 0.513362    \n",
      "[10]\tvalid's ndcg@1: 0.538857\tvalid's ndcg@2: 0.527325\tvalid's ndcg@3: 0.51397    \n",
      "[15]\tvalid's ndcg@1: 0.530857\tvalid's ndcg@2: 0.524491\tvalid's ndcg@3: 0.515852   \n",
      "[20]\tvalid's ndcg@1: 0.543429\tvalid's ndcg@2: 0.529186\tvalid's ndcg@3: 0.51989    \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.554286\tvalid's ndcg@2: 0.531922\tvalid's ndcg@3: 0.519197\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.536571\tvalid's ndcg@2: 0.526529\tvalid's ndcg@3: 0.515071    \n",
      "[10]\tvalid's ndcg@1: 0.529143\tvalid's ndcg@2: 0.523358\tvalid's ndcg@3: 0.516319   \n",
      "[15]\tvalid's ndcg@1: 0.532571\tvalid's ndcg@2: 0.522145\tvalid's ndcg@3: 0.519122   \n",
      "[20]\tvalid's ndcg@1: 0.542857\tvalid's ndcg@2: 0.528254\tvalid's ndcg@3: 0.519372   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536289\tvalid's ndcg@3: 0.522442\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.537143\tvalid's ndcg@2: 0.523366\tvalid's ndcg@3: 0.513675    \n",
      "[10]\tvalid's ndcg@1: 0.535429\tvalid's ndcg@2: 0.523757\tvalid's ndcg@3: 0.51483    \n",
      "[15]\tvalid's ndcg@1: 0.541714\tvalid's ndcg@2: 0.530624\tvalid's ndcg@3: 0.518599   \n",
      "[20]\tvalid's ndcg@1: 0.537714\tvalid's ndcg@2: 0.524798\tvalid's ndcg@3: 0.517617   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.554286\tvalid's ndcg@2: 0.531922\tvalid's ndcg@3: 0.519197\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.531429\tvalid's ndcg@2: 0.526005\tvalid's ndcg@3: 0.514379    \n",
      "[10]\tvalid's ndcg@1: 0.524\tvalid's ndcg@2: 0.518216\tvalid's ndcg@3: 0.510922      \n",
      "[15]\tvalid's ndcg@1: 0.525714\tvalid's ndcg@2: 0.51559\tvalid's ndcg@3: 0.51025     \n",
      "[20]\tvalid's ndcg@1: 0.527429\tvalid's ndcg@2: 0.51556\tvalid's ndcg@3: 0.509718    \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536289\tvalid's ndcg@3: 0.522442\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.525143\tvalid's ndcg@2: 0.522511\tvalid's ndcg@3: 0.511207    \n",
      "[10]\tvalid's ndcg@1: 0.523429\tvalid's ndcg@2: 0.518692\tvalid's ndcg@3: 0.510692   \n",
      "[15]\tvalid's ndcg@1: 0.523429\tvalid's ndcg@2: 0.518086\tvalid's ndcg@3: 0.51192    \n",
      "[20]\tvalid's ndcg@1: 0.522286\tvalid's ndcg@2: 0.520178\tvalid's ndcg@3: 0.512658   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536428\tvalid's ndcg@3: 0.52219\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.518286\tvalid's ndcg@2: 0.514072\tvalid's ndcg@3: 0.505576    \n",
      "[10]\tvalid's ndcg@1: 0.516571\tvalid's ndcg@2: 0.513242\tvalid's ndcg@3: 0.505308   \n",
      "[15]\tvalid's ndcg@1: 0.515429\tvalid's ndcg@2: 0.509226\tvalid's ndcg@3: 0.502286   \n",
      "[20]\tvalid's ndcg@1: 0.518286\tvalid's ndcg@2: 0.508022\tvalid's ndcg@3: 0.503406   \n",
      "Early stopping, best iteration is:                                                \n",
      "[2]\tvalid's ndcg@1: 0.544\tvalid's ndcg@2: 0.536913\tvalid's ndcg@3: 0.51837\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.536\tvalid's ndcg@2: 0.526073\tvalid's ndcg@3: 0.517914       \n",
      "[10]\tvalid's ndcg@1: 0.523429\tvalid's ndcg@2: 0.51712\tvalid's ndcg@3: 0.511939    \n",
      "[15]\tvalid's ndcg@1: 0.530286\tvalid's ndcg@2: 0.520685\tvalid's ndcg@3: 0.511778   \n",
      "[20]\tvalid's ndcg@1: 0.529143\tvalid's ndcg@2: 0.522835\tvalid's ndcg@3: 0.512763   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536428\tvalid's ndcg@3: 0.52219\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47243                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.537714\tvalid's ndcg@2: 0.525961\tvalid's ndcg@3: 0.514573    \n",
      "[10]\tvalid's ndcg@1: 0.541714\tvalid's ndcg@2: 0.527693\tvalid's ndcg@3: 0.515196   \n",
      "[15]\tvalid's ndcg@1: 0.537143\tvalid's ndcg@2: 0.526577\tvalid's ndcg@3: 0.516508   \n",
      "[20]\tvalid's ndcg@1: 0.544571\tvalid's ndcg@2: 0.527979\tvalid's ndcg@3: 0.518993   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.556\tvalid's ndcg@2: 0.536428\tvalid's ndcg@3: 0.52219\n",
      "100%|██████████| 25/25 [00:20<00:00,  1.24trial/s, best loss: -0.5270711920014535]\n",
      "best parameters: {'lambdarank_truncation_level': 46, 'learning_rate': 0.023221403531782224, 'num_iterations': 33}\n"
     ]
    }
   ],
   "source": [
    "train_data = ll.r.data_c\n",
    "train, valid = split_data(train_data,test_size=0.2,rank_learning=False)\n",
    "# 0.8 : 0.2\n",
    "\n",
    "x_train = train.drop(['rank', 'date','単勝'], axis=1)\n",
    "y_train = train['rank']\n",
    "x_valid = valid.drop(['rank', 'date','単勝'], axis=1)\n",
    "y_valid = valid['rank']\n",
    "train_query = x_train.groupby(x_train.index).size()\n",
    "train = lgb.Dataset(x_train, y_train, group=train_query)\n",
    "valid_query = x_valid.groupby(x_valid.index).size()\n",
    "valid = lgb.Dataset(x_valid, y_valid, reference=train, group=valid_query)\n",
    "\n",
    "\n",
    "def score(params):\n",
    "    print(\"Training start:\")\n",
    "\n",
    "    N_boost_round = []\n",
    "    Score = []\n",
    "\n",
    "    lgb_results={}  #履歴格納用\n",
    "\n",
    "    lgb_clf = lgb.train(\n",
    "        params,\n",
    "        train,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=valid,\n",
    "        valid_names=['valid'],\n",
    "        early_stopping_rounds=20,\n",
    "        verbose_eval=5,\n",
    "        evals_result=lgb_results,\n",
    "    )\n",
    "#     return lgb_results\n",
    "    return {'loss': -1.0 * lgb_results['valid']['ndcg@3'][lgb_clf.best_iteration], 'status': STATUS_OK}\n",
    "\n",
    "def optimize(trials):\n",
    "#探索スペース\n",
    "    space = {\n",
    "        'objective': 'lambdarank',\n",
    "        'metric': 'ndcg',\n",
    "        # 上位三着を考慮する\n",
    "        'ndcg_eval_at': [1,2,3],\n",
    "#         best paramsの返り値は, choiceだとindexか?\n",
    "        'lambdarank_truncation_level': hp.choice('lambdarank_truncation_level',range(1,50)),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.1),\n",
    "        # n_estimators == num_iterations\n",
    "        'num_iterations': hp.choice('num_iterations',range(50,120)),\n",
    "        'boosting_type': 'gbdt',\n",
    "        'random_state': 777\n",
    "    }\n",
    "\n",
    "    max_evals = 25      #探索回数(25くらいで十分)\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=max_evals)\n",
    "\n",
    "    print(\"best parameters:\", best)\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "optimize(trials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad70252",
   "metadata": {},
   "source": [
    "# milestone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977d2055",
   "metadata": {},
   "outputs": [],
   "source": [
    "'lambdarank_truncation_level': 46, 'learning_rate': 0.023221403531782224, 'num_iterations': 33}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6be3bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "                'metric': 'ndcg',\n",
    "                'objective': 'lambdarank',\n",
    "                'ndcg_eval_at': [1,2,3],\n",
    "                'boosting_type': 'gbdt',\n",
    "                'random_state': 777,\n",
    "                'lambdarank_truncation_level': 47,\n",
    "                'learning_rate':0.023221403531782224,\n",
    "                'num_iterations': 83,\n",
    "                # 'lambdarank_truncation_level': 10,\n",
    "                # 'learning_rate': 0.02273417953255777,\n",
    "                # n_estimators は num_iterations と同義　default = 100\n",
    "                # 'n_estimators': 97,\n",
    "                # 'num_leaves': 42,\n",
    "                'force_col_wise':True\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "defd053c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 47243\n",
      "[LightGBM] [Info] Number of data points in the train set: 96523, number of used features: 172\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ll.learn_lgb2(train,lgbm_params=lgbm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30c738-f553-4488-8239-235c9808c184",
   "metadata": {},
   "source": [
    "# Simulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a51be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd\n",
    "save_path = '/Users/Owner/Desktop/Horse/ll_obj.pickle'\n",
    "\n",
    "def save_pickle(save_path,object_):\n",
    "    with open(save_path, mode=\"wb\") as f:\n",
    "        pickle.dump(object_, f)\n",
    "\n",
    "def load_pickle(save_path):\n",
    "    with open(save_path, mode=\"rb\") as f:\n",
    "        object_ = pickle.load(f)\n",
    "    return object_\n",
    "\n",
    "# save_pickle(save_path,ll)\n",
    "ll = load_pickle(save_path)\n",
    "ll.learn_model_ft()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4c3498b-a9bf-4891-9ec4-748f1681fe24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "odds 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for odds in [1]:\n",
    "    print()\n",
    "    sl = RankSimulater(ll.model)\n",
    "    print(\"odds\",odds)\n",
    "    fukusho_df = sl.get_result_df(ll.r.data_c.loc[ll.x_test.index[0]:],return_tables,kaime='fukusho',odds=odds)\n",
    "    tansho_df = sl.get_result_df(ll.r.data_c.loc[ll.x_test.index[0]:],return_tables,kaime='tansho',odds=odds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493518ec",
   "metadata": {},
   "source": [
    "# calc results df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba8fd1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fukusho_acc(fukusho_df,odds=1.1,bet=100):\n",
    "    race_num = len(fukusho_df)\n",
    "    count_in3 = 0\n",
    "    count_list = [0 for _ in range(3)]\n",
    "\n",
    "    for i in range(len(fukusho_df)):\n",
    "        col = fukusho_df.iloc[i]\n",
    "        actual_rank_list = col['actual rank list']\n",
    "        pred_list = col['pred list']\n",
    "        fukusho_list = col['fukusho list']\n",
    "        is_in = False\n",
    "        visited = False\n",
    "\n",
    "        for i,pred in enumerate(pred_list):\n",
    "            is_in =  pred in fukusho_list\n",
    "            if is_in and not visited:\n",
    "                count_in3 += 1\n",
    "                visited = True\n",
    "\n",
    "            if pred_list[i] in fukusho_list:\n",
    "                count_list[i] += 1\n",
    "                \n",
    "    # 予測した3頭の馬のうち, 1頭以上複勝圏に含まれている割合\n",
    "    acc_in3 = count_in3/race_num * 100\n",
    "    acc_list = [i/race_num * 100 for i in count_list]\n",
    "\n",
    "    print(\"予測した3頭の馬のうち, 1頭以上複勝圏に含まれている割合\",acc_in3)\n",
    "    print(\"予測した3頭のそれぞれの複勝率\",acc_list)\n",
    "    \n",
    "\n",
    "def calc_tansho_accuracy(result_df,bet=100):\n",
    "    race_num = len(result_df)\n",
    "    atari_num = result_df[result_df['is_atari']==True].sum()['is_atari']\n",
    "    acc = (atari_num/race_num) * 100\n",
    "    \n",
    "    buy_num = result_df[result_df['is_buy']==True].sum()['is_buy']\n",
    "    buy_df = result_df[result_df['is_buy']]\n",
    "    atari_buy_num = buy_df[buy_df['is_atari']==True].sum()['is_atari']\n",
    "    # 条件付き精度 (買ったもとで当たった確率)\n",
    "    acc_cond = (atari_buy_num/buy_num) * 100\n",
    "    total_expense = buy_num * bet\n",
    "    return_price = result_df.sum()['profit']\n",
    "    # 回収率\n",
    "    profit_rate = (total_expense + return_price)/total_expense * 100\n",
    "    atari_dist = {i:0 for i in range(1,13)}\n",
    "    atari_buy_df = buy_df[buy_df['is_atari']==True]\n",
    "\n",
    "    for race_id in atari_buy_df.index:\n",
    "        race_num = int(str(race_id)[-2:])\n",
    "        atari_dist[race_num] += (1/atari_buy_num) * 100\n",
    "    \n",
    "    print('acc ',acc)\n",
    "    print('acc cond',acc_cond)\n",
    "    print('profit rate',profit_rate)\n",
    "    print('atari race distribution',atari_dist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b2e3331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "予測した3頭の馬のうち, 1頭以上複勝圏に含まれている割合 86.20302860347728\n",
      "予測した3頭のそれぞれの複勝率 [50.1402131239484, 41.61525518788559, 38.75490745933819]\n"
     ]
    }
   ],
   "source": [
    "calc_fukusho_acc(fukusho_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64589db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc  22.994952327537856\n",
      "acc cond 22.87323943661972\n",
      "profit rate 104.82816901408452\n",
      "atari race distribution {1: 10.344827586206895, 2: 8.866995073891625, 3: 8.374384236453201, 4: 9.60591133004926, 5: 8.620689655172413, 6: 8.12807881773399, 7: 10.591133004926107, 8: 7.881773399014777, 9: 7.635467980295565, 10: 6.403940886699506, 11: 5.1724137931034475, 12: 8.374384236453201}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "calc_tansho_accuracy(tansho_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff135d8f-2a18-4583-8747-68c2938e6b79",
   "metadata": {},
   "source": [
    "# race_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca02207f-1319-48d2-943f-195f395e1d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# race_id_list = ['2022040303{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022100403{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022010203{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "\n",
    "race_id_list = ['2022040304{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "race_id_list += ['2022100404{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "race_id_list += ['2022010204{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "\n",
    "\n",
    "\n",
    "# race_id_list += ['2022050308{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "\n",
    "# race_id_list += ['2022090301{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022090302{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022090303{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022090304{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "\n",
    "# race_id_list += ['2022020103{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022020104{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022020105{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022020106{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b58872b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_id_list = []\n",
    "\n",
    "for place in range(1, 11, 1):\n",
    "    for kai in range(1, 6, 1):\n",
    "        for day in range(1, 13, 1):\n",
    "            for r in range(1, 13, 1):\n",
    "                race_id = \"2022\" + str(place).zfill(2) + str(kai).zfill(2) +\\\n",
    "\t\tstr(day).zfill(2) + str(r).zfill(2)\n",
    "                race_id_list.append(race_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23038204",
   "metadata": {},
   "source": [
    "# Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "869c4470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aaa9befb2b6415485bd2f552509f1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2adcf3139c8d468594eaab5eb0d18083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c616d6e9c984e1f921af0c534fc5c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a54ead60d3465a9df9b07eeeafe046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18673 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a8a237ddac41bca2256875b1f658a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18673 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pe finish\n",
      "pe regularizrd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b211f1c4d4d44cb996cb69b3f43bb8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hr finish\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2a3c62326f4dc995f778840f379ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8016d8096e6a4fe49cff5b7059e96fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b505bbba3a4ff79fb53592d70a3d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 49464\n",
      "[LightGBM] [Info] Number of data points in the train set: 120314, number of used features: 172\n"
     ]
    }
   ],
   "source": [
    "pt = Predictor(peds,results,horse_results,race_id_list)\n",
    "# ********* test_size = 0  : ずっと0にしてなかった...\n",
    "pt.path_ft = '/Users/Owner/Desktop/Horse/horse/peds_ft.txt'\n",
    "pt.learn_lgb(lgbm_params,test_size=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32941e34",
   "metadata": {},
   "source": [
    "# 新潟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf56de",
   "metadata": {},
   "outputs": [],
   "source": [
    "base  = '2022040303'\n",
    "pt.predict(base+'12')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b57a3d",
   "metadata": {},
   "source": [
    "# 小倉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6722cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "base  = '2022100403'\n",
    "# for i in ['07','08','09','10','11']:\n",
    "pt.predict(base+'12')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e1ee5",
   "metadata": {},
   "source": [
    "# 札幌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "base  = '2022010203'\n",
    "# for i in ['07','08','09','10','11']:\n",
    "pt.predict(base+'12')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c82bc",
   "metadata": {},
   "source": [
    "# 当日の収支計算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92025ba",
   "metadata": {},
   "source": [
    "return_tables　と, return_tables_todayで形式が異なるので, 形式をそろえる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f72488",
   "metadata": {},
   "source": [
    "# 当日 sim 手順"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c63ecee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa0988ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fukusho_row = return_table[return_table[0]=='複勝']\n",
    "fukusho_odds_list = fukusho_row[2].str.split('円').values[0][0:3]\n",
    "fukusho_odds_list = [i for i in fukusho_odds_list if i!='']\n",
    "fukusho_odds = list(map(lambda x: int(x.replace(',',''))/100 , fukusho_odds_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11b04495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1, 1.1]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fukusho_odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c6c05ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['110', '110']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fukusho_odds_list = fukusho_row[2].str.split('円').values[0][0:3]\n",
    "fukusho_odds_list.remove('')\n",
    "fukusho_odds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1915ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fukusho_row[2].str.split('円').values[0][0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9f98cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0        1             2          3\n",
      "202204030404  複勝  11 9 13  110円220円140円  1人気4人気3人気\n",
      "               0      1             2          3\n",
      "202201020411  複勝  4 3 9  180円170円310円  3人気2人気5人気\n",
      "               0      1             2          3\n",
      "202210040412  複勝  1 3 9  110円130円150円  1人気2人気4人気\n",
      "               0        1             2          3\n",
      "202210040404  複勝  17 12 5  130円150円240円  1人気3人気4人気\n",
      "               0       1             2          3\n",
      "202201020403  複勝  1 6 10  190円110円170円  4人気1人気2人気\n",
      "               0       1             2          3\n",
      "202201020407  複勝  6 12 3  200円230円150円  3人気4人気1人気\n",
      "               0       1             2          3\n",
      "202204030405  複勝  9 4 11  150円120円310円  2人気1人気6人気\n",
      "               0       1             2          3\n",
      "202210040408  複勝  14 7 6  170円600円490円  1人気9人気6人気\n",
      "               0      1               2          3\n",
      "202201020409  複勝  4 6 2  1,100円150円230円  8人気1人気5人気\n",
      "               0      1             2          3\n",
      "202210040401  複勝  4 2 3  110円290円250円  1人気5人気3人気\n",
      "               0      1             2          3\n",
      "202210040409  複勝  2 7 3  290円130円140円  6人気1人気2人気\n",
      "               0       1             2          3\n",
      "202210040410  複勝  5 6 14  140円120円280円  2人気1人気5人気\n",
      "               0    1         2       3\n",
      "202210040402  複勝  4 1  110円110円  1人気2人気\n",
      "               0       1             2          3\n",
      "202204030403  複勝  12 8 6  210円500円270円  1人気8人気6人気\n",
      "               0       1             2          3\n",
      "202210040406  複勝  2 11 8  390円150円120円  6人気2人気1人気\n",
      "               0      1             2          3\n",
      "202201020406  複勝  1 3 4  620円140円200円  9人気1人気3人気\n",
      "               0         1             2          3\n",
      "202204030412  複勝  10 13 11  220円380円200円  5人気7人気2人気\n",
      "               0       1               2           3\n",
      "202210040411  複勝  1 3 16  1,570円170円120円  16人気2人気1人気\n",
      "               0       1             2          3\n",
      "202204030406  複勝  8 6 14  120円150円180円  1人気2人気4人気\n",
      "               0       1             2          3\n",
      "202201020404  複勝  2 13 4  360円330円170円  4人気3人気2人気\n",
      "               0         1             2          3\n",
      "202204030409  複勝  12 17 18  380円210円250円  5人気2人気3人気\n",
      "               0        1               2           3\n",
      "202201020401  複勝  3 10 12  150円190円1,880円  2人気3人気11人気\n",
      "               0      1               2          3\n",
      "202204030402  複勝  7 4 9  140円2,300円180円  1人気8人気4人気\n",
      "               0       1             2          3\n",
      "202204030401  複勝  10 6 7  140円100円160円  3人気1人気4人気\n",
      "               0        1             2          3\n",
      "202201020408  複勝  14 3 13  150円160円480円  1人気2人気7人気\n",
      "               0       1             2          3\n",
      "202210040407  複勝  14 8 7  490円420円710円  8人気7人気9人気\n",
      "               0       1             2          3\n",
      "202204030407  複勝  2 3 10  140円340円550円  1人気6人気8人気\n",
      "               0      1             2          3\n",
      "202201020412  複勝  4 8 3  130円200円200円  1人気5人気3人気\n",
      "               0         1             2          3\n",
      "202204030411  複勝  12 11 10  330円190円350円  5人気1人気6人気\n",
      "               0       1             2          3\n",
      "202201020402  複勝  4 10 3  260円110円140円  6人気1人気2人気\n",
      "               0      1             2          3\n",
      "202204030410  複勝  5 2 1  110円170円170円  1人気3人気4人気\n",
      "               0        1             2          3\n",
      "202201020410  複勝  11 7 13  210円120円240円  3人気1人気4人気\n",
      "               0       1             2          3\n",
      "202210040403  複勝  16 5 7  150円360円140円  2人気6人気1人気\n",
      "               0        1               2          3\n",
      "202204030408  複勝  11 12 4  450円660円2,370円  2人気5人気8人気\n",
      "               0      1             2          3\n",
      "202210040405  複勝  7 4 6  220円390円110円  5人気6人気1人気\n",
      "               0    1         2       3\n",
      "202201020405  複勝  4 5  240円190円  3人気2人気\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "return_tables_ = tsl.return_tables\n",
    "indexes = set(return_tables_.index)\n",
    "\n",
    "for idx in indexes:\n",
    "    return_table = return_tables_.loc[idx]\n",
    "    fukusho_row = return_table[return_table[0]=='複勝']\n",
    "    print(fukusho_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7f9297d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225b255eec384897953022183bdd642e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data =  ShutubaTable.scrape(race_id_list, pt.date)\n",
    "st = ShutubaTable(data)\n",
    "st.preprocessing()\n",
    "st.merge_horse_results(pt.hr)\n",
    "st.merge_peds(pt.pe.peds_vec)\n",
    "st.process_categorical(pt.r.le_horse, pt.r.le_jockey, pt.r.data_pe)\n",
    "\n",
    "\n",
    "tsl = TodaySimulater(pt.model)\n",
    "tsl.return_table_today(race_id_list)\n",
    "all_results = tsl.get_result_df( st.data_c, tsl.return_tables,race_id_list, kaime='all',odds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5ada4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_list</th>\n",
       "      <th>actual_rank_list</th>\n",
       "      <th>tansho_odds</th>\n",
       "      <th>fukusho_odds</th>\n",
       "      <th>umaren_odds</th>\n",
       "      <th>wide_odds</th>\n",
       "      <th>umatan_odds</th>\n",
       "      <th>sanrenpuku_odds</th>\n",
       "      <th>sanrentan_odds</th>\n",
       "      <th>wide_comb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202204030401</th>\n",
       "      <td>[7, 6, 10, 2, 3, 8, 5, 4, 9, 1]</td>\n",
       "      <td>[10, 6, 7]</td>\n",
       "      <td>8.1</td>\n",
       "      <td>[1.4, 1.0, 1.6]</td>\n",
       "      <td>4.2</td>\n",
       "      <td>[1.9, 4.3, 2.1]</td>\n",
       "      <td>15.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>59.4</td>\n",
       "      <td>[[6, 10], [7, 10], [6, 7]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030402</th>\n",
       "      <td>[9, 6, 7, 5, 3, 8, 2, 4, 1]</td>\n",
       "      <td>[7, 4, 9]</td>\n",
       "      <td>3.1</td>\n",
       "      <td>[1.4, 23.0, 1.8]</td>\n",
       "      <td>295.5</td>\n",
       "      <td>[70.8, 3.2, 83.5]</td>\n",
       "      <td>396.6</td>\n",
       "      <td>295.4</td>\n",
       "      <td>2036.3</td>\n",
       "      <td>[[4, 7], [7, 9], [4, 9]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030403</th>\n",
       "      <td>[7, 4, 12, 1, 6, 8, 11, 17, 2, 14, 13, 15, 16,...</td>\n",
       "      <td>[12, 8, 6]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[2.1, 5.0, 2.7]</td>\n",
       "      <td>40.9</td>\n",
       "      <td>[12.0, 6.7, 23.9]</td>\n",
       "      <td>69.2</td>\n",
       "      <td>91.4</td>\n",
       "      <td>402.0</td>\n",
       "      <td>[[8, 12], [6, 12], [6, 8]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030404</th>\n",
       "      <td>[13, 11, 5, 9, 12, 2, 10, 4, 6, 1, 15, 3, 14, ...</td>\n",
       "      <td>[11, 9, 13]</td>\n",
       "      <td>2.3</td>\n",
       "      <td>[1.1, 2.2, 1.4]</td>\n",
       "      <td>12.6</td>\n",
       "      <td>[4.8, 3.0, 5.1]</td>\n",
       "      <td>15.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>65.9</td>\n",
       "      <td>[[9, 11], [11, 13], [9, 13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030405</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]</td>\n",
       "      <td>[9, 4, 11]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[1.5, 1.2, 3.1]</td>\n",
       "      <td>5.5</td>\n",
       "      <td>[2.7, 8.0, 7.3]</td>\n",
       "      <td>10.8</td>\n",
       "      <td>19.1</td>\n",
       "      <td>84.6</td>\n",
       "      <td>[[4, 9], [9, 11], [4, 11]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030406</th>\n",
       "      <td>[6, 12, 14, 8, 15, 9, 13, 4, 16, 11, 2, 5, 18,...</td>\n",
       "      <td>[8, 6, 14]</td>\n",
       "      <td>2.8</td>\n",
       "      <td>[1.2, 1.5, 1.8]</td>\n",
       "      <td>5.9</td>\n",
       "      <td>[2.4, 4.9, 4.7]</td>\n",
       "      <td>10.8</td>\n",
       "      <td>13.8</td>\n",
       "      <td>51.7</td>\n",
       "      <td>[[6, 8], [8, 14], [6, 14]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030407</th>\n",
       "      <td>[2, 8, 4, 3, 7, 10, 12, 14, 6, 15, 9, 13, 1, 5...</td>\n",
       "      <td>[2, 3, 10]</td>\n",
       "      <td>2.7</td>\n",
       "      <td>[1.4, 3.4, 5.5]</td>\n",
       "      <td>14.7</td>\n",
       "      <td>[7.3, 14.8, 58.0]</td>\n",
       "      <td>21.7</td>\n",
       "      <td>146.0</td>\n",
       "      <td>478.1</td>\n",
       "      <td>[[2, 3], [2, 10], [3, 10]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030408</th>\n",
       "      <td>[8, 7, 9, 11, 12, 4, 2, 10, 1, 3, 6, 5]</td>\n",
       "      <td>[11, 12, 4]</td>\n",
       "      <td>7.2</td>\n",
       "      <td>[4.5, 6.6, 23.7]</td>\n",
       "      <td>27.6</td>\n",
       "      <td>[6.9, 23.0, 32.1]</td>\n",
       "      <td>66.1</td>\n",
       "      <td>313.2</td>\n",
       "      <td>1447.5</td>\n",
       "      <td>[[11, 12], [4, 11], [4, 12]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030409</th>\n",
       "      <td>[8, 12, 3, 2, 10, 6, 17, 7, 11, 1, 15, 13, 18,...</td>\n",
       "      <td>[12, 17, 18]</td>\n",
       "      <td>11.3</td>\n",
       "      <td>[3.8, 2.1, 2.5]</td>\n",
       "      <td>21.9</td>\n",
       "      <td>[7.5, 10.7, 6.9]</td>\n",
       "      <td>58.6</td>\n",
       "      <td>52.9</td>\n",
       "      <td>349.4</td>\n",
       "      <td>[[12, 17], [12, 18], [17, 18]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030410</th>\n",
       "      <td>[6, 5, 4, 7, 2, 1, 3, 9, 8]</td>\n",
       "      <td>[5, 2, 1]</td>\n",
       "      <td>1.8</td>\n",
       "      <td>[1.1, 1.7, 1.7]</td>\n",
       "      <td>6.1</td>\n",
       "      <td>[2.7, 3.4, 6.2]</td>\n",
       "      <td>7.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>33.8</td>\n",
       "      <td>[[2, 5], [1, 5], [1, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030411</th>\n",
       "      <td>[2, 9, 11, 14, 3, 5, 15, 8, 10, 6, 4, 1, 12, 7...</td>\n",
       "      <td>[12, 11, 10]</td>\n",
       "      <td>8.7</td>\n",
       "      <td>[3.3, 1.9, 3.5]</td>\n",
       "      <td>37.7</td>\n",
       "      <td>[14.1, 26.7, 8.9]</td>\n",
       "      <td>75.6</td>\n",
       "      <td>105.5</td>\n",
       "      <td>636.6</td>\n",
       "      <td>[[11, 12], [10, 12], [10, 11]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030412</th>\n",
       "      <td>[10, 11, 6, 5, 14, 12, 1, 13, 3, 8, 4, 7, 9, 1...</td>\n",
       "      <td>[10, 13, 11]</td>\n",
       "      <td>5.2</td>\n",
       "      <td>[2.2, 3.8, 2.0]</td>\n",
       "      <td>44.4</td>\n",
       "      <td>[11.0, 5.0, 9.8]</td>\n",
       "      <td>61.8</td>\n",
       "      <td>49.5</td>\n",
       "      <td>282.8</td>\n",
       "      <td>[[10, 13], [10, 11], [11, 13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040401</th>\n",
       "      <td>[3, 6, 4, 7, 2, 1, 8, 9, 5, 10]</td>\n",
       "      <td>[4, 2, 3]</td>\n",
       "      <td>1.5</td>\n",
       "      <td>[1.1, 2.9, 2.5]</td>\n",
       "      <td>12.3</td>\n",
       "      <td>[3.9, 3.9, 11.6]</td>\n",
       "      <td>16.8</td>\n",
       "      <td>27.4</td>\n",
       "      <td>80.8</td>\n",
       "      <td>[[2, 4], [3, 4], [2, 3]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040402</th>\n",
       "      <td>[1, 4, 3, 2, 5]</td>\n",
       "      <td>[4, 1, 3]</td>\n",
       "      <td>1.9</td>\n",
       "      <td>[1.1, 1.1]</td>\n",
       "      <td>1.4</td>\n",
       "      <td>[1.1, 1.5, 1.8]</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.2</td>\n",
       "      <td>[[1, 4], [3, 4], [1, 3]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040403</th>\n",
       "      <td>[8, 7, 16, 12, 9, 11, 14, 6, 4, 1, 2, 13, 5, 1...</td>\n",
       "      <td>[16, 5, 7]</td>\n",
       "      <td>4.1</td>\n",
       "      <td>[1.5, 3.6, 1.4]</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[11.8, 2.8, 10.9]</td>\n",
       "      <td>56.9</td>\n",
       "      <td>39.4</td>\n",
       "      <td>267.9</td>\n",
       "      <td>[[5, 16], [7, 16], [5, 7]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040404</th>\n",
       "      <td>[17, 4, 1, 10, 12, 5, 9, 2, 8, 6, 3, 7, 11, 15...</td>\n",
       "      <td>[17, 12, 5]</td>\n",
       "      <td>3.1</td>\n",
       "      <td>[1.3, 1.5, 2.4]</td>\n",
       "      <td>7.7</td>\n",
       "      <td>[3.4, 6.9, 8.3]</td>\n",
       "      <td>12.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>93.1</td>\n",
       "      <td>[[12, 17], [5, 17], [5, 12]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040405</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>[7, 4, 6]</td>\n",
       "      <td>12.3</td>\n",
       "      <td>[2.2, 3.9, 1.1]</td>\n",
       "      <td>75.3</td>\n",
       "      <td>[16.7, 4.4, 6.7]</td>\n",
       "      <td>146.3</td>\n",
       "      <td>43.4</td>\n",
       "      <td>454.3</td>\n",
       "      <td>[[4, 7], [6, 7], [4, 6]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040406</th>\n",
       "      <td>[12, 8, 11, 3, 5, 2, 9, 10, 7, 13, 1, 6, 4]</td>\n",
       "      <td>[2, 11, 8]</td>\n",
       "      <td>28.0</td>\n",
       "      <td>[3.9, 1.5, 1.2]</td>\n",
       "      <td>68.7</td>\n",
       "      <td>[15.9, 10.4, 2.8]</td>\n",
       "      <td>184.3</td>\n",
       "      <td>42.8</td>\n",
       "      <td>579.9</td>\n",
       "      <td>[[2, 11], [2, 8], [8, 11]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040407</th>\n",
       "      <td>[15, 5, 2, 14, 7, 4, 10, 12, 11, 13, 3, 8, 9, ...</td>\n",
       "      <td>[14, 8, 7]</td>\n",
       "      <td>14.4</td>\n",
       "      <td>[4.9, 4.2, 7.1]</td>\n",
       "      <td>95.1</td>\n",
       "      <td>[27.4, 51.1, 39.4]</td>\n",
       "      <td>220.8</td>\n",
       "      <td>610.9</td>\n",
       "      <td>4115.4</td>\n",
       "      <td>[[8, 14], [7, 14], [7, 8]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040408</th>\n",
       "      <td>[12, 3, 6, 13, 14, 7, 16, 4, 8, 2, 5, 15, 10, ...</td>\n",
       "      <td>[14, 7, 6]</td>\n",
       "      <td>2.8</td>\n",
       "      <td>[1.7, 6.0, 4.9]</td>\n",
       "      <td>45.6</td>\n",
       "      <td>[14.7, 11.0, 42.8]</td>\n",
       "      <td>67.2</td>\n",
       "      <td>192.0</td>\n",
       "      <td>675.5</td>\n",
       "      <td>[[7, 14], [6, 14], [6, 7]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040409</th>\n",
       "      <td>[3, 7, 9, 2, 5, 10, 6, 11, 12, 8, 4, 1]</td>\n",
       "      <td>[2, 7, 3]</td>\n",
       "      <td>15.4</td>\n",
       "      <td>[2.9, 1.3, 1.4]</td>\n",
       "      <td>16.6</td>\n",
       "      <td>[5.4, 6.5, 2.3]</td>\n",
       "      <td>49.8</td>\n",
       "      <td>16.3</td>\n",
       "      <td>149.0</td>\n",
       "      <td>[[2, 7], [2, 3], [3, 7]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040410</th>\n",
       "      <td>[15, 9, 16, 5, 6, 10, 1, 14, 3, 2, 13, 11, 12,...</td>\n",
       "      <td>[5, 6, 14]</td>\n",
       "      <td>4.2</td>\n",
       "      <td>[1.4, 1.2, 2.8]</td>\n",
       "      <td>5.2</td>\n",
       "      <td>[2.3, 9.2, 5.4]</td>\n",
       "      <td>11.6</td>\n",
       "      <td>21.1</td>\n",
       "      <td>91.8</td>\n",
       "      <td>[[5, 6], [5, 14], [6, 14]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040411</th>\n",
       "      <td>[16, 7, 14, 11, 12, 3, 15, 4, 18, 2, 17, 8, 5,...</td>\n",
       "      <td>[1, 3, 16]</td>\n",
       "      <td>164.3</td>\n",
       "      <td>[15.7, 1.7, 1.2]</td>\n",
       "      <td>461.9</td>\n",
       "      <td>[89.6, 45.2, 3.1]</td>\n",
       "      <td>1133.9</td>\n",
       "      <td>318.2</td>\n",
       "      <td>4935.8</td>\n",
       "      <td>[[1, 3], [1, 16], [3, 16]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040412</th>\n",
       "      <td>[1, 9, 7, 6, 2, 5, 8, 3, 4, 10]</td>\n",
       "      <td>[1, 3, 9]</td>\n",
       "      <td>1.6</td>\n",
       "      <td>[1.1, 1.3, 1.5]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[2.0, 2.2, 4.9]</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[[1, 3], [1, 9], [3, 9]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020401</th>\n",
       "      <td>[11, 10, 2, 3, 5, 9, 14, 4, 8, 13, 12, 7, 6, 1]</td>\n",
       "      <td>[3, 10, 12]</td>\n",
       "      <td>3.2</td>\n",
       "      <td>[1.5, 1.9, 18.8]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[4.1, 54.4, 73.5]</td>\n",
       "      <td>16.8</td>\n",
       "      <td>372.0</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>[[3, 10], [3, 12], [10, 12]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020402</th>\n",
       "      <td>[3, 5, 10, 12, 7, 4, 9, 11, 2, 1, 6, 8]</td>\n",
       "      <td>[4, 10, 3]</td>\n",
       "      <td>12.5</td>\n",
       "      <td>[2.6, 1.1, 1.4]</td>\n",
       "      <td>14.6</td>\n",
       "      <td>[4.7, 7.3, 2.2]</td>\n",
       "      <td>35.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>137.9</td>\n",
       "      <td>[[4, 10], [3, 4], [3, 10]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020403</th>\n",
       "      <td>[6, 8, 10, 12, 14, 1, 5, 4, 2, 13, 9, 3, 7]</td>\n",
       "      <td>[1, 6, 10]</td>\n",
       "      <td>6.8</td>\n",
       "      <td>[1.9, 1.1, 1.7]</td>\n",
       "      <td>5.2</td>\n",
       "      <td>[2.7, 7.5, 2.7]</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>86.2</td>\n",
       "      <td>[[1, 6], [1, 10], [6, 10]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020404</th>\n",
       "      <td>[4, 13, 1, 9, 8, 7, 10, 6, 12, 5, 2, 11, 3, 14]</td>\n",
       "      <td>[2, 13, 4]</td>\n",
       "      <td>12.8</td>\n",
       "      <td>[3.6, 3.3, 1.7]</td>\n",
       "      <td>70.2</td>\n",
       "      <td>[16.3, 5.6, 5.3]</td>\n",
       "      <td>144.1</td>\n",
       "      <td>46.4</td>\n",
       "      <td>500.3</td>\n",
       "      <td>[[2, 13], [2, 4], [4, 13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020405</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>[4, 5, 6]</td>\n",
       "      <td>6.4</td>\n",
       "      <td>[2.4, 1.9]</td>\n",
       "      <td>10.1</td>\n",
       "      <td>[2.7, 1.8, 1.5]</td>\n",
       "      <td>21.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>33.9</td>\n",
       "      <td>[[4, 5], [4, 6], [5, 6]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020406</th>\n",
       "      <td>[9, 12, 2, 4, 11, 3, 6, 8, 5, 7, 10, 1]</td>\n",
       "      <td>[1, 3, 4]</td>\n",
       "      <td>21.3</td>\n",
       "      <td>[6.2, 1.4, 2.0]</td>\n",
       "      <td>48.1</td>\n",
       "      <td>[17.0, 30.0, 4.7]</td>\n",
       "      <td>103.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>698.3</td>\n",
       "      <td>[[1, 3], [1, 4], [3, 4]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020407</th>\n",
       "      <td>[12, 8, 4, 9, 2, 13, 7, 3, 1, 6, 11, 10, 5]</td>\n",
       "      <td>[6, 12, 3]</td>\n",
       "      <td>6.9</td>\n",
       "      <td>[2.0, 2.3, 1.5]</td>\n",
       "      <td>36.4</td>\n",
       "      <td>[13.1, 4.6, 6.3]</td>\n",
       "      <td>76.8</td>\n",
       "      <td>41.6</td>\n",
       "      <td>294.2</td>\n",
       "      <td>[[6, 12], [3, 6], [3, 12]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020408</th>\n",
       "      <td>[13, 9, 14, 11, 5, 3, 12, 1, 7, 2, 6, 4, 10, 8]</td>\n",
       "      <td>[14, 3, 13]</td>\n",
       "      <td>3.3</td>\n",
       "      <td>[1.5, 1.6, 4.8]</td>\n",
       "      <td>6.8</td>\n",
       "      <td>[3.9, 13.5, 12.7]</td>\n",
       "      <td>13.1</td>\n",
       "      <td>43.4</td>\n",
       "      <td>180.6</td>\n",
       "      <td>[[3, 14], [13, 14], [3, 13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020409</th>\n",
       "      <td>[3, 11, 2, 5, 9, 6, 7, 1, 4, 8, 10]</td>\n",
       "      <td>[4, 6, 2]</td>\n",
       "      <td>78.4</td>\n",
       "      <td>[11.0, 1.5, 2.3]</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[29.5, 52.7, 5.5]</td>\n",
       "      <td>279.0</td>\n",
       "      <td>215.2</td>\n",
       "      <td>1774.5</td>\n",
       "      <td>[[4, 6], [2, 4], [2, 6]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020410</th>\n",
       "      <td>[7, 1, 12, 10, 11, 3, 4, 5, 14, 8, 6, 13, 9, 2]</td>\n",
       "      <td>[11, 7, 13]</td>\n",
       "      <td>19.3</td>\n",
       "      <td>[2.1, 1.2, 2.4]</td>\n",
       "      <td>16.9</td>\n",
       "      <td>[6.2, 16.4, 5.1]</td>\n",
       "      <td>54.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>391.4</td>\n",
       "      <td>[[7, 11], [11, 13], [7, 13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020411</th>\n",
       "      <td>[4, 13, 12, 3, 10, 6, 14, 11, 16, 7, 8, 5, 1, ...</td>\n",
       "      <td>[4, 3, 9]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[1.8, 1.7, 3.1]</td>\n",
       "      <td>9.3</td>\n",
       "      <td>[4.1, 10.9, 8.0]</td>\n",
       "      <td>18.8</td>\n",
       "      <td>41.9</td>\n",
       "      <td>152.1</td>\n",
       "      <td>[[3, 4], [4, 9], [3, 9]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020412</th>\n",
       "      <td>[4, 7, 3, 16, 15, 12, 11, 8, 6, 5, 9, 2, 10, 1...</td>\n",
       "      <td>[4, 8, 3]</td>\n",
       "      <td>2.7</td>\n",
       "      <td>[1.3, 2.0, 2.0]</td>\n",
       "      <td>8.6</td>\n",
       "      <td>[4.0, 4.0, 10.9]</td>\n",
       "      <td>13.6</td>\n",
       "      <td>28.1</td>\n",
       "      <td>92.9</td>\n",
       "      <td>[[4, 8], [3, 4], [3, 8]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      pred_list  \\\n",
       "202204030401                    [7, 6, 10, 2, 3, 8, 5, 4, 9, 1]   \n",
       "202204030402                        [9, 6, 7, 5, 3, 8, 2, 4, 1]   \n",
       "202204030403  [7, 4, 12, 1, 6, 8, 11, 17, 2, 14, 13, 15, 16,...   \n",
       "202204030404  [13, 11, 5, 9, 12, 2, 10, 4, 6, 1, 15, 3, 14, ...   \n",
       "202204030405        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]   \n",
       "202204030406  [6, 12, 14, 8, 15, 9, 13, 4, 16, 11, 2, 5, 18,...   \n",
       "202204030407  [2, 8, 4, 3, 7, 10, 12, 14, 6, 15, 9, 13, 1, 5...   \n",
       "202204030408            [8, 7, 9, 11, 12, 4, 2, 10, 1, 3, 6, 5]   \n",
       "202204030409  [8, 12, 3, 2, 10, 6, 17, 7, 11, 1, 15, 13, 18,...   \n",
       "202204030410                        [6, 5, 4, 7, 2, 1, 3, 9, 8]   \n",
       "202204030411  [2, 9, 11, 14, 3, 5, 15, 8, 10, 6, 4, 1, 12, 7...   \n",
       "202204030412  [10, 11, 6, 5, 14, 12, 1, 13, 3, 8, 4, 7, 9, 1...   \n",
       "202210040401                    [3, 6, 4, 7, 2, 1, 8, 9, 5, 10]   \n",
       "202210040402                                    [1, 4, 3, 2, 5]   \n",
       "202210040403  [8, 7, 16, 12, 9, 11, 14, 6, 4, 1, 2, 13, 5, 1...   \n",
       "202210040404  [17, 4, 1, 10, 12, 5, 9, 2, 8, 6, 3, 7, 11, 15...   \n",
       "202210040405                           [1, 2, 3, 4, 5, 6, 7, 8]   \n",
       "202210040406        [12, 8, 11, 3, 5, 2, 9, 10, 7, 13, 1, 6, 4]   \n",
       "202210040407  [15, 5, 2, 14, 7, 4, 10, 12, 11, 13, 3, 8, 9, ...   \n",
       "202210040408  [12, 3, 6, 13, 14, 7, 16, 4, 8, 2, 5, 15, 10, ...   \n",
       "202210040409            [3, 7, 9, 2, 5, 10, 6, 11, 12, 8, 4, 1]   \n",
       "202210040410  [15, 9, 16, 5, 6, 10, 1, 14, 3, 2, 13, 11, 12,...   \n",
       "202210040411  [16, 7, 14, 11, 12, 3, 15, 4, 18, 2, 17, 8, 5,...   \n",
       "202210040412                    [1, 9, 7, 6, 2, 5, 8, 3, 4, 10]   \n",
       "202201020401    [11, 10, 2, 3, 5, 9, 14, 4, 8, 13, 12, 7, 6, 1]   \n",
       "202201020402            [3, 5, 10, 12, 7, 4, 9, 11, 2, 1, 6, 8]   \n",
       "202201020403        [6, 8, 10, 12, 14, 1, 5, 4, 2, 13, 9, 3, 7]   \n",
       "202201020404    [4, 13, 1, 9, 8, 7, 10, 6, 12, 5, 2, 11, 3, 14]   \n",
       "202201020405                                 [1, 2, 3, 4, 5, 6]   \n",
       "202201020406            [9, 12, 2, 4, 11, 3, 6, 8, 5, 7, 10, 1]   \n",
       "202201020407        [12, 8, 4, 9, 2, 13, 7, 3, 1, 6, 11, 10, 5]   \n",
       "202201020408    [13, 9, 14, 11, 5, 3, 12, 1, 7, 2, 6, 4, 10, 8]   \n",
       "202201020409                [3, 11, 2, 5, 9, 6, 7, 1, 4, 8, 10]   \n",
       "202201020410    [7, 1, 12, 10, 11, 3, 4, 5, 14, 8, 6, 13, 9, 2]   \n",
       "202201020411  [4, 13, 12, 3, 10, 6, 14, 11, 16, 7, 8, 5, 1, ...   \n",
       "202201020412  [4, 7, 3, 16, 15, 12, 11, 8, 6, 5, 9, 2, 10, 1...   \n",
       "\n",
       "             actual_rank_list tansho_odds      fukusho_odds umaren_odds  \\\n",
       "202204030401       [10, 6, 7]         8.1   [1.4, 1.0, 1.6]         4.2   \n",
       "202204030402        [7, 4, 9]         3.1  [1.4, 23.0, 1.8]       295.5   \n",
       "202204030403       [12, 8, 6]         5.0   [2.1, 5.0, 2.7]        40.9   \n",
       "202204030404      [11, 9, 13]         2.3   [1.1, 2.2, 1.4]        12.6   \n",
       "202204030405       [9, 4, 11]         4.0   [1.5, 1.2, 3.1]         5.5   \n",
       "202204030406       [8, 6, 14]         2.8   [1.2, 1.5, 1.8]         5.9   \n",
       "202204030407       [2, 3, 10]         2.7   [1.4, 3.4, 5.5]        14.7   \n",
       "202204030408      [11, 12, 4]         7.2  [4.5, 6.6, 23.7]        27.6   \n",
       "202204030409     [12, 17, 18]        11.3   [3.8, 2.1, 2.5]        21.9   \n",
       "202204030410        [5, 2, 1]         1.8   [1.1, 1.7, 1.7]         6.1   \n",
       "202204030411     [12, 11, 10]         8.7   [3.3, 1.9, 3.5]        37.7   \n",
       "202204030412     [10, 13, 11]         5.2   [2.2, 3.8, 2.0]        44.4   \n",
       "202210040401        [4, 2, 3]         1.5   [1.1, 2.9, 2.5]        12.3   \n",
       "202210040402        [4, 1, 3]         1.9        [1.1, 1.1]         1.4   \n",
       "202210040403       [16, 5, 7]         4.1   [1.5, 3.6, 1.4]        40.0   \n",
       "202210040404      [17, 12, 5]         3.1   [1.3, 1.5, 2.4]         7.7   \n",
       "202210040405        [7, 4, 6]        12.3   [2.2, 3.9, 1.1]        75.3   \n",
       "202210040406       [2, 11, 8]        28.0   [3.9, 1.5, 1.2]        68.7   \n",
       "202210040407       [14, 8, 7]        14.4   [4.9, 4.2, 7.1]        95.1   \n",
       "202210040408       [14, 7, 6]         2.8   [1.7, 6.0, 4.9]        45.6   \n",
       "202210040409        [2, 7, 3]        15.4   [2.9, 1.3, 1.4]        16.6   \n",
       "202210040410       [5, 6, 14]         4.2   [1.4, 1.2, 2.8]         5.2   \n",
       "202210040411       [1, 3, 16]       164.3  [15.7, 1.7, 1.2]       461.9   \n",
       "202210040412        [1, 3, 9]         1.6   [1.1, 1.3, 1.5]         4.6   \n",
       "202201020401      [3, 10, 12]         3.2  [1.5, 1.9, 18.8]        10.0   \n",
       "202201020402       [4, 10, 3]        12.5   [2.6, 1.1, 1.4]        14.6   \n",
       "202201020403       [1, 6, 10]         6.8   [1.9, 1.1, 1.7]         5.2   \n",
       "202201020404       [2, 13, 4]        12.8   [3.6, 3.3, 1.7]        70.2   \n",
       "202201020405        [4, 5, 6]         6.4        [2.4, 1.9]        10.1   \n",
       "202201020406        [1, 3, 4]        21.3   [6.2, 1.4, 2.0]        48.1   \n",
       "202201020407       [6, 12, 3]         6.9   [2.0, 2.3, 1.5]        36.4   \n",
       "202201020408      [14, 3, 13]         3.3   [1.5, 1.6, 4.8]         6.8   \n",
       "202201020409        [4, 6, 2]        78.4  [11.0, 1.5, 2.3]        95.0   \n",
       "202201020410      [11, 7, 13]        19.3   [2.1, 1.2, 2.4]        16.9   \n",
       "202201020411        [4, 3, 9]         4.6   [1.8, 1.7, 3.1]         9.3   \n",
       "202201020412        [4, 8, 3]         2.7   [1.3, 2.0, 2.0]         8.6   \n",
       "\n",
       "                       wide_odds umatan_odds sanrenpuku_odds sanrentan_odds  \\\n",
       "202204030401     [1.9, 4.3, 2.1]        15.4             7.4           59.4   \n",
       "202204030402   [70.8, 3.2, 83.5]       396.6           295.4         2036.3   \n",
       "202204030403   [12.0, 6.7, 23.9]        69.2            91.4          402.0   \n",
       "202204030404     [4.8, 3.0, 5.1]        15.5            16.0           65.9   \n",
       "202204030405     [2.7, 8.0, 7.3]        10.8            19.1           84.6   \n",
       "202204030406     [2.4, 4.9, 4.7]        10.8            13.8           51.7   \n",
       "202204030407   [7.3, 14.8, 58.0]        21.7           146.0          478.1   \n",
       "202204030408   [6.9, 23.0, 32.1]        66.1           313.2         1447.5   \n",
       "202204030409    [7.5, 10.7, 6.9]        58.6            52.9          349.4   \n",
       "202204030410     [2.7, 3.4, 6.2]         7.4            12.3           33.8   \n",
       "202204030411   [14.1, 26.7, 8.9]        75.6           105.5          636.6   \n",
       "202204030412    [11.0, 5.0, 9.8]        61.8            49.5          282.8   \n",
       "202210040401    [3.9, 3.9, 11.6]        16.8            27.4           80.8   \n",
       "202210040402     [1.1, 1.5, 1.8]         2.6             2.2            6.2   \n",
       "202210040403   [11.8, 2.8, 10.9]        56.9            39.4          267.9   \n",
       "202210040404     [3.4, 6.9, 8.3]        12.2            27.3           93.1   \n",
       "202210040405    [16.7, 4.4, 6.7]       146.3            43.4          454.3   \n",
       "202210040406   [15.9, 10.4, 2.8]       184.3            42.8          579.9   \n",
       "202210040407  [27.4, 51.1, 39.4]       220.8           610.9         4115.4   \n",
       "202210040408  [14.7, 11.0, 42.8]        67.2           192.0          675.5   \n",
       "202210040409     [5.4, 6.5, 2.3]        49.8            16.3          149.0   \n",
       "202210040410     [2.3, 9.2, 5.4]        11.6            21.1           91.8   \n",
       "202210040411   [89.6, 45.2, 3.1]      1133.9           318.2         4935.8   \n",
       "202210040412     [2.0, 2.2, 4.9]         5.8             7.2           22.0   \n",
       "202201020401   [4.1, 54.4, 73.5]        16.8           372.0         1282.0   \n",
       "202201020402     [4.7, 7.3, 2.2]        35.2            16.8          137.9   \n",
       "202201020403     [2.7, 7.5, 2.7]        15.0            13.1           86.2   \n",
       "202201020404    [16.3, 5.6, 5.3]       144.1            46.4          500.3   \n",
       "202201020405     [2.7, 1.8, 1.5]        21.4             3.1           33.9   \n",
       "202201020406   [17.0, 30.0, 4.7]       103.7           100.0          698.3   \n",
       "202201020407    [13.1, 4.6, 6.3]        76.8            41.6          294.2   \n",
       "202201020408   [3.9, 13.5, 12.7]        13.1            43.4          180.6   \n",
       "202201020409   [29.5, 52.7, 5.5]       279.0           215.2         1774.5   \n",
       "202201020410    [6.2, 16.4, 5.1]        54.0            46.0          391.4   \n",
       "202201020411    [4.1, 10.9, 8.0]        18.8            41.9          152.1   \n",
       "202201020412    [4.0, 4.0, 10.9]        13.6            28.1           92.9   \n",
       "\n",
       "                                   wide_comb  \n",
       "202204030401      [[6, 10], [7, 10], [6, 7]]  \n",
       "202204030402        [[4, 7], [7, 9], [4, 9]]  \n",
       "202204030403      [[8, 12], [6, 12], [6, 8]]  \n",
       "202204030404    [[9, 11], [11, 13], [9, 13]]  \n",
       "202204030405      [[4, 9], [9, 11], [4, 11]]  \n",
       "202204030406      [[6, 8], [8, 14], [6, 14]]  \n",
       "202204030407      [[2, 3], [2, 10], [3, 10]]  \n",
       "202204030408    [[11, 12], [4, 11], [4, 12]]  \n",
       "202204030409  [[12, 17], [12, 18], [17, 18]]  \n",
       "202204030410        [[2, 5], [1, 5], [1, 2]]  \n",
       "202204030411  [[11, 12], [10, 12], [10, 11]]  \n",
       "202204030412  [[10, 13], [10, 11], [11, 13]]  \n",
       "202210040401        [[2, 4], [3, 4], [2, 3]]  \n",
       "202210040402        [[1, 4], [3, 4], [1, 3]]  \n",
       "202210040403      [[5, 16], [7, 16], [5, 7]]  \n",
       "202210040404    [[12, 17], [5, 17], [5, 12]]  \n",
       "202210040405        [[4, 7], [6, 7], [4, 6]]  \n",
       "202210040406      [[2, 11], [2, 8], [8, 11]]  \n",
       "202210040407      [[8, 14], [7, 14], [7, 8]]  \n",
       "202210040408      [[7, 14], [6, 14], [6, 7]]  \n",
       "202210040409        [[2, 7], [2, 3], [3, 7]]  \n",
       "202210040410      [[5, 6], [5, 14], [6, 14]]  \n",
       "202210040411      [[1, 3], [1, 16], [3, 16]]  \n",
       "202210040412        [[1, 3], [1, 9], [3, 9]]  \n",
       "202201020401    [[3, 10], [3, 12], [10, 12]]  \n",
       "202201020402      [[4, 10], [3, 4], [3, 10]]  \n",
       "202201020403      [[1, 6], [1, 10], [6, 10]]  \n",
       "202201020404      [[2, 13], [2, 4], [4, 13]]  \n",
       "202201020405        [[4, 5], [4, 6], [5, 6]]  \n",
       "202201020406        [[1, 3], [1, 4], [3, 4]]  \n",
       "202201020407      [[6, 12], [3, 6], [3, 12]]  \n",
       "202201020408    [[3, 14], [13, 14], [3, 13]]  \n",
       "202201020409        [[4, 6], [2, 4], [2, 6]]  \n",
       "202201020410    [[7, 11], [11, 13], [7, 13]]  \n",
       "202201020411        [[3, 4], [4, 9], [3, 9]]  \n",
       "202201020412        [[4, 8], [3, 4], [3, 8]]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b97e7-5e69-4334-a268-c7a57eaa10d8",
   "metadata": {},
   "source": [
    "# 日付に注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00c431-6a37-4f54-bfd3-7a1cc01780cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2022/12/31'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ec390-bc7f-4821-8417-76382d034041",
   "metadata": {},
   "source": [
    "# Results scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "131add0a-4ac5-4133-b242-3fa2109a4762",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe5bf96c80d4da6aa37813f7839c294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# race_id_list = results.index.astype('str')\n",
    "\n",
    "results_tmp = Results.scrape(race_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ac189-894a-48ac-adb2-4e731640bc5c",
   "metadata": {},
   "source": [
    "# Horse_results scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1fb495b3-1044-4b5a-afdc-cdf1b60aa6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c26aeaff064f7480dedcb213ddd5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4712 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "horse_id_list = results_tmp['horse_id'].astype(str).unique()\n",
    "horse_results_tmp = HorseResults.scrape(horse_id_list)\n",
    "\n",
    "# save_path = '/Users/rince/Desktop/Horse/Data/horse_2020.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1569216-aa8f-40a3-8303-5d54a442b00e",
   "metadata": {},
   "source": [
    "# Peds scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56d56e6b-7a60-4721-a111-892aafa204d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ef3b7f7acd491b9fa4743c3e5e5177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4712 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a31056e3e2e42b39b8ddd7aec560233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4712 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peds_2021 = Peds.scrape(horse_id_list)\n",
    "pe_2021 = Peds(peds_2021)\n",
    "pe_2021.regularize_peds()\n",
    "peds_tmp = pe_2021.peds_re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1db0da-3505-4825-8408-e7dd58205c96",
   "metadata": {},
   "source": [
    "# Return scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56a4d97d-94cc-477f-b643-5144c7173613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed7106bda2c4f6db76d7f3698f53b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "returns_tmp = Return.scrape(race_id_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e175b9a-1a2d-4d5d-a5e2-e771c86dd8d2",
   "metadata": {},
   "source": [
    "# update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "428fa2b8-2058-4c1d-af05-ec10e9f3768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = update_data(load_csv(path_win+'results.csv'),results_tmp)\n",
    "new_horse_results = update_data(load_csv(path_win+'horse_results.csv'),horse_results_tmp)\n",
    "new_peds = update_data(load_csv(path_win+'peds.csv'),peds_tmp)\n",
    "returns = load_csv(path_win+'return.csv')\n",
    "returns.rename(columns={'0':0,'1':1,'2':2,'3':3},inplace=True)\n",
    "returns_tmp.rename(columns={'0':0,'1':1,'2':2,'3':3},inplace=True)\n",
    "new_return = update_data(returns,returns_tmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77364dd-545a-43d4-97aa-070ca0595356",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "875dc8e7-f696-4b78-933d-4f62f3603430",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results.to_csv(path_win+'results.csv')\n",
    "new_horse_results.to_csv(path_win+'horse_results.csv')\n",
    "new_peds.to_csv(path_win+'peds.csv')\n",
    "new_return.to_csv(path_win+'return.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb0ca11-eae4-4d5e-b833-3184f6e85f85",
   "metadata": {},
   "source": [
    "# 重要度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f0ed3-8651-4105-aa14-83bfa45b20c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importances = pd.DataFrame(\n",
    "{'features' : x_train.columns, 'importances' : lgb_rank.feature_importance()})\n",
    "print(importances.sort_values('importances', ascending=False)[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc1142-ff9b-4568-80b8-18ef0d9010c1",
   "metadata": {},
   "source": [
    "# fastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea29d7bf-5052-44dc-ac80-dea59ed65444",
   "metadata": {},
   "source": [
    "流れ\n",
    "1. fasttext用の血統データの学習データを作る (血統の情報のみ, index ヘッダはいらない)\n",
    "2. fasttext学習\n",
    "3. 学習モデルを使って, 血統データをベクトル化\n",
    "4. ベクトル化して r.data_cに concat\n",
    "5. 学習\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d375b9-e292-4d4a-97c2-905e3060419f",
   "metadata": {},
   "source": [
    "教師あり, 教師なしでも生成されるベクトルは等しい"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de5229f-9b05-4bc1-820a-0e275a1d6c8f",
   "metadata": {},
   "source": [
    "# model_ft 作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f0c62-72c2-4a2e-b45e-b0b4d37c2e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 相対パスしかできない\n",
    "# dim : 出力の次元\n",
    "# minn : n_gramの最小単位\n",
    "# maxn : n_gramの最大単位\n",
    "path_ft = '/Users/rince/Desktop/Horse/code/horse/peds_ft.txt'\n",
    "# 上書き保存OK\n",
    "peds.to_csv(path_ft,header=False,index=False,sep=',')\n",
    "model_ft = ft.train_unsupervised(path_ft,dim=62,minn=2,maxn=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd9030-310c-414d-8c91-6178159c00e6",
   "metadata": {},
   "source": [
    "model[model.words[1]] と model.get_input_vector(ind=1) は等価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b23af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_ = [1,2,3,4,True,4]\n",
    "lis2_ = [2,3,4,5,False,5]\n",
    "dic_ = {\n",
    "}\n",
    "dic_['a'] = lis_\n",
    "dic_['b'] = lis2_\n",
    "\n",
    "df_ = pd.DataFrame(dic_).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f9f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0cc9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.rename(columns={0:'profit',1:'is_atari',2:'is_buy',3:'actual_rank',4:'not_buy_reason',5:'is_error'})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6ca01a9d29b8f49b2398e47ff0a4f0d82a4b97eff954d8fa800ff949016a671"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
