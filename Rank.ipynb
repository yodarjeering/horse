{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "485b75ae-02d8-4d3e-b0f4-c8cad9518e8c",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa116d3b-51ac-42de-bf7a-fb55eb148689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import urllib.request\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, accuracy_score,roc_curve, roc_auc_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from graphviz import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna.integration.xgboost as xgb_o\n",
    "import optuna.integration.lightgbm as lgb_o\n",
    "import scipy as sp\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import sklearn\n",
    "from scipy.special import comb\n",
    "from itertools import combinations\n",
    "import copy\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.special import comb\n",
    "from itertools import permutations\n",
    "import datetime\n",
    "import lxml\n",
    "import seaborn as sns\n",
    "from hyperopt import hp, tpe, Trials, fmin,STATUS_OK\n",
    "import fasttext as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1782806f-f29f-40fe-9c06-7dfca7dd2339",
   "metadata": {},
   "source": [
    "# path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a4008e3-1c76-4f8e-b375-0f3533379d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ubu = '/home/hipro/デスクトップ/Horse/Data/20_21'\n",
    "path_mac2 = '/Users/rince/Desktop/Horse/Data/saishin2/'\n",
    "path_mac = '/Users/rince/Desktop/Horse/Data/saishin/'\n",
    "path_win = '/Users/Owner/Desktop/program/Horse/Data/saishin/'\n",
    "path_win2 = '/Users/Owner/Desktop/program/Horse/Data/saishin2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89abdac4-ad14-4a42-a549-33a6270db233",
   "metadata": {},
   "source": [
    "# funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa496290-3b79-4e19-9f1b-a7c4a08f209c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_data(df, test_size=0.2, rank_learning=True):\n",
    "    \"\"\"\n",
    "    データを学習データと, 訓練データに分ける関数\n",
    "    \"\"\"\n",
    "    df_ = df.copy()\n",
    "    if not rank_learning:\n",
    "        df_['rank'] = df_['rank'].map(lambda x:1 if x<4 else 0)\n",
    "    sorted_id_list = df_.sort_values(\"date\").index.unique()\n",
    "    train_id_list = sorted_id_list[: round(len(sorted_id_list) * (1 - test_size))]\n",
    "    test_id_list = sorted_id_list[round(len(sorted_id_list) * (1 - test_size)) :]\n",
    "    train = df_.loc[train_id_list]#.drop(['date'], axis=1)\n",
    "    test = df_.loc[test_id_list]#.drop(['date'], axis=1)\n",
    "    return train, test\n",
    "\n",
    "def rus_data(df, test_size=0.2):\n",
    "    train, test = split_data(df,test_size=test_size)\n",
    "    x_train = train.drop(['rank', 'date','単勝'], axis=1)\n",
    "    y_train = train['rank']\n",
    "    x_test = test.drop(['rank', 'date','単勝'], axis=1)\n",
    "    y_test = test['rank']\n",
    "    \n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    x_resampled, y_resampled = rus.fit_resample(x_train, y_train)\n",
    "    return x_resampled, y_resampled, x_test, y_test\n",
    "\n",
    "def load_csv(load_path):\n",
    "    df = pd.read_csv(load_path, index_col=0)\n",
    "    return df\n",
    "\n",
    "def gain(return_func, x_, n_samples=100,lower=50,t_range=[0.5,3.5]):\n",
    "    gain = {}\n",
    "    for i in range(n_samples):\n",
    "        threshold = t_range[1] * (i/n_samples) + t_range[0] *(1-i/n_samples)\n",
    "        n_bets, return_rate, n_hits,std = return_func(x_, threshold)\n",
    "        if n_bets > lower:\n",
    "            gain[threshold] = {'return_rate':return_rate,'n_hits':n_hits,'std':std,'n_bets':n_bets}\n",
    "    return pd.DataFrame(gain).T\n",
    "\n",
    "place_dict = {\n",
    "    '札幌':'01',  '函館':'02',  '福島':'03',  '新潟':'04',  '東京':'05', \n",
    "    '中山':'06',  '中京':'07',  '京都':'08',  '阪神':'09',  '小倉':'10'\n",
    "}\n",
    "\n",
    "race_type_dict = {\n",
    "    '芝': '芝', 'ダ': 'ダート', '障': '障害'\n",
    "}\n",
    "\n",
    "def plot(g,label=''):\n",
    "    plt.fill_between(g.index,y1 = g['return_rate'] - g['std'],y2=g['return_rate']+g['std'],alpha=0.3)\n",
    "    plt.plot(g.index,g['return_rate'],label=label)\n",
    "    plt.grid(True)\n",
    "    \n",
    "def update_data(old, new):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    old : pandas.DataFrame\n",
    "        古いデータ\n",
    "    new : pandas.DataFrame\n",
    "        新しいデータ\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_old = old[~old.index.isin(new.index)]\n",
    "    return pd.concat([filtered_old, new])\n",
    "\n",
    "def scrape_race_results(race_id_list, pre_race_results={}):\n",
    "    race_results = pre_race_results\n",
    "    for race_id in race_id_list:\n",
    "        if race_id in race_results.keys():\n",
    "            continue\n",
    "        try:\n",
    "            time.sleep(0.5)\n",
    "            url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "            race_results[race_id] = pd.read_html(url)[0]\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "        except:\n",
    "            break\n",
    "    return race_results\n",
    "\n",
    "def plot_importances(xgb_model, x_test):\n",
    "    importances = pd.DataFrame(\n",
    "    {'features' : x_test.columns, 'importances' : xgb_model.feature_importances_})\n",
    "    print(importances.sort_values('importances', ascending=False)[:20])\n",
    "    \n",
    "def xgb_pred(x_train, y_train, x_test, y_test):\n",
    "    param_dist = {'objective':'binary:logistic',\n",
    "                  'n_estimators':14,\n",
    "                  'use_label_encoder':False,\n",
    "                 'max_depth':4,\n",
    "                 'random_state':100}\n",
    "    \n",
    "    best_params = {'booster': 'gbtree', \n",
    "                   'objective': 'binary:logistic',\n",
    "                   'use_label_encoder':False,\n",
    "                   'eval_metric': 'rmse', \n",
    "                   'random_state': 100, \n",
    "                   'use_label_encoder':False,\n",
    "                   'eta': 0.13449222415941048,\n",
    "                   'max_depth': 3,\n",
    "                   'lambda': 0.7223936363734638, \n",
    "                   'n_estimators': 14, \n",
    "                   'reg_alpha': 0.7879044553842869,\n",
    "                   'reg_lambda': 0.7780344172793093,\n",
    "                   'importance_type': 'gain'}\n",
    "    xgb_model = xgb.XGBClassifier(**best_params)\n",
    "    hr_pred = xgb_model.fit(x_train.astype(float), np.array(y_train), eval_metric='logloss').predict(x_test.astype(float))\n",
    "    print(\"---------------------\")\n",
    "    y_proba_train = xgb_model.predict_proba(x_train)[:,1]\n",
    "    y_proba = xgb_model.predict_proba(x_test)[:,1]\n",
    "    print('AUC train:',roc_auc_score(y_train,y_proba_train))    \n",
    "    print('AUC test :',roc_auc_score(y_test,y_proba))\n",
    "    print(classification_report(np.array(y_test), hr_pred))\n",
    "    xgb.plot_importance(xgb_model) \n",
    "    plot_importances(xgb_model, x_test)\n",
    "    return xgb_model\n",
    "\n",
    "def lgb_pred(x_train, y_train, x_test, y_test):\n",
    "    param_dist = {\n",
    "        'objective' : 'binary',\n",
    "          'random_state':100,\n",
    "                 }\n",
    "    best_params = {'objective': 'binary',\n",
    "     'metric': 'l1',\n",
    "     'verbosity': -1,\n",
    "     'boosting_type': 'gbdt',\n",
    "     'feature_pre_filter': False,\n",
    "     'lambda_l1': 0.001101158293733924,\n",
    "     'lambda_l2': 7.419556660834531e-07,\n",
    "     'num_leaves': 254,\n",
    "     'feature_fraction': 1.0,\n",
    "     'bagging_fraction': 0.9773374137350906,\n",
    "     'bagging_freq': 1,\n",
    "     'min_child_samples': 5,\n",
    "    #  'num_iterations': 200,\n",
    "    #  'early_stopping_round': 50,\n",
    "     'categorical_column': [4,\n",
    "                            5,94,95,96,97,  98,  99,  100,  101,  102,  103,  104,  105,  106,  107,  108,  109,  110,  111,  112,  113,  114,  115,  116,  117,  118,  119,  120,  121,  122,  123,  124,  125,  126,  127,  128,  129,  130,  131,  132,  133,  134,  135,  136,  137,  138,  139,  140,  141,  142,  143,  144,  145,  146,  147,  148,  149,  150,  151,  152,  153,  154,\n",
    "      155]\n",
    "                  }\n",
    "\n",
    "    lgb_model = lgb.LGBMClassifier(**best_params)\n",
    "    hr_pred = lgb_model.fit(x_train.astype(float), np.array(y_train), eval_metric='logloss').predict(x_test.astype(float))\n",
    "    print(\"---------------------\")\n",
    "    y_proba_train = lgb_model.predict_proba(x_train.astype(float))[:,1]\n",
    "    y_proba = lgb_model.predict_proba(x_test.astype(float))[:,1]\n",
    "    print('AUC train:',roc_auc_score(y_train,y_proba_train))    \n",
    "    print('AUC test :',roc_auc_score(y_test,y_proba))\n",
    "    print(classification_report(np.array(y_test), hr_pred))\n",
    "    plt.clf()\n",
    "    lgb.plot_importance(lgb_model) \n",
    "    plot_importances(lgb_model, x_test)\n",
    "    return lgb_model\n",
    "\n",
    "def make_data(data_,test_rate=0.8,is_rus=True):\n",
    "    data_ = data_.sort_values('date')\n",
    "    x_ = data_.drop(['rank','date','単勝'],axis=1)\n",
    "    y_ = data_['rank']\n",
    "\n",
    "    test_rate = int(test_rate*len(x_))\n",
    "    x_train, x_test = x_.iloc[:test_rate],x_.iloc[test_rate:]\n",
    "    y_train, y_test = y_.iloc[:test_rate],y_.iloc[test_rate:]\n",
    "    if is_rus:\n",
    "        rus = RandomUnderSampler(random_state=0)\n",
    "        x_resampled, y_resampled = rus.fit_resample(x_train, y_train)\n",
    "        return x_resampled, y_resampled, x_test, y_test\n",
    "    else:\n",
    "        return x_train,y_train,x_test,y_test\n",
    "\n",
    "def make_check_data(data_,test_rate=0.8):\n",
    "    data_ = data_.sort_values('date')\n",
    "    x_ = data_.drop(['rank','date'],axis=1)\n",
    "    y_ = data_['rank']\n",
    "\n",
    "    test_rate = int(test_rate*len(x_))\n",
    "    x_train, x_check = x_.iloc[:test_rate],x_.iloc[test_rate:]\n",
    "    y_train, y_check = y_.iloc[:test_rate],y_.iloc[test_rate:]\n",
    "\n",
    "    return x_check,y_check\n",
    "\n",
    "def grid_search(x_train,y_train,x_test,y_test):\n",
    "    trains = xgb.DMatrix(x_train.astype(float), label=y_train)\n",
    "    tests = xgb.DMatrix(x_test.astype(float), label=y_test)\n",
    "\n",
    "    base_params = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective':'binary:logistic',\n",
    "        'eval_metric': 'rmse',\n",
    "        'random_state':100,\n",
    "        'use_label_encoder':False\n",
    "    }\n",
    "\n",
    "    watchlist = [(trains, 'train'), (tests, 'eval')]\n",
    "    tmp_params = copy.deepcopy(base_params)\n",
    "    \n",
    "#     インナー関数\n",
    "    def optimizer(trial):\n",
    "        eta = trial.suggest_uniform('eta', 0.01, 0.3)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "        __lambda = trial.suggest_uniform('lambda', 0.7, 2)\n",
    "        n_estimators = trial.suggest_int('n_estimators', 3, 20)\n",
    "        learning_rate = trial.suggest_uniform('lambda', 0.01, 1)\n",
    "        reg_alpha = trial.suggest_uniform('reg_alpha', 0.01, 1)\n",
    "        reg_lambda = trial.suggest_uniform('reg_lambda', 0.01, 1)\n",
    "        importance_type = trial.suggest_categorical('importance_type',\n",
    "                                                    ['gain', 'weight', 'cover','total_gain','total_cover'])\n",
    "\n",
    "        tmp_params['eta'] = eta\n",
    "        tmp_params['max_depth'] = max_depth\n",
    "        tmp_params['lambda'] = __lambda\n",
    "        tmp_params['n_estimators'] = n_estimators\n",
    "        tmp_params['learning_rate'] = learning_rate\n",
    "        tmp_params['reg_alpha'] = reg_alpha\n",
    "        tmp_params['reg_lambda'] = reg_lambda\n",
    "        tmp_params['importance_type'] = importance_type\n",
    "        model = xgb.train(tmp_params, trains, num_boost_round=50)\n",
    "        predicts = model.predict(tests)\n",
    "        r2 = r2_score(y_test, predicts)\n",
    "        print(f'#{trial.number}, Result: {r2}, {trial.params}')\n",
    "        return r2\n",
    "    \n",
    "def predict(race_id,p,hr,r,return_tables,lgb_clf,date):\n",
    "    data =  ShutubaTable.scrape([str(race_id)], date)\n",
    "    st = ShutubaTable(data)\n",
    "    st.preprocessing()\n",
    "    st.merge_horse_results(hr)\n",
    "    st.merge_peds(p.peds_e)\n",
    "    st.process_categorical(r.le_horse, r.le_jockey, r.data_pe)\n",
    "    return_tables.rename(columns={'0':0,'1':1,'2':2,'3':3},inplace=True)\n",
    "    me_st = ModelEvaluator(lgb_clf, return_tables)\n",
    "\n",
    "    \n",
    "    #予測\n",
    "    scores = me_st.predict_proba(st.data_c.drop(['date'],axis=1),train=False)\n",
    "    pred = st.data_c[['馬番']].copy()\n",
    "    pred['scores'] = scores\n",
    "    print(pred.loc[race_id].sort_values('scores',ascending=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897b3ed-08f1-452f-bc5c-840f04015aed",
   "metadata": {},
   "source": [
    "# race_id 命名規則"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f840d19f-0d83-4c24-a9d6-245b20e6eac6",
   "metadata": {},
   "source": [
    "race_id 202105040802\\\n",
    "yyyy_pp_xx_xxrr\\\n",
    "y : year\\\n",
    "p : palce\\\n",
    "x : 謎\\\n",
    "r : race番号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d0bd9a-f85f-4949-90e8-4915a8a43ff3",
   "metadata": {},
   "source": [
    "# r.data_c['単勝'] == st.data_c[オッズ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f4a8a9-d289-4262-bbd7-e7196f6b2d2c",
   "metadata": {},
   "source": [
    "# classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27a0076-950a-49b1-9b34-5ca61c6adfcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class HorseResults:\n",
    "    def __init__(self, horse_results):\n",
    "        self.horse_results = horse_results[['日付', '着順', '賞金', '着差', '通過',\n",
    "                                            '開催', '距離']]\n",
    "        self.preprocessing()\n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.concat([pd.read_pickle(path) for path in path_list])\n",
    "        return cls(df)\n",
    "    @staticmethod\n",
    "    def scrape(horse_id_list):\n",
    "        #horse_idをkeyにしてDataFrame型を格納\n",
    "        horse_results = {}\n",
    "        for horse_id in tqdm(horse_id_list):\n",
    "#         for horse_id in horse_id_list:\n",
    "            try:\n",
    "                url = 'https://db.netkeiba.com/horse/' + horse_id\n",
    "                df = pd.read_html(url)[3]\n",
    "                #受賞歴がある馬の場合、3番目に受賞歴テーブルが来るため、4番目のデータを取得する\n",
    "                if df.columns[0]=='受賞歴':\n",
    "                    df = pd.read_html(url)[4]\n",
    "                df.index = [horse_id] * len(df)\n",
    "                horse_results[horse_id] = df\n",
    "                time.sleep(0.5)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #pd.DataFrame型にして一つのデータにまとめる        \n",
    "        horse_results_df = pd.concat([horse_results[key] for key in horse_results])\n",
    "\n",
    "        return horse_results_df\n",
    "    \n",
    "    \n",
    "    #省略\n",
    "        \n",
    "    def preprocessing(self):\n",
    "        df = self.horse_results.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"日付\"])\n",
    "        df.drop(['日付'], axis=1, inplace=True)\n",
    "        \n",
    "        #賞金のNaNを0で埋める\n",
    "        df['賞金'].fillna(0, inplace=True)\n",
    "        \n",
    "        #1着の着差を0にする\n",
    "        df['着差'] = df['着差'].map(lambda x: 0 if x<0 else x)\n",
    "        \n",
    "        #レース展開データ\n",
    "        #n=1: 最初のコーナー位置, n=4: 最終コーナー位置\n",
    "        def corner(x, n):\n",
    "            if type(x) != str:\n",
    "                return x\n",
    "            elif n==4:\n",
    "                return int(re.findall(r'\\d+', x)[-1])\n",
    "            elif n==1:\n",
    "                return int(re.findall(r'\\d+', x)[0])\n",
    "        df['first_corner'] = df['通過'].map(lambda x: corner(x, 1))\n",
    "        df['final_corner'] = df['通過'].map(lambda x: corner(x, 4))\n",
    "        \n",
    "        df['final_to_rank'] = df['final_corner'] - df['着順']\n",
    "        df['first_to_rank'] = df['first_corner'] - df['着順']\n",
    "        df['first_to_final'] = df['first_corner'] - df['final_corner']\n",
    "        \n",
    "        #開催場所\n",
    "        df['開催'] = df['開催'].str.extract(r'(\\D+)')[0].map(place_dict).fillna('11')\n",
    "        #race_type\n",
    "        df['race_type'] = df['距離'].str.extract(r'(\\D+)')[0].map(race_type_dict)\n",
    "        #距離\n",
    "        df['course_len'] = df['距離'].str.extract(r'(\\d+)').astype(int) // 100\n",
    "        df.drop(['距離'], axis=1, inplace=True)\n",
    "        \n",
    "        #インデックス名を与える\n",
    "        df.index.name = 'horse_id'\n",
    "    \n",
    "        self.horse_results = df\n",
    "        self.target_list = ['着順', '賞金', '着差', 'first_corner',\n",
    "                            'first_to_rank', 'first_to_final','final_to_rank']\n",
    "        \n",
    "        \n",
    "    def average(self, horse_id_list, date, n_samples='all'):\n",
    "        target_df = self.horse_results.query('index in @horse_id_list')\n",
    "        \n",
    "        #過去何走分取り出すか指定\n",
    "        if n_samples == 'all':\n",
    "            filtered_df = target_df[target_df['date'] < date]\n",
    "        elif n_samples > 0:\n",
    "            filtered_df = target_df[target_df['date'] < date].\\\n",
    "                sort_values('date', ascending=False).groupby(level=0).head(n_samples)\n",
    "        else:\n",
    "            raise Exception('n_samples must be >0')\n",
    "          \n",
    "        self.average_dict = {}\n",
    "        self.average_dict['non_category'] = filtered_df.groupby(level=0)[self.target_list]\\\n",
    "            .mean().add_suffix('_{}R'.format(n_samples))\n",
    "        for column in ['course_len', 'race_type', '開催']:\n",
    "            self.average_dict[column] = filtered_df.groupby(['horse_id', column])\\\n",
    "                [self.target_list].mean().add_suffix('_{}_{}R'.format(column, n_samples)).fillna(0)\n",
    "\n",
    "    \n",
    "    def merge(self, results, date, n_samples='all'):\n",
    "        df = results[results['date']==date]\n",
    "        horse_id_list = df['horse_id']\n",
    "        self.average(horse_id_list, date, n_samples)\n",
    "        merged_df = df.merge(self.average_dict['non_category'], left_on='horse_id',\n",
    "                             right_index=True, how='left')\n",
    "        for column in ['course_len','race_type', '開催']:\n",
    "            merged_df = merged_df.merge(self.average_dict[column], \n",
    "                                        left_on=['horse_id', column],\n",
    "                                        right_index=True, how='left').fillna(0)\n",
    "        return merged_df\n",
    "    \n",
    "    def merge_all(self, results, n_samples='all'):\n",
    "        date_list = results['date'].unique()\n",
    "        merged_df = pd.concat(\n",
    "            [self.merge(results, date, n_samples) for date in tqdm(date_list)]\n",
    "        )\n",
    "        return merged_df\n",
    "\n",
    "class Return:\n",
    "\n",
    "    def __init__(self, return_tables):\n",
    "        self.return_tables = return_tables\n",
    "    \n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.concat([pd.read_pickle(path) for path in path_list])\n",
    "        return cls(df)\n",
    "\n",
    "    @staticmethod\n",
    "    def scrape(race_id_list):\n",
    "        \"\"\"\n",
    "        払い戻し表データをスクレイピングする関数\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        race_id_list : list\n",
    "            レースIDのリスト\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        return_tables_df : pandas.DataFrame\n",
    "            全払い戻し表データをまとめてDataFrame型にしたもの\n",
    "        \"\"\"\n",
    "\n",
    "        return_tables = {}\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            try:\n",
    "                url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "\n",
    "                #普通にスクレイピングすると複勝やワイドなどが区切られないで繋がってしまう。\n",
    "                #そのため、改行コードを文字列brに変換して後でsplitする\n",
    "                f = urllib.request.urlopen(url)\n",
    "                html = f.read()\n",
    "                html = html.replace(b'<br />', b'br')\n",
    "                dfs = pd.read_html(html)\n",
    "\n",
    "                #dfsの1番目に単勝〜馬連、2番目にワイド〜三連単がある\n",
    "                df = pd.concat([dfs[1], dfs[2]])\n",
    "\n",
    "                df.index = [race_id] * len(df)\n",
    "                return_tables[race_id] = df\n",
    "                time.sleep(0.5)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #pd.DataFrame型にして一つのデータにまとめる\n",
    "        return_tables_df = pd.concat([return_tables[key] for key in return_tables])\n",
    "        return return_tables_df\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    @property\n",
    "    def fukusho(self):\n",
    "        fukusho = self.return_tables[self.return_tables[0]=='複勝'][[1,2]]\n",
    "        wins = fukusho[1].str.split('br', expand=True)[[0,1,2]]\n",
    "        \n",
    "        wins.columns = ['win_0', 'win_1', 'win_2']\n",
    "        returns = fukusho[2].str.split('br', expand=True)[[0,1,2]]\n",
    "        returns.columns = ['return_0', 'return_1', 'return_2']\n",
    "        \n",
    "        df = pd.concat([wins, returns], axis=1)\n",
    "        for column in df.columns:\n",
    "            df[column] = df[column].str.replace(',', '')\n",
    "        return df.fillna(0).astype(int)\n",
    "    \n",
    "    @property\n",
    "    def tansho(self):\n",
    "        tansho = self.return_tables[self.return_tables[0]=='単勝'][[1,2]]\n",
    "        tansho.columns = ['win', 'return']\n",
    "        \n",
    "        for column in tansho.columns:\n",
    "            tansho[column] = pd.to_numeric(tansho[column], errors='coerce')\n",
    "            \n",
    "        return tansho\n",
    "    \n",
    "    @property\n",
    "    def umaren(self):\n",
    "        umaren = self.return_tables[self.return_tables[0]=='馬連'][[1,2]]\n",
    "        wins = umaren[1].str.split('-', expand=True)[[0,1]].add_prefix('win_')\n",
    "        return_ = umaren[2].rename('return')  \n",
    "        df = pd.concat([wins, return_], axis=1)        \n",
    "        return df.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    \n",
    "    @property\n",
    "    def umatan(self):\n",
    "        umatan = self.return_tables[self.return_tables[0]=='馬単'][[1,2]]\n",
    "        wins = umatan[1].str.split('→', expand=True)[[0,1]].add_prefix('win_')\n",
    "        return_ = umatan[2].rename('return')  \n",
    "        df = pd.concat([wins, return_], axis=1)        \n",
    "        return df.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    \n",
    "    @property\n",
    "    def wide(self):\n",
    "        wide = self.return_tables[self.return_tables[0]=='ワイド'][[1,2]]\n",
    "        wins = wide[1].str.split('br', expand=True)[[0,1,2]]\n",
    "        wins = wins.stack().str.split('-', expand=True).add_prefix('win_')\n",
    "        return_ = wide[2].str.split('br', expand=True)[[0,1,2]]\n",
    "        return_ = return_.stack().rename('return')\n",
    "        df = pd.concat([wins, return_], axis=1)\n",
    "        return df.apply(lambda x: pd.to_numeric(x.str.replace(',',''), errors='coerce'))\n",
    "    \n",
    "    @property\n",
    "    def sanrentan(self):\n",
    "        rentan = self.return_tables[self.return_tables[0]=='三連単'][[1,2]]\n",
    "        wins = rentan[1].str.split('→', expand=True)[[0,1,2]].add_prefix('win_')\n",
    "        return_ = rentan[2].rename('return')\n",
    "        df = pd.concat([wins, return_], axis=1) \n",
    "        return df.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    \n",
    "    @property\n",
    "    def sanrenpuku(self):\n",
    "        renpuku = self.return_tables[self.return_tables[0]=='三連複'][[1,2]]\n",
    "        wins = renpuku[1].str.split('-', expand=True)[[0,1,2]].add_prefix('win_')\n",
    "        return_ = renpuku[2].rename('return')\n",
    "        df = pd.concat([wins, return_], axis=1) \n",
    "        return df.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    \n",
    "class ModelEvaluator:\n",
    "\n",
    "    \n",
    "    def __init__(self, model, return_tables):\n",
    "        self.model = model\n",
    "        self.rt = Return(return_tables)\n",
    "        self.fukusho = self.rt.fukusho\n",
    "        self.tansho = self.rt.tansho\n",
    "        self.umaren = self.rt.umaren\n",
    "        self.umatan = self.rt.umatan\n",
    "        self.wide = self.rt.wide\n",
    "        self.sanrenpuku = self.rt.sanrenpuku\n",
    "        self.sanrentan = self.rt.sanrentan\n",
    "\n",
    "    \n",
    "    #3着以内に入る確率を予測\n",
    "    def predict_proba(self, X, train=True, std=True, minmax=False):\n",
    "        if train:\n",
    "            proba = pd.Series(\n",
    "                self.model.predict_proba(X.drop(['単勝'], axis=1))[:, 1], index=X.index\n",
    "            )\n",
    "        else:\n",
    "            proba = pd.Series(\n",
    "                self.model.predict_proba(X, axis=1)[:, 1], index=X.index\n",
    "            )\n",
    "        if std:\n",
    "            #レース内で標準化して、相対評価する。「レース内偏差値」みたいなもの。\n",
    "            standard_scaler = lambda x: (x - x.mean()) / x.std()\n",
    "            proba = proba.groupby(level=0).transform(standard_scaler)\n",
    "        if minmax:\n",
    "            #データ全体を0~1にする\n",
    "            proba = (proba - proba.min()) / (proba.max() - proba.min())\n",
    "        return proba\n",
    "    \n",
    "    #0か1かを予測\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        y_pred = self.predict_proba(X)\n",
    "        self.proba = y_pred\n",
    "        return [0 if p<threshold else 1 for p in y_pred]\n",
    "    \n",
    "    def score(self, y_true, X):\n",
    "        return roc_auc_score(y_true, self.predict_proba(X))\n",
    "    \n",
    "    def feature_importance(self, X, n_display=20):\n",
    "        importances = pd.DataFrame({\"features\": X.columns, \n",
    "                                    \"importance\": self.model.feature_importances_})\n",
    "        return importances.sort_values(\"importance\", ascending=False)[:n_display]\n",
    "    \n",
    "    def pred_table(self, X, threshold=0.5, bet_only=True):\n",
    "        pred_table = X.copy()[['馬番', '単勝']]\n",
    "        pred_table['pred'] = self.predict(X, threshold)\n",
    "        pred_table['score'] = self.proba\n",
    "        if bet_only:\n",
    "            return pred_table[pred_table['pred']==1][['馬番', '単勝', 'score','pred']]\n",
    "        else:\n",
    "            return pred_table[['馬番', '単勝', 'score', 'pred']]\n",
    "        \n",
    "    def bet(self, race_id, kind, umaban, amount):\n",
    "        if kind == 'fukusho':\n",
    "            rt_1R = self.fukusho.loc[race_id]\n",
    "            return_ = (rt_1R[['win_0', 'win_1', 'win_2']]==umaban).values * \\\n",
    "                rt_1R[['return_0', 'return_1', 'return_2']].values * amount/100\n",
    "            return_ = np.sum(return_)\n",
    "        if kind == 'tansho':\n",
    "            rt_1R = self.tansho.loc[race_id]\n",
    "            return_ = (rt_1R['win']==umaban) * rt_1R['return'] * amount/100\n",
    "        if kind == 'umaren':\n",
    "            rt_1R = self.umaren.loc[race_id]\n",
    "            return_ = (set(rt_1R[['win_0', 'win_1']]) == set(umaban)) \\\n",
    "                * rt_1R['return']/100 * amount\n",
    "        if kind == 'umatan':\n",
    "            rt_1R = self.umatan.loc[race_id]\n",
    "            return_ = (list(rt_1R[['win_0', 'win_1']]) == list(umaban))\\\n",
    "                * rt_1R['return']/100 * amount\n",
    "        if kind == 'wide':\n",
    "            rt_1R = self.wide.loc[race_id]\n",
    "            return_ = (rt_1R[['win_0', 'win_1']].\\\n",
    "                           apply(lambda x: set(x)==set(umaban), axis=1)) \\\n",
    "                * rt_1R['return']/100 * amount\n",
    "            return_ = return_.sum()\n",
    "        if kind == 'sanrentan':\n",
    "            rt_1R = self.sanrentan.loc[race_id]\n",
    "            return_ = (list(rt_1R[['win_0', 'win_1', 'win_2']]) == list(umaban)) * \\\n",
    "                rt_1R['return']/100 * amount\n",
    "        if kind == 'sanrenpuku':\n",
    "            rt_1R = self.sanrenpuku.loc[race_id]\n",
    "            return_ = (set(rt_1R[['win_0', 'win_1', 'win_2']]) == set(umaban)) \\\n",
    "                * rt_1R['return']/100 * amount\n",
    "        if not (return_ >= 0):\n",
    "                return_ = amount\n",
    "        return return_\n",
    "        \n",
    "    def fukusho_return(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_list.append(np.sum([\n",
    "                self.bet(race_id, 'fukusho', umaban, 1) for umaban in preds['馬番']\n",
    "            ]))\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def tansho_return(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        self.sample = pred_table\n",
    "        n_bets = len(pred_table)\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_list.append(\n",
    "                np.sum([self.bet(race_id, 'tansho', umaban, 1) for umaban in preds['馬番']])\n",
    "            )\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def tansho_return_proper(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_list.append(\n",
    "                np.sum(preds.apply(lambda x: self.bet(\n",
    "                    race_id, 'tansho', x['馬番'], 1/x['単勝']), axis=1)))\n",
    "        \n",
    "        bet_money = (1 / pred_table['単勝']).sum()\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / bet_money\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / bet_money\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def umaren_box(self, X, threshold=0.5, n_aite=5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(preds_jiku['馬番'], 2):\n",
    "                    return_ += self.bet(race_id, 'umaren', umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def umatan_box(self, X, threshold=0.5, n_aite=5):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue   \n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in permutations(preds_jiku['馬番'], 2):\n",
    "                    return_ += self.bet(race_id, 'umatan', umaban, 1)\n",
    "                    n_bets += 1\n",
    "            return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def wide_box(self, X, threshold=0.5, n_aite=5):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(preds_jiku['馬番'], 2):\n",
    "                    return_ += self.bet(race_id, 'wide', umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std  \n",
    "        \n",
    "    def sanrentan_box(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            if len(preds)<3:\n",
    "                continue\n",
    "            else:\n",
    "                for umaban in permutations(preds['馬番'], 3):\n",
    "                    return_ += self.bet(race_id, 'sanrentan', umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def sanrenpuku_box(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            if len(preds)<3:\n",
    "                continue\n",
    "            else:\n",
    "                for umaban in combinations(preds['馬番'], 3):\n",
    "                    return_ += self.bet(race_id, 'sanrenpuku', umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def umaren_nagashi(self, X, threshold=0.5, n_aite=5):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                preds_aite = preds.sort_values('score', ascending = False)\\\n",
    "                    .iloc[1:(n_aite+1)]['馬番']\n",
    "                return_ = preds_aite.map(\n",
    "                    lambda x: self.bet(\n",
    "                        race_id, 'umaren', [preds_jiku['馬番'].values[0], x], 1\n",
    "                    )\n",
    "                ).sum()\n",
    "                n_bets += n_aite\n",
    "                return_list.append(return_)\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(preds_jiku['馬番'], 2):\n",
    "                    return_ += self.bet(race_id, 'umaren', umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def umatan_nagashi(self, X, threshold=0.5, n_aite=5):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                preds_aite = preds.sort_values('score', ascending = False)\\\n",
    "                    .iloc[1:(n_aite+1)]['馬番']\n",
    "                return_ = preds_aite.map(\n",
    "                    lambda x: self.bet(\n",
    "                        race_id, 'umatan', [preds_jiku['馬番'].values[0], x], 1\n",
    "                    )\n",
    "                ).sum()\n",
    "                n_bets += n_aite\n",
    "                \n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in permutations(preds_jiku['馬番'], 2):\n",
    "                    return_ += self.bet(race_id, 'umatan', umaban, 1)\n",
    "                    n_bets += 1\n",
    "            return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def wide_nagashi(self, X, threshold=0.5, n_aite=5):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                preds_aite = preds.sort_values('score', ascending = False)\\\n",
    "                    .iloc[1:(n_aite+1)]['馬番']\n",
    "                return_ = preds_aite.map(\n",
    "                    lambda x: self.bet(\n",
    "                        race_id, 'wide', [preds_jiku['馬番'].values[0], x], 1\n",
    "                    )\n",
    "                ).sum()\n",
    "                n_bets += len(preds_aite)\n",
    "                return_list.append(return_)\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(preds_jiku['馬番'], 2):\n",
    "                    return_ += self.bet(race_id, 'wide', umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def sanrentan_nagashi(self, X, threshold = 1.5, n_aite=7):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "        n_bets = 0\n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue\n",
    "            elif len(preds_jiku) == 2:\n",
    "                preds_aite = preds.sort_values('score', ascending = False)\\\n",
    "                    .iloc[2:(n_aite+2)]['馬番']\n",
    "                return_ = preds_aite.map(\n",
    "                    lambda x: self.bet(\n",
    "                        race_id, 'sanrentan',\n",
    "                        np.append(preds_jiku['馬番'].values, x),\n",
    "                        1\n",
    "                    )\n",
    "                ).sum()\n",
    "                n_bets += len(preds_aite)\n",
    "                return_list.append(return_)\n",
    "            elif len(preds_jiku) >= 3:\n",
    "                return_ = 0\n",
    "                for umaban in permutations(preds_jiku['馬番'], 3):\n",
    "                    return_ += self.bet(race_id, 'sanrentan', umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "class DataProcessor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = pd.DataFrame() #raw data\n",
    "        self.data_p = pd.DataFrame() #after preprocessing\n",
    "        self.data_h = pd.DataFrame() #after merging horse_results\n",
    "        self.data_pe = pd.DataFrame() #after merging peds\n",
    "        self.data_c = pd.DataFrame() #after processing categorical features\n",
    "        \n",
    "    #馬の過去成績データの追加\n",
    "    def merge_horse_results(self, hr, n_samples_list=[5, 9, 'all']):\n",
    "        self.data_h = self.data_p.copy()\n",
    "        for n_samples in n_samples_list:\n",
    "            self.data_h = hr.merge_all(self.data_h, n_samples=n_samples)\n",
    "        self.data_h.drop(['開催'], axis=1, inplace=True)\n",
    "            \n",
    "    #血統データ追加\n",
    "    def merge_peds(self, peds):\n",
    "        self.data_pe = self.data_h.merge(peds, left_on='horse_id', right_index=True,how='left')\n",
    "#         重複データを削除\n",
    "        self.data_pe = self.data_pe[~self.data_pe.duplicated()]\n",
    "        self.no_peds = self.data_pe[self.data_pe['peds_0'].isnull()]['horse_id'].unique()\n",
    "#         print(\"type :\",type(self.no_peds)) ndarray\n",
    "#         Peds.scrape()\n",
    "        if len(self.no_peds) > 0:\n",
    "            print('scrape peds at horse_id_list \"no_peds\"')\n",
    "            \n",
    "        #カテゴリ変数の処理\n",
    "    def process_categorical(self, le_horse, le_jockey,results_m):\n",
    "        df = self.data_pe.copy()\n",
    "        \n",
    "        #ラベルエンコーディング。horse_id, jockey_idを0始まりの整数に変換\n",
    "        mask_horse = df['horse_id'].isin(le_horse.classes_)\n",
    "        new_horse_id = df['horse_id'].mask(mask_horse).dropna().unique()\n",
    "        le_horse.classes_ = np.concatenate([le_horse.classes_, new_horse_id])\n",
    "        df['horse_id'] = le_horse.transform(df['horse_id'])\n",
    "        \n",
    "        mask_jockey = df['jockey_id'].isin(le_jockey.classes_)\n",
    "        new_jockey_id = df['jockey_id'].mask(mask_jockey).dropna().unique()\n",
    "        le_jockey.classes_ = np.concatenate([le_jockey.classes_, new_jockey_id])\n",
    "        df['jockey_id'] = le_jockey.transform(df['jockey_id'])\n",
    "#         pedsデータのラベルエンコーディング\n",
    "\n",
    "#         for column in p.peds_e.columns:\n",
    "# #             self.le_peds_dict[column] = LabelEncoder().fit_transform(df[column].fillna('Na'))\n",
    "# #             mask_peds = df[column].isin(p.le_peds[column].classes_)\n",
    "#             new_peds_id = df[column].dropna().unique()\n",
    "# #             p.le_peds[column].classes_ = np.concatenate([p.le_peds[column].classes_, new_peds_id])\n",
    "#             df[column] = p.le_peds[column].transform(df[column])\n",
    "        \n",
    "        \n",
    "        #horse_id, jockey_idをpandasのcategory型に変換\n",
    "        df['horse_id'] = df['horse_id'].astype('category')\n",
    "        df['jockey_id'] = df['jockey_id'].astype('category')\n",
    "        \n",
    "        #そのほかのカテゴリ変数をpandasのcategory型に変換してからダミー変数化\n",
    "        #列を一定にするため\n",
    "        weathers = results_m['weather'].unique()\n",
    "        race_types = results_m['race_type'].unique()\n",
    "        ground_states = results_m['ground_state'].unique()\n",
    "        sexes = results_m['性'].unique()\n",
    "        df['weather'] = pd.Categorical(df['weather'], weathers)\n",
    "        df['race_type'] = pd.Categorical(df['race_type'], race_types)\n",
    "        df['ground_state'] = pd.Categorical(df['ground_state'], ground_states)\n",
    "        df['性'] = pd.Categorical(df['性'], sexes)\n",
    "        df = pd.get_dummies(df, columns=['weather', 'race_type', 'ground_state', '性'])\n",
    "        \n",
    "        self.data_c = df    \n",
    "    \n",
    "class ShutubaTable(DataProcessor):\n",
    "    \n",
    "    \n",
    "    def __init__(self, shutuba_tables):\n",
    "        super(ShutubaTable, self).__init__()\n",
    "        self.data = shutuba_tables\n",
    "    \n",
    "    @classmethod\n",
    "    def scrape(cls, race_id_list, date):\n",
    "        data = pd.DataFrame()\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            url = 'https://race.netkeiba.com/race/shutuba.html?race_id=' + race_id\n",
    "            df = pd.read_html(url)[0]\n",
    "            df = df.T.reset_index(level=0, drop=True).T\n",
    "\n",
    "            html = requests.get(url)\n",
    "            html.encoding = \"EUC-JP\"\n",
    "            soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "\n",
    "            texts = soup.find('div', attrs={'class': 'RaceData01'}).text\n",
    "            texts = re.findall(r'\\w+', texts)\n",
    "            for text in texts:\n",
    "                if 'm' in text:\n",
    "                    df['course_len'] = [int(re.findall(r'\\d+', text)[0])] * len(df)\n",
    "                if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                    df[\"weather\"] = [text] * len(df)\n",
    "                if text in [\"良\", \"稍重\", \"重\",\"稍\"]:\n",
    "                    df[\"ground_state\"] = [text] * len(df)\n",
    "                if '不' in text:\n",
    "                    df[\"ground_state\"] = ['不良'] * len(df)\n",
    "                if '芝' in text:\n",
    "                    df['race_type'] = ['芝'] * len(df)\n",
    "                if '障' in text:\n",
    "                    df['race_type'] = ['障害'] * len(df)\n",
    "                if 'ダ' in text:\n",
    "                    df['race_type'] = ['ダート'] * len(df)\n",
    "            df['date'] = [date] * len(df)\n",
    "\n",
    "            # horse_id\n",
    "            horse_id_list = []\n",
    "            horse_td_list = soup.find_all(\"td\", attrs={'class': 'HorseInfo'})\n",
    "            for td in horse_td_list:\n",
    "                horse_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                horse_id_list.append(horse_id)\n",
    "            # jockey_id\n",
    "            jockey_id_list = []\n",
    "            jockey_td_list = soup.find_all(\"td\", attrs={'class': 'Jockey'})\n",
    "            for td in jockey_td_list:\n",
    "                jockey_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                jockey_id_list.append(jockey_id)\n",
    "            df['horse_id'] = list(map(lambda x: int(x),horse_id_list)) \n",
    "            df['jockey_id'] = jockey_id_list\n",
    "\n",
    "            df.index = [race_id] * len(df)\n",
    "#             win 環境だとなぜかintに直せない.floatならつかえる\n",
    "            df.index = df.index.astype(int)\n",
    "            data = data.append(df)\n",
    "\n",
    "            \n",
    "        return data\n",
    "                \n",
    "    def preprocessing(self):\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "        df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "#         体重変化をデータから消した\n",
    "        # 馬体重を体重と体重変化に分ける\n",
    "        df = df[df[\"馬体重(増減)\"] != '--']\n",
    "        df[\"体重\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[0].astype(int)\n",
    "        df[\"体重変化\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[1].str[:-1].replace('前計不',0).astype(int)\n",
    "\n",
    "\n",
    "        \n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        \n",
    "        df['枠'] = df['枠'].astype(int)\n",
    "        df['馬番'] = df['馬番'].astype(int)\n",
    "        df['斤量'] = df['斤量'].astype(int)\n",
    "        df['開催'] = df.index.map(lambda x:str(x)[4:6])\n",
    "        df['n_horse'] = df.index.map(lambda x: len(df.loc[x]))\n",
    "\n",
    "        # 不要な列を削除\n",
    "        df = df[['枠', '馬番', '斤量', 'course_len', 'weather','race_type',\n",
    "        'ground_state', 'date', 'horse_id', 'jockey_id', '性', '年齢','開催','n_horse','体重','体重変化']]\n",
    "        \n",
    "        self.data_p = df.rename(columns={'枠': '枠番'})\n",
    "        \n",
    "class Results(DataProcessor):\n",
    "    def __init__(self, results):\n",
    "        super(Results, self).__init__()\n",
    "        self.data = results\n",
    "        self.le_peds = None\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def scrape(race_id_list):\n",
    "        #race_idをkeyにしてDataFrame型を格納\n",
    "        race_results = {}\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            time.sleep(0.5)\n",
    "            try:\n",
    "                url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "                #メインとなるテーブルデータを取得\n",
    "                df = pd.read_html(url)[0]\n",
    "                html = requests.get(url)\n",
    "                html.encoding = \"EUC-JP\"\n",
    "                soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "\n",
    "                #天候、レースの種類、コースの長さ、馬場の状態、日付をスクレイピング\n",
    "                texts = (\n",
    "                    soup.find(\"div\", attrs={\"class\": \"data_intro\"}).find_all(\"p\")[0].text\n",
    "                    + soup.find(\"div\", attrs={\"class\": \"data_intro\"}).find_all(\"p\")[1].text\n",
    "                )\n",
    "                info = re.findall(r'\\w+', texts)\n",
    "                for text in info:\n",
    "                    if text in [\"芝\", \"ダート\"]:\n",
    "                        df[\"race_type\"] = [text] * len(df)\n",
    "                    if \"障\" in text:\n",
    "                        df[\"race_type\"] = [\"障害\"] * len(df)\n",
    "                    if \"m\" in text:\n",
    "                        df[\"course_len\"] = [int(re.findall(r\"\\d+\", text)[0])] * len(df)\n",
    "                    if text in [\"良\", \"稍重\", \"重\", \"不良\"]:\n",
    "                        df[\"ground_state\"] = [text] * len(df)\n",
    "                    if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                        df[\"weather\"] = [text] * len(df)\n",
    "                    if \"年\" in text:\n",
    "                        df[\"date\"] = [text] * len(df)\n",
    "\n",
    "                #馬ID、騎手IDをスクレイピング\n",
    "                horse_id_list = []\n",
    "                horse_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\n",
    "                    \"a\", attrs={\"href\": re.compile(\"^/horse\")}\n",
    "                )\n",
    "                for a in horse_a_list:\n",
    "                    horse_id = re.findall(r\"\\d+\", a[\"href\"])\n",
    "                    horse_id_list.append(horse_id[0])\n",
    "                jockey_id_list = []\n",
    "                jockey_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\n",
    "                    \"a\", attrs={\"href\": re.compile(\"^/jockey\")}\n",
    "                )\n",
    "                for a in jockey_a_list:\n",
    "                    jockey_id = re.findall(r\"\\d+\", a[\"href\"])\n",
    "                    jockey_id_list.append(jockey_id[0])\n",
    "                df[\"horse_id\"] = horse_id_list\n",
    "                df[\"jockey_id\"] = jockey_id_list\n",
    "\n",
    "                #インデックスをrace_idにする\n",
    "                df.index = [race_id] * len(df)\n",
    "\n",
    "                race_results[race_id] = df\n",
    "            #存在しないrace_idを飛ばす\n",
    "            except IndexError:\n",
    "                continue\n",
    "            #wifiの接続が切れた時などでも途中までのデータを返せるようにする\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            #Jupyterで停止ボタンを押した時の対処\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #pd.DataFrame型にして一つのデータにまとめる\n",
    "        race_results_df = pd.concat([race_results[key] for key in race_results])\n",
    "\n",
    "        return race_results_df\n",
    "        \n",
    "    #前処理    \n",
    "    def preprocessing(self):\n",
    "        df = self.data.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "#         rank学習の場合はそのまま\n",
    "#         df['rank'] = df['着順'].map(lambda x:1 if x<4 else 0)\n",
    "        df['rank'] = df['着順']\n",
    "\n",
    "        # 性齢を性と年齢に分ける\n",
    "        df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "        df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "        # 馬体重を体重と体重変化に分ける\n",
    "        df[\"体重\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[0].astype(int)\n",
    "        df[\"体重変化\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[1].str[:-1].astype(int)\n",
    "\n",
    "        # データをint, floatに変換\n",
    "        df[\"単勝\"] = df[\"単勝\"].astype(float)\n",
    "        df[\"course_len\"] = df[\"course_len\"].astype(float) // 100\n",
    "\n",
    "        # 不要な列を削除\n",
    "        df.drop([\"タイム\", \"着差\", \"調教師\", \"性齢\", \"馬体重\", '馬名', '騎手', '人気', '着順'],\n",
    "                axis=1, inplace=True)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y年%m月%d日\")\n",
    "        \n",
    "        #開催場所\n",
    "        df['開催'] = df.index.map(lambda x:str(x)[4:6])\n",
    "        df['n_horse'] = df.index.map(lambda x: len(df.loc[x]))\n",
    "        \n",
    "        self.data_p = df\n",
    "    \n",
    "    #カテゴリ変数の処理\n",
    "    def process_categorical(self):\n",
    "        self.le_horse = LabelEncoder().fit(self.data_pe['horse_id'])\n",
    "        self.le_jockey = LabelEncoder().fit(self.data_pe['jockey_id'])\n",
    "#         self.le_peds = p.le_peds_dict\n",
    "        super().process_categorical(self.le_horse, self.le_jockey,self.data_pe)\n",
    "        \n",
    "class Peds:\n",
    "\n",
    "    def __init__(self, peds):\n",
    "        self.peds = peds\n",
    "        self.peds_cat = pd.DataFrame() #after label encoding and transforming into category\n",
    "        self.peds_re = pd.DataFrame()\n",
    "        self.peds_vec = pd.DataFrame()\n",
    "    \n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.concat([pd.read_pickle(path) for path in path_list])\n",
    "        return cls(df)\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape(horse_id_list):\n",
    "        peds_dict = {}\n",
    "        for horse_id in tqdm(horse_id_list):\n",
    "#         for horse_id in horse_id_list:\n",
    "            try:\n",
    "                url = \"https://db.netkeiba.com/horse/ped/\" + horse_id\n",
    "            \n",
    "                df = pd.read_html(url)[0]\n",
    "\n",
    "                #重複を削除して1列のSeries型データに直す\n",
    "                generations = {}\n",
    "                for i in reversed(range(5)):\n",
    "                    generations[i] = df[i]\n",
    "                    df.drop([i], axis=1, inplace=True)\n",
    "                    df = df.drop_duplicates()\n",
    "                ped = pd.concat([generations[i] for i in range(5)]).rename(horse_id)\n",
    "\n",
    "                peds_dict[horse_id] = ped.reset_index(drop=True)\n",
    "                time.sleep(0.5)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #列名をpeds_0, ..., peds_61にする\n",
    "        peds_df = pd.concat([peds_dict[key] for key in peds_dict],\n",
    "                            axis=1).T.add_prefix('peds_')\n",
    "        peds_df.index =peds_df.index.astype(int)\n",
    "\n",
    "        return peds_df\n",
    "    \n",
    "    \n",
    "#     血統データが正規化されたいないデータに対して, 正規化する関数\n",
    "    def regularize_peds(self):\n",
    "        peds = self.peds.copy()\n",
    "        error_idx_list = []\n",
    "        for idx in tqdm(peds.index):\n",
    "            for col in peds.columns:\n",
    "            #     漢字 : 一-龥\n",
    "                code_regex = re.compile('[!\"#$%&\\'\\\\\\\\()*+,-./:;<=>?@[\\\\]^_`{|}~「」〔〕“”〈〉『』【】＆＊・（）＄＃＠。、？！｀＋￥％一-龥\\d]')\n",
    "                try:\n",
    "                    cleaned_text = code_regex.sub('', peds[col].loc[idx])\n",
    "                    one_word = \"\".join(cleaned_text.split())\n",
    "                    p_alphabet = re.compile('[a-zA-Z]+')\n",
    "                    p_katakana = re.compile(r'[ァ-ヶー]+')\n",
    "\n",
    "                    peds[col].loc[idx] = one_word\n",
    "                    if (not p_alphabet.fullmatch(one_word)) and not (p_katakana.fullmatch(one_word)):\n",
    "                        peds[col].loc[idx] = re.sub('[a-zA-Z]+', '', one_word)\n",
    "                except:\n",
    "                    error_idx_list.append(idx)\n",
    "        self.error_idx_list_r = error_idx_list\n",
    "        self.peds_re = peds\n",
    "\n",
    "    \n",
    "    def categorize(self):\n",
    "        df = self.peds.copy()\n",
    "        self.le_peds_dict = {}\n",
    "        \n",
    "        \n",
    "        for column in df.columns:\n",
    "            \n",
    "            self.le_peds_dict[column] = LabelEncoder()\n",
    "            df[column] = self.le_peds_dict[column].fit_transform(df[column].fillna('Na'))\n",
    "#             df[column] = self.le_peds_dict[column]\n",
    "        self.peds_cat = df.astype('category')\n",
    "        self.le_peds = self.le_peds_dict\n",
    "        \n",
    "        \n",
    "#         血統データをベクトル化する関数\n",
    "# peds_re は 正規化済み血統データを仮定\n",
    "# model_ft : fasttextモデル\n",
    "    def vectorize(self,peds_re,model_ft):\n",
    "        df = peds_re.copy()\n",
    "        error_idx_list = []\n",
    "        for idx in tqdm(df.index):\n",
    "            text = ','.join(df.loc[idx].tolist())\n",
    "            df.loc[idx] = model_ft[text]\n",
    "#             except:\n",
    "#                 error_idx_list.append(idx)\n",
    "        self.error_idx_list_v = error_idx_list\n",
    "        self.peds_vec = df.astype('float')\n",
    "#     def vectorize(self,peds_re,model_ft):\n",
    "#         df = peds_re.copy()\n",
    "        \n",
    "#         for idx in tqdm(df.index):\n",
    "#             for column in df.columns:\n",
    "#                 horse_name = df[column].loc[idx]\n",
    "#                 df[column].loc[idx] = model_ft[horse_name][0]\n",
    "\n",
    "#         self.peds_vec = df.astype('float')\n",
    "\n",
    "class Simulater():\n",
    "    \n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.return_tables = None\n",
    "        self.pred_df = None\n",
    "    \n",
    "\n",
    "    #     当日のデータでシミュレートするとあかん\n",
    "    def return_table(self, race_id_list):\n",
    "        return_tables = Return.scrape(race_id_list)\n",
    "        return_tables.rename(columns={'0':0,'1':1,'2':2,'3':3},inplace=True)\n",
    "        self.return_tables = return_tables\n",
    "    \n",
    "    \n",
    "    def return_table_today(self,race_id_list):\n",
    "        return_tables = {}\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            try:\n",
    "                url = 'https://race.netkeiba.com/race/result.html?race_id='+race_id+'&amp;rf=race_submenu'\n",
    "                dfs = pd.read_html(url)\n",
    "                df = pd.concat([dfs[1], dfs[2]])\n",
    "                df.index = [race_id] * len(df)\n",
    "                return_tables[race_id] = df\n",
    "                time.sleep(0.5)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "            #pd.DataFrame型にして一つのデータにまとめる\n",
    "        return_tables_df = pd.concat([return_tables[key] for key in return_tables])\n",
    "        # return_tables_df.index = return_tables_df.index.astype(int)\n",
    "        self.return_tables = return_tables_df\n",
    "    \n",
    "   \n",
    "    def return_pred_table(self,st,return_tables):\n",
    "        me_st = ModelEvaluator(self.model, return_tables)\n",
    "        #予測\n",
    "        scores = me_st.predict_proba(st.data_c.drop(['date'],axis=1),train=False)\n",
    "        pred = st.data_c[['馬番']].copy()\n",
    "        pred['scores'] = scores\n",
    "        pred.index = pred.index.astype(int)\n",
    "        return pred\n",
    "        \n",
    "        \n",
    "    def show_results(self , st ,race_id_list ,bet = 100):\n",
    "        self.return_table_today(race_id_list)\n",
    "        return_tables = self.return_tables.copy()\n",
    "        acc_dict = {'単勝':0,'複勝':0,'ワイド':0}\n",
    "        return_dict = {'単勝':0,'複勝':0,'ワイド':0}\n",
    "        target_race_dict = {}\n",
    "        self.pred_df = self.return_pred_table(st,return_tables)\n",
    "        tansho_list = []\n",
    "        fukusho_list = []\n",
    "        wide_list =[]\n",
    "\n",
    "        for race_id in race_id_list:\n",
    "            df_  = self.return_tables.loc[int(race_id)]\n",
    "            print(\"-------------------\")\n",
    "            print(\"predict\")\n",
    "            pred_df = self.pred_df.loc[int(race_id)]\n",
    "            pred_df = pred_df.sort_values('scores',ascending=False)\n",
    "            print(pred_df.iloc[:3])\n",
    "            print(\"actual\")\n",
    "            print(self.return_tables.loc[race_id])\n",
    "            pred_1 = str(pred_df['馬番'].iloc[0])\n",
    "            pred_2 = str(pred_df['馬番'].iloc[1])\n",
    "\n",
    "\n",
    "            if  pred_1 == df_[df_[0]=='単勝'][1].values[0]:\n",
    "                acc_dict['単勝'] += 1\n",
    "                profit = int(df_[df_[0]=='単勝'][2].values[0].replace('円','').replace(',',''))\n",
    "                return_dict['単勝'] += profit\n",
    "                acc_dict['複勝'] += 1\n",
    "                return_index = df_[df_[0]=='複勝'][1].str.split(' ')[0].index(str(pred_1))\n",
    "                profit = int(df_[df_[0]=='複勝'][2].str.split('円')[0][return_index].replace(',',''))\n",
    "                return_dict['複勝'] += profit \n",
    "                tansho_list.append(race_id[-2:])\n",
    "                fukusho_list.append(race_id[-2:])\n",
    "\n",
    "            elif pred_1 in df_[df_[0]=='複勝'][1].str.split(' ')[0]:\n",
    "                acc_dict['複勝'] += 1\n",
    "                return_index = df_[df_[0]=='複勝'][1].str.split(' ')[0].index(str(pred_1))\n",
    "                profit = int(df_[df_[0]=='複勝'][2].str.split('円')[0][return_index].replace(',',''))\n",
    "                return_dict['複勝'] += profit \n",
    "                fukusho_list.append(race_id[-2:])\n",
    "                \n",
    "\n",
    "            for i in range(len(df_[df_[0]=='ワイド'][1].str.split(' ')[0])//2):\n",
    "                if set([pred_1,pred_2])==set(df_[df_[0]=='ワイド'][1].str.split(' ')[0][i:i+2]):\n",
    "                    if i!=0:\n",
    "                        return_index = i-1\n",
    "                    else:\n",
    "                        return_index = i\n",
    "                    profit = int(df_[df_[0]=='ワイド'][2].str.split('円')[0][return_index].replace(',',''))\n",
    "                    return_dict['ワイド'] += profit\n",
    "                    print(\"profit\",profit)\n",
    "                    acc_dict['ワイド'] += 1\n",
    "                    wide_list.append(race_id[-2:])\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        for i, key in enumerate(acc_dict):\n",
    "            return_dict[key] -= bet * len(race_id_list)\n",
    "        \n",
    "        print(\"---------------------\")\n",
    "        print(\"単勝\")\n",
    "        print(\"的中率 :\",acc_dict['単勝'],'/',len(race_id_list))\n",
    "        print(\"収支   :\",return_dict['単勝'],'円')\n",
    "        print(\"的中レース\",tansho_list)\n",
    "        print(\"---------------------\")\n",
    "        print(\"複勝\")\n",
    "        print(\"的中率 :\",acc_dict['複勝'],'/',len(race_id_list))\n",
    "        print(\"収支   :\",return_dict['複勝'],'円')\n",
    "        print(\"的中レース\",fukusho_list)\n",
    "        print(\"---------------------\")\n",
    "        print(\"ワイド\")\n",
    "        print(\"的中率 :\",acc_dict['ワイド'],'/',len(race_id_list))\n",
    "        print(\"収支   :\",return_dict['ワイド'],'円')\n",
    "        print(\"的中レース\",wide_list)\n",
    "             \n",
    "class RankSimulater(Simulater):\n",
    "    \n",
    "    \n",
    "    def return_pred_table(self,data_c,is_long=False):\n",
    "        # is_long って何？\n",
    "        #予測\n",
    "        if not is_long:\n",
    "            scores = pd.Series(self.model.predict(data_c.drop(['date'],axis=1)),index=data_c.index)\n",
    "        else:\n",
    "            scores = pd.Series(self.model.predict(data_c.drop(['date','rank','単勝'],axis=1)),index=data_c.index)\n",
    "        pred = data_c[['馬番']].copy()\n",
    "        pred['scores'] = scores\n",
    "        pred = pred.sort_values('scores',ascending=False)\n",
    "        return pred\n",
    "\n",
    "# 的中レースの分布を表示できるように\n",
    "\n",
    "    def show_results(self , st ,race_id_list ,bet = 100):\n",
    "        self.return_table_today(race_id_list)\n",
    "        return_tables = self.return_tables.copy()\n",
    "        acc_dict = {'単勝':0,'複勝':0,'ワイド':0}\n",
    "        return_dict = {'単勝':0,'複勝':0,'ワイド':0}\n",
    "        # target_race_dict  = {}\n",
    "        self.pred_df = self.return_pred_table(st.data_c)\n",
    "        tansho_list = []\n",
    "        fukusho_list = []\n",
    "        wide_list =[]\n",
    "\n",
    "        for race_id in race_id_list:\n",
    "            df_  = return_tables.loc[race_id]\n",
    "            print(\"-------------------\")\n",
    "            print(\"predict\")\n",
    "            pred_df = self.pred_df.loc[int(race_id)]\n",
    "            pred_df = pred_df.sort_values('scores',ascending=False)\n",
    "            print(pred_df.iloc[:3])\n",
    "            print(\"actual\")\n",
    "            print(return_tables.loc[race_id])\n",
    "            pred_1 = str(pred_df['馬番'].iloc[0])\n",
    "            pred_2 = str(pred_df['馬番'].iloc[1])\n",
    "\n",
    "\n",
    "            if  pred_1 == df_[df_[0]=='単勝'][1].values[0]:\n",
    "                acc_dict['単勝'] += 1\n",
    "                profit = int(df_[df_[0]=='単勝'][2].values[0].replace('円','').replace(',',''))\n",
    "                return_dict['単勝'] += profit\n",
    "                acc_dict['複勝'] += 1\n",
    "                return_index = df_[df_[0]=='複勝'][1].str.split(' ')[0].index(str(pred_1))\n",
    "                profit = int(df_[df_[0]=='複勝'][2].str.split('円')[0][return_index].replace(',',''))\n",
    "                return_dict['複勝'] += profit \n",
    "                tansho_list.append(race_id[-2:])\n",
    "                fukusho_list.append(race_id[-2:])\n",
    "\n",
    "            elif pred_1 in df_[df_[0]=='複勝'][1].str.split(' ')[0]:\n",
    "                acc_dict['複勝'] += 1\n",
    "                return_index = df_[df_[0]=='複勝'][1].str.split(' ')[0].index(str(pred_1))\n",
    "                profit = int(df_[df_[0]=='複勝'][2].str.split('円')[0][return_index].replace(',',''))\n",
    "                return_dict['複勝'] += profit \n",
    "                fukusho_list.append(race_id[-2:])\n",
    "                \n",
    "\n",
    "            for i in range(len(df_[df_[0]=='ワイド'][1].str.split(' ')[0])//2):\n",
    "                if set([pred_1,pred_2])==set(df_[df_[0]=='ワイド'][1].str.split(' ')[0][i:i+2]):\n",
    "                    if i!=0:\n",
    "                        return_index = i-1\n",
    "                    else:\n",
    "                        return_index = i\n",
    "                    profit = int(df_[df_[0]=='ワイド'][2].str.split('円')[0][return_index].replace(',',''))\n",
    "                    return_dict['ワイド'] += profit\n",
    "                    print(\"profit\",profit)\n",
    "                    acc_dict['ワイド'] += 1\n",
    "                    wide_list.append(race_id[-2:])\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        for i, key in enumerate(acc_dict):\n",
    "            return_dict[key] -= bet * len(race_id_list)\n",
    "        \n",
    "        print(\"---------------------\")\n",
    "        print(\"単勝\")\n",
    "        print(\"的中率 :\",acc_dict['単勝'],'/',len(race_id_list))\n",
    "        print(\"収支   :\",return_dict['単勝'],'円')\n",
    "        print(\"的中レース\",tansho_list)\n",
    "        print(\"---------------------\")\n",
    "        print(\"複勝\")\n",
    "        print(\"的中率 :\",acc_dict['複勝'],'/',len(race_id_list))\n",
    "        print(\"収支   :\",return_dict['複勝'],'円')\n",
    "        print(\"的中レース\",fukusho_list)\n",
    "        print(\"---------------------\")\n",
    "        print(\"ワイド\")\n",
    "        print(\"的中率 :\",acc_dict['ワイド'],'/',len(race_id_list))\n",
    "        print(\"収支   :\",return_dict['ワイド'],'円')\n",
    "        print(\"的中レース\",wide_list)\n",
    "    \n",
    "#     odds以上の馬券しか買わない\n",
    "    def show_long_results(self, data_c, return_tables, kaime='tansho', odds=2.0, bet = 100):\n",
    "        if kaime=='tansho':\n",
    "            pass\n",
    "        elif kaime=='fukusho':\n",
    "            pass\n",
    "        elif kaime=='wide':\n",
    "            pass\n",
    "        elif kaime=='wide_3_box':\n",
    "            pass\n",
    "        elif kaime=='umaren':\n",
    "            pass\n",
    "        elif kaime=='umatan':\n",
    "            pass\n",
    "        elif kaime=='sanrentan':\n",
    "            pass\n",
    "        elif kaime=='sanrenpuku':\n",
    "            pass\n",
    "        else:\n",
    "            print(\"No such kaime.\")\n",
    "\n",
    "            \n",
    "    def calc_tansho(self,data_c,return_tables,odds=2.0,bet=100,is_long=True):\n",
    "#         data_c = r.data_cを仮定\n",
    "        acc_dict = {'単勝':0,'複勝':0,'ワイド':0}\n",
    "        return_dict = {'単勝':0,'複勝':0,'ワイド':0}\n",
    "        tansho_list = []\n",
    "        race_id_list = list(set(data_c.index))\n",
    "        not_bet_count = 0\n",
    "        race_count_dict = {\n",
    "            '01':0,\n",
    "            '02':0,\n",
    "            '03':0,\n",
    "            '04':0,\n",
    "            '05':0,\n",
    "            '06':0,\n",
    "            '07':0,\n",
    "            '08':0,\n",
    "            '09':0,\n",
    "            '10':0,\n",
    "            '11':0,\n",
    "            '12':0\n",
    "        }\n",
    "\n",
    "        for race_id in race_id_list: # race_id : int\n",
    "            pred_df = self.return_pred_table(data_c.loc[race_id],is_long=is_long)\n",
    "            df_  = return_tables.loc[race_id]\n",
    "            pred_df = pred_df.loc[race_id]\n",
    "            pred_df = pred_df.sort_values('scores',ascending=False)\n",
    "            pred_1 = pred_df['馬番'].iloc[0]\n",
    "            pred_2 = pred_df['馬番'].iloc[1]\n",
    "#             上位２着の予測スコアが同じなら賭けない\n",
    "            score_1 = pred_df['scores'].iloc[0]\n",
    "            score_2 = pred_df['scores'].iloc[1]\n",
    "\n",
    "            \n",
    "            pred_odds = data_c[data_c['馬番']==pred_1].loc[race_id]['単勝']\n",
    "            try:\n",
    "                rank = data_c[data_c['rank']==1].loc[race_id]['馬番']\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "\n",
    "            if type(rank)!=pd.core.series.Series:\n",
    "                if  pred_1 == rank:\n",
    "                    race_count_dict[str(race_id)[-2:]] += 1\n",
    "                    if pred_odds>=odds and score_1!= score_2:\n",
    "                        acc_dict['単勝'] += 1\n",
    "                        profit = pred_odds*bet\n",
    "                        return_dict['単勝'] += profit\n",
    "                        tansho_list.append(race_id)\n",
    "                    else: #odds　低い or 出力の信頼性がないときは買わない\n",
    "                        not_bet_count += 1\n",
    "#                     odds低かったら買わない\n",
    "                elif data_c[data_c['馬番']==int(pred_1)].loc[race_id]['単勝']<odds:\n",
    "                    not_bet_count+=1\n",
    "            else:\n",
    "                if  pred_1 == rank.values[0] or pred_1 == rank.values[1]:\n",
    "                    race_count_dict[str(race_id)[-2:]] += 1\n",
    "                    if pred_odds>=odds and score_1!= score_2:\n",
    "                        acc_dict['単勝'] += 1\n",
    "                        profit = pred_odds*bet\n",
    "                        return_dict['単勝'] += profit\n",
    "                        tansho_list.append(race_id)\n",
    "                    else: #odds　低い or 出力の信頼性がないときは買わない\n",
    "                        not_bet_count += 1\n",
    "                elif data_c[data_c['馬番']==int(pred_1)].loc[race_id]['単勝']<odds:\n",
    "                    not_bet_count+=1\n",
    "\n",
    "        real_race_len = len(race_id_list) - not_bet_count\n",
    "        return_dict['単勝'] -= bet * real_race_len\n",
    "        print(\"not_bet_count\",not_bet_count)\n",
    "        print(\"---------------------\")\n",
    "        print(\"単勝\")\n",
    "        print(\"的中率 :\",acc_dict['単勝'],'/',real_race_len)\n",
    "        print(\"的中% :\",'{:.2f}'.format(acc_dict['単勝']/real_race_len*100),'%')\n",
    "        print(\"収支   :\",return_dict['単勝'],'円')\n",
    "        print(\"的中レース :\",race_count_dict)\n",
    "#         print(\"的中レース\",tansho_list)\n",
    "\n",
    "    \n",
    "    def calc_tansho_top3(self,data_c,return_tables,odds=2.0,bet=100,is_long=True):\n",
    "        acc_dict = {'単勝':0,'複勝':0,'ワイド':0}\n",
    "        return_dict = {'単勝':0,'複勝':0,'ワイド':0}\n",
    "        tansho_list = []\n",
    "        race_id_list = list(set(data_c.index))\n",
    "        not_bet_count = 0\n",
    "        for race_id in race_id_list: # race_id : int\n",
    "            pred_df = self.return_pred_table(data_c.loc[race_id],is_long=is_long)\n",
    "            df_  = return_tables.loc[race_id]\n",
    "            pred_df = pred_df.loc[race_id]\n",
    "            pred_df = pred_df.sort_values('scores',ascending=False)\n",
    "            pred_1 = pred_df['馬番'].iloc[0]\n",
    "            pred_2 = pred_df['馬番'].iloc[1]\n",
    "            pred_3 = pred_df['馬番'].iloc[2]\n",
    "#             上位２着の予測スコアが同じなら賭けない\n",
    "            score_1 = pred_df['scores'].iloc[0]\n",
    "            score_2 = pred_df['scores'].iloc[1]\n",
    "        \n",
    "        \n",
    "            odds_tmp = return_tables.loc[race_id].iloc[0][2].split('br')\n",
    "            real_odds = int(odds_tmp[0])/100\n",
    "            \n",
    "            \n",
    "            \n",
    "            rank_tmp = df_.iloc[0][1].split('br')\n",
    "            rank = int(rank_tmp[0])\n",
    "            # df_.iloc[0]が単勝\n",
    "            # df_.iloc[1]が複勝, etc..\n",
    "            # df_.iloc[x][1] が１着の馬番\n",
    "            # df_.iloc[x][2] がodds\n",
    "            # df_.iloc[x][3] が人気\n",
    "\n",
    "            if  pred_1 == rank or pred_2 == rank or pred_3==rank:\n",
    "                if real_odds>=odds and score_1!= score_2:\n",
    "                    acc_dict['単勝'] += 1\n",
    "                    profit = real_odds*bet\n",
    "                    return_dict['単勝'] += profit\n",
    "                    tansho_list.append(race_id)\n",
    "                else: #odds　低い or 出力の信頼性がないときは買わない\n",
    "                    not_bet_count += 1\n",
    "        \n",
    "#         top3 全てに賭けるから賭け金の3倍\n",
    "        real_race_len = len(race_id_list) - not_bet_count\n",
    "        return_dict['単勝'] -= 3*bet * real_race_len\n",
    "        print(\"not_bet_count\",not_bet_count)\n",
    "        print(\"---------------------\")\n",
    "        print(\"単勝\")\n",
    "        print(\"的中率 :\",acc_dict['単勝'],'/',len(race_id_list)-not_bet_count)\n",
    "        print(\"的中% :\",'{:.2f}'.format(acc_dict['単勝']/len(race_id_list)*100),'%')\n",
    "        print(\"収支   :\",return_dict['単勝'],'円')\n",
    "        \n",
    "    \n",
    "    def calc_fukusho(self,data_c,return_tables,odds=2.0,bet=100,is_long=True):\n",
    "#         data_c = r.data_cを仮定\n",
    "        acc_dict = {'単勝':0,'複勝':0,'ワイド':0}\n",
    "        return_dict = {'単勝':0,'複勝':0,'ワイド':0}\n",
    "        race_id_list = list(set(data_c.index))\n",
    "        not_bet_count = 0\n",
    "        \n",
    "        \n",
    "        for race_id in race_id_list: # race_id : int\n",
    "            pred_df = self.return_pred_table(data_c.loc[race_id],is_long=is_long)\n",
    "            df_  = return_tables.loc[race_id]\n",
    "            pred_df = pred_df.loc[race_id]\n",
    "            pred_df = pred_df.sort_values('scores',ascending=False)\n",
    "            pred_1 = str(pred_df['馬番'].iloc[0])\n",
    "            pred_2 = str(pred_df['馬番'].iloc[1])\n",
    "#             上位２着の予測スコアが同じなら賭けない\n",
    "            score_1 = pred_df['scores'].iloc[0]\n",
    "            score_2 = pred_df['scores'].iloc[1]\n",
    "            \n",
    "            \n",
    "            \n",
    "            # df_.iloc[0]が単勝\n",
    "            # df_.iloc[1]が複勝, etc..\n",
    "            # df_.iloc[x][1] が１着の馬番\n",
    "            # df_.iloc[x][2] がodds\n",
    "            # df_.iloc[x][3] が人気\n",
    "#             # 一着にのみかける\n",
    "# ############### 確定した odds と 単勝 odds が混在している, よくない\n",
    "            if pred_1 in df_[df_[0]=='複勝'][1].str.split('br').tolist()[0] and score_1!= score_2:\n",
    "                return_index = df_[df_[0]=='複勝'][1].str.split('br').tolist()[0].index(pred_1)\n",
    "                real_odds = int(df_[df_[0]=='複勝'][2].str.split('br').tolist()[0][return_index].replace(',',''))/100\n",
    "                \n",
    "                \n",
    "                if real_odds>=odds:    \n",
    "                    acc_dict['複勝'] += 1\n",
    "                    profit = real_odds*bet\n",
    "                    return_dict['複勝'] += profit \n",
    "                else:\n",
    "                    not_bet_count+=1\n",
    "#             odds が低かったら賭けない\n",
    "            elif data_c[data_c['馬番']==int(pred_1)].loc[race_id]['単勝']<odds:\n",
    "                not_bet_count+=1\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "        real_race_len = len(race_id_list) - not_bet_count\n",
    "        return_dict['複勝'] -= bet * real_race_len\n",
    "\n",
    "        print(\"---------------------\")\n",
    "        print(\"not_bet_count\",not_bet_count)\n",
    "        print(\"複勝\")\n",
    "        print(\"的中率 :\",acc_dict['複勝'],'/',real_race_len)\n",
    "        print(\"的中% :\",'{:.2f}'.format((acc_dict['複勝']/real_race_len)*100),'%')\n",
    "        print(\"収支   :\",return_dict['複勝'],'円')\n",
    "        \n",
    "        \n",
    "    def calc_wide(self,data_c,return_tables,odds=2.0,bet=100,is_long=True):\n",
    "        acc_dict = {'単勝':0,'複勝':0,'ワイド':0}\n",
    "        return_dict = {'単勝':0,'複勝':0,'ワイド':0}\n",
    "        wide_list = []\n",
    "        race_id_list = data_c.index.tolist()\n",
    "        \n",
    "        for i in range(len(df_[df_[0]=='ワイド'][1].str.split(' ')[0])//2):\n",
    "            if set([pred_1,pred_2])==set(df_[df_[0]=='ワイド'][1].str.split(' ')[0][i:i+2]):\n",
    "                if i!=0:\n",
    "                    return_index = i-1\n",
    "                else:\n",
    "                    return_index = i\n",
    "\n",
    "            profit = int(df_[df_[0]=='ワイド'][2].str.split('円')[0][return_index].replace(',',''))\n",
    "            return_dict['ワイド'] += profit\n",
    "            print(\"profit\",profit)\n",
    "            acc_dict['ワイド'] += 1\n",
    "            wide_list.append(race_id[-2:])\n",
    "            break\n",
    "            \n",
    "            \n",
    "    def calc_wide_3box(self,data_c,return_tables,odds=2.0,bet=100,is_long=True):\n",
    "        pass\n",
    "            \n",
    "    \n",
    "    def calc_sanrenpuku(self,data_c,return_tables,bet=100,is_long=True):\n",
    "        acc_dict = {'三連複':0}\n",
    "        return_dict = {'三連複':0}\n",
    "        sanrenpuku_list = []\n",
    "        race_id_list = list(set(data_c.index))\n",
    "        not_bet_count = 0\n",
    "        \n",
    "        \n",
    "        for race_id in race_id_list: # race_id : int\n",
    "            pred_df = self.return_pred_table(data_c.loc[race_id],is_long=is_long)\n",
    "            df_  = return_tables.loc[race_id]\n",
    "            pred_df = pred_df.loc[race_id]\n",
    "            pred_df = pred_df.sort_values('scores',ascending=False)\n",
    "            pred_1 = pred_df['馬番'].iloc[0]\n",
    "            pred_2 = pred_df['馬番'].iloc[1]\n",
    "            try:\n",
    "                pred_3 = pred_df['馬番'].iloc[2]\n",
    "            except:\n",
    "                print(\"race_id\",race_id)\n",
    "                print(\"pred_df\",pred_df)\n",
    "#             上位２着の予測スコアが同じなら賭けない\n",
    "            score_1 = pred_df['scores'].iloc[0]\n",
    "            score_2 = pred_df['scores'].iloc[1] \n",
    "            \n",
    "#             data_cから観測できる odds は100をかけた時の ×odds だが, return_tables の オッズは, 100円をかけた時の払い戻し金額\n",
    "            odds_tmp = df_[df_[0]=='三連複'][2].values[0].replace(',','').split('br')\n",
    "            if len(odds_tmp)==1:\n",
    "                odds = int(odds_tmp[0])\n",
    "            else:\n",
    "                odds = int(odds_tmp[0])\n",
    "                odds2 = int(odds_tmp[1])\n",
    "\n",
    "            if score_1 != score_2:\n",
    "#                 当たってた時\n",
    "                try:\n",
    "                    if [int(i) for i in df_[df_[0]=='三連複'][1].values[0].replace(' ','').split('-')] == sorted([pred_1,pred_2,pred_3]):\n",
    "                        acc_dict['三連複'] += 1\n",
    "                        profit = (bet/100)*odds\n",
    "                        return_dict['三連複'] += profit\n",
    "                except:\n",
    "                    print()\n",
    "                    print('race_id',race_id)\n",
    "            else:\n",
    "                not_bet_count += 1\n",
    "            \n",
    "        real_race_len = len(race_id_list) - not_bet_count\n",
    "        return_dict['三連複'] -= bet * real_race_len\n",
    "#         この辺のロジック同じだから, 関数でまとめたい\n",
    "        print(\"---------------------\")\n",
    "        print(\"not_bet_count\",not_bet_count)\n",
    "        print(\"三連複\")\n",
    "        print(\"的中率 :\",acc_dict['三連複'],'/',real_race_len)\n",
    "        print(\"的中% :\",'{:.2f}'.format((acc_dict['三連複']/real_race_len)*100),'%')\n",
    "        print(\"収支   :\",return_dict['三連複'],'円')\n",
    "    \n",
    "    def calc_sanrenpuku_box(self,data_c,return_tables,odds=2.0,bet=100,is_long=True):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def calc_sanrentan(self,data_c,return_tables,bet=100,is_long=True):\n",
    "        acc_dict = {'三連単':0}\n",
    "        return_dict = {'三連単':0}\n",
    "        sanrenpuku_list = []\n",
    "        race_id_list = list(set(data_c.index))\n",
    "        not_bet_count = 0\n",
    "        \n",
    "        \n",
    "        for race_id in race_id_list: # race_id : int\n",
    "            pred_df = self.return_pred_table(data_c.loc[race_id],is_long=is_long)\n",
    "            df_  = return_tables.loc[int(race_id)]\n",
    "            pred_df = pred_df.loc[race_id]\n",
    "            pred_df = pred_df.sort_values('scores',ascending=False)\n",
    "            pred_1 = pred_df['馬番'].iloc[0]\n",
    "            pred_2 = pred_df['馬番'].iloc[1]\n",
    "            try:\n",
    "                pred_3 = pred_df['馬番'].iloc[2]\n",
    "            except:\n",
    "                print(\"race_id\",race_id)\n",
    "                print(\"pred_df\",pred_df)\n",
    "#             上位２着の予測スコアが同じなら賭けない\n",
    "            score_1 = pred_df['scores'].iloc[0]\n",
    "            score_2 = pred_df['scores'].iloc[1] \n",
    "            \n",
    "#             data_cから観測できる odds は100をかけた時の ×odds だが, return_tables の オッズは, 100円をかけた時の払い戻し金額\n",
    "            odds_tmp = df_[df_[0]=='三連単'][2].values[0].replace(',','').split('br')\n",
    "            if len(odds_tmp)==1:\n",
    "                odds = int(odds_tmp[0])\n",
    "            else:\n",
    "                odds = int(odds_tmp[0])\n",
    "                odds2 = int(odds_tmp[1])\n",
    "\n",
    "            if score_1 != score_2:\n",
    "#                 当たってた時\n",
    "                try:\n",
    "                    if [int(i) for i in df_[df_[0]=='三連単'][1].values[0].replace(' ','').split('→')] == [pred_1,pred_2,pred_3]:\n",
    "                        acc_dict['三連単'] += 1\n",
    "                        profit = (bet/100)*odds\n",
    "                        return_dict['三連単'] += profit\n",
    "                except:\n",
    "                    print()\n",
    "                    print('race_id',race_id)\n",
    "            else:\n",
    "                not_bet_count += 1\n",
    "            \n",
    "        real_race_len = len(race_id_list) - not_bet_count\n",
    "        return_dict['三連単'] -= bet * real_race_len\n",
    "#         この辺のロジック同じだから, 関数でまとめたい\n",
    "        print(\"---------------------\")\n",
    "        print(\"not_bet_count\",not_bet_count)\n",
    "        print(\"三連単\")\n",
    "        print(\"的中率 :\",acc_dict['三連単'],'/',real_race_len)\n",
    "        print(\"的中% :\",'{:.2f}'.format((acc_dict['三連単']/real_race_len)*100),'%')\n",
    "        print(\"収支   :\",return_dict['三連単'],'円')\n",
    "    \n",
    "    \n",
    "    def show_results_today(self , st ,race_id_list ,bet = 100):\n",
    "        acc_dict = {'単勝':0,'複勝':0,'ワイド':0}\n",
    "        return_dict = {'単勝':0,'複勝':0,'ワイド':0}\n",
    "        tansho_list = []\n",
    "        fukusho_list = []\n",
    "        wide_list =[]\n",
    "\n",
    "        for race_id in race_id_list:\n",
    "            self.pred_df = self.return_pred_table(st.data_c.loc[int(race_id)])\n",
    "#             self.return_tables.index =  self.return_tables.index.astype(int)\n",
    "            df_  = self.return_tables.loc[int(race_id)]\n",
    "            print(\"-------------------\")\n",
    "            print(\"predict\")\n",
    "            pred_df = self.pred_df.loc[int(race_id)]\n",
    "            pred_df = pred_df.sort_values('scores',ascending=False)\n",
    "            print(pred_df.iloc[:3])\n",
    "            print(\"actual\")\n",
    "            print(self.return_tables.loc[int(race_id)])\n",
    "            pred_1 = str(pred_df['馬番'].iloc[0])\n",
    "            pred_2 = str(pred_df['馬番'].iloc[1])\n",
    "\n",
    "\n",
    "            if  pred_1 == df_[df_[0]=='単勝'][1].values[0]:\n",
    "                acc_dict['単勝'] += 1\n",
    "                profit = int(df_[df_[0]=='単勝'][2].values[0].replace('円','').replace(',',''))\n",
    "                return_dict['単勝'] += profit\n",
    "                acc_dict['複勝'] += 1\n",
    "                return_index = df_[df_[0]=='複勝'][1].str.split(' ').values[0].index(str(pred_1))\n",
    "                profit = int(df_[df_[0]=='複勝'][2].str.split('円').values[0][return_index].replace(',',''))\n",
    "                return_dict['複勝'] += profit \n",
    "                tansho_list.append(race_id[-2:])\n",
    "                fukusho_list.append(race_id[-2:])\n",
    "\n",
    "            elif pred_1 in df_[df_[0]=='複勝'][1].str.split(' ')[0]:\n",
    "                acc_dict['複勝'] += 1\n",
    "                return_index = df_[df_[0]=='複勝'][1].str.split(' ').values[0].index(str(pred_1))\n",
    "                profit = int(df_[df_[0]=='複勝'][2].str.split('円').values[0][return_index].replace(',',''))\n",
    "                return_dict['複勝'] += profit \n",
    "                fukusho_list.append(race_id[-2:])\n",
    "                \n",
    "\n",
    "            for i in range(len(df_[df_[0]=='ワイド'][1].str.split(' ')[0])//2):\n",
    "                if set([pred_1,pred_2])==set(df_[df_[0]=='ワイド'][1].str.split(' ')[0][i:i+2]):\n",
    "                    if i!=0:\n",
    "                        return_index = i-1\n",
    "                    else:\n",
    "                        return_index = i\n",
    "                    profit = int(df_[df_[0]=='ワイド'][2].str.split('円')[0][return_index].replace(',',''))\n",
    "                    return_dict['ワイド'] += profit\n",
    "                    print(\"profit\",profit)\n",
    "                    acc_dict['ワイド'] += 1\n",
    "                    wide_list.append(race_id[-2:])\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        for i, key in enumerate(acc_dict):\n",
    "            return_dict[key] -= bet * len(race_id_list)\n",
    "        \n",
    "        print(\"---------------------\")\n",
    "        print(\"単勝\")\n",
    "        print(\"的中率 :\",acc_dict['単勝'],'/',len(race_id_list))\n",
    "        print(\"的中% :\",'{:.2f}'.format(acc_dict['単勝']/len(race_id_list)*100),'%')\n",
    "        print(\"収支   :\",return_dict['単勝'],'円')\n",
    "        print(\"的中レース\",tansho_list)\n",
    "        print(\"---------------------\")\n",
    "        print(\"複勝\")\n",
    "        print(\"的中率 :\",acc_dict['複勝'],'/',len(race_id_list))\n",
    "        print(\"的中% :\",'{:.2f}'.format(acc_dict['複勝']/len(race_id_list)*100),'%')\n",
    "        print(\"収支   :\",return_dict['複勝'],'円')\n",
    "        print(\"的中レース\",fukusho_list)\n",
    "        print(\"---------------------\")\n",
    "        print(\"ワイド\")\n",
    "        print(\"的中率 :\",acc_dict['ワイド'],'/',len(race_id_list))\n",
    "        print(\"的中% :\",'{:.2f}'.format(acc_dict['ワイド']/len(race_id_list)*100),'%')\n",
    "        print(\"収支   :\",return_dict['ワイド'],'円')\n",
    "        print(\"的中レース\",wide_list)\n",
    "        \n",
    "class LearnLGBM():\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "        \n",
    "    def get_train_data(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ff45a5-ed87-4f2c-9c50-8059c145f8de",
   "metadata": {},
   "source": [
    "回収率 \\\n",
    "(profit - real_race_len*bet) /real_race_len * bet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e17aadb6-decc-4070-b4d2-b97c41ddd927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = return_tables.loc[202001010101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bb9255aa-35f1-4d67-b6d4-e5c36ad57631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 6]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(i) for i in df_[df_[0]=='三連複'][1].values[0].replace(' ','').split('-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b5e65fa1-890f-4b24-b980-73bfe9bf5366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9060', '9810']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'9,060br9,810'.replace(',','').split('br')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3aca7555-19cf-4624-83c7-49ee254668dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.data_c.iloc[0]['単勝']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "79305132-3e9c-46cd-aec3-90ec2672902b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12', '10', '6br12', '10', '11']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_[df_[0]=='三連単'][1].values[0].replace(' ','').split('→')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30c738-f553-4488-8239-235c9808c184",
   "metadata": {},
   "source": [
    "# Simulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b4c3498b-a9bf-4891-9ec4-748f1681fe24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odds 1.1\n",
      "not_bet_count 2\n",
      "---------------------\n",
      "単勝\n",
      "的中率 : 583 / 1512\n",
      "的中% : 38.56 %\n",
      "収支   : 90490.0 円\n",
      "的中レース : {'01': 56, '02': 57, '03': 49, '04': 56, '05': 44, '06': 55, '07': 53, '08': 51, '09': 47, '10': 44, '11': 30, '12': 43}\n",
      "time 45.751676082611084\n",
      "odds 2.0\n",
      "not_bet_count 209\n",
      "---------------------\n",
      "単勝\n",
      "的中率 : 434 / 1305\n",
      "的中% : 33.26 %\n",
      "収支   : 87600.0 円\n",
      "的中レース : {'01': 56, '02': 57, '03': 49, '04': 56, '05': 44, '06': 55, '07': 53, '08': 51, '09': 47, '10': 44, '11': 30, '12': 43}\n",
      "time 87.51412010192871\n",
      "odds 3.0\n",
      "not_bet_count 495\n",
      "---------------------\n",
      "単勝\n",
      "的中率 : 269 / 1019\n",
      "的中% : 26.40 %\n",
      "収支   : 76240.0 円\n",
      "的中レース : {'01': 56, '02': 57, '03': 49, '04': 56, '05': 44, '06': 55, '07': 53, '08': 51, '09': 47, '10': 44, '11': 30, '12': 43}\n",
      "time 130.4610562324524\n",
      "odds 4.0\n",
      "not_bet_count 725\n",
      "---------------------\n",
      "単勝\n",
      "的中率 : 183 / 789\n",
      "的中% : 23.19 %\n",
      "収支   : 69810.0 円\n",
      "的中レース : {'01': 56, '02': 57, '03': 49, '04': 56, '05': 44, '06': 55, '07': 53, '08': 51, '09': 47, '10': 44, '11': 30, '12': 43}\n",
      "time 174.98983216285706\n",
      "odds 5.0\n",
      "not_bet_count 905\n",
      "---------------------\n",
      "単勝\n",
      "的中率 : 125 / 609\n",
      "的中% : 20.53 %\n",
      "収支   : 62210.0 円\n",
      "的中レース : {'01': 56, '02': 57, '03': 49, '04': 56, '05': 44, '06': 55, '07': 53, '08': 51, '09': 47, '10': 44, '11': 30, '12': 43}\n",
      "time 216.80688214302063\n",
      "odds 6.0\n",
      "not_bet_count 1022\n",
      "---------------------\n",
      "単勝\n",
      "的中率 : 87 / 492\n",
      "的中% : 17.68 %\n",
      "収支   : 53250.0 円\n",
      "的中レース : {'01': 56, '02': 57, '03': 49, '04': 56, '05': 44, '06': 55, '07': 53, '08': 51, '09': 47, '10': 44, '11': 30, '12': 43}\n",
      "time 261.6003291606903\n",
      "odds 7.0\n",
      "not_bet_count 1113\n",
      "---------------------\n",
      "単勝\n",
      "的中率 : 62 / 401\n",
      "的中% : 15.46 %\n",
      "収支   : 46350.0 円\n",
      "的中レース : {'01': 56, '02': 57, '03': 49, '04': 56, '05': 44, '06': 55, '07': 53, '08': 51, '09': 47, '10': 44, '11': 30, '12': 43}\n",
      "time 303.6184170246124\n"
     ]
    }
   ],
   "source": [
    "sl = RankSimulater(lgb_rank)\n",
    "start_time = time.time()\n",
    "for odds in [1.1,2.0,3.0,4.0,5.0,6.0,7.0]:\n",
    "    print(\"odds\",odds)\n",
    "    sl.calc_tansho(test.fillna(0),return_tables,odds=odds)\n",
    "    print(\"time\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9a5acc8c-484d-4fef-ae88-1c20180881d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "not_bet_count 0\n",
      "三連複\n",
      "的中率 : 4 / 69\n",
      "的中% : 5.80 %\n",
      "収支   : -2250.0 円\n"
     ]
    }
   ],
   "source": [
    "sl = RankSimulater(lgb_rank)\n",
    "sl.calc_sanrenpuku(r.data_c.iloc[-1000:].fillna(0),return_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a4f65-19bc-482c-be47-daeb67e6623a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2b0526b6-d15f-4e39-abaf-40aaf6cfd0fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "not_bet_count 0\n",
      "三連単\n",
      "的中率 : 0 / 71\n",
      "的中% : 0.00 %\n",
      "収支   : -7100 円\n"
     ]
    }
   ],
   "source": [
    "sl = RankSimulater(lgb_rank)\n",
    "sl.calc_sanrentan(r.data_c.iloc[-1000:].fillna(0),return_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a23be3e1-765c-4435-9355-1008834f3119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6', '10', '12br10', '11', '12']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_[df_[0]=='三連複'][1].values[0].replace(' ','').split('-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a920e716-5257-45d8-9831-2effe586aa2c",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cafb76f-29dc-4841-bb1b-2792c246cd20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = load_csv(path_mac+'results.csv')\n",
    "horse_results = load_csv(path_mac+'horse_results.csv')\n",
    "peds = load_csv(path_mac+'peds.csv')\n",
    "# 何回やってもロードすると, nanが出る\n",
    "peds.fillna('nan',inplace=True)\n",
    "return_tables = load_csv(path_mac+'return.csv')\n",
    "return_tables.rename(columns={'0':0,'1':1,'2':2,'3':3},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b97e7-5e69-4334-a268-c7a57eaa10d8",
   "metadata": {},
   "source": [
    "# 日付に注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e00c431-6a37-4f54-bfd3-7a1cc01780cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2022/12/31'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff135d8f-2a18-4583-8747-68c2938e6b79",
   "metadata": {},
   "source": [
    "# race_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca02207f-1319-48d2-943f-195f395e1d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 202206030101\n",
    "race_id_list = ['2022050201{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "race_id_list += ['2022050202{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022070205{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "\n",
    "race_id_list += ['2022090209{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "race_id_list += ['2022090210{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022100204{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "\n",
    "\n",
    "# race_id_list += ['2022060208{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022070204{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "\n",
    "race_id_list += ['2022030103{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "race_id_list += ['2022030104{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ec390-bc7f-4821-8417-76382d034041",
   "metadata": {},
   "source": [
    "# Results scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "131add0a-4ac5-4133-b242-3fa2109a4762",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a354ce46a140e2a2c6312b2e092092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=120.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# race_id_list = results.index.astype('str')\n",
    "\n",
    "results = Results.scrape(race_id_list)\n",
    "\n",
    "results.to_csv(path_mac+'results_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ac189-894a-48ac-adb2-4e731640bc5c",
   "metadata": {},
   "source": [
    "# Horse_results scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fb495b3-1044-4b5a-afdc-cdf1b60aa6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8382262b1cab4b51881a205c44632555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1744.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "horse_id_list = results['horse_id'].astype(str).unique()\n",
    "horse_results = HorseResults.scrape(horse_id_list)\n",
    "# save_path = '/Users/rince/Desktop/Horse/Data/horse_2020.csv'\n",
    "horse_results.to_csv(path_mac+'horse_results_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1569216-aa8f-40a3-8303-5d54a442b00e",
   "metadata": {},
   "source": [
    "# Peds scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56d56e6b-7a60-4721-a111-892aafa204d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f09bccdecef47a3b5dbb5c949bfaf21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1744.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd43d1c47d3a479e84379bbd63ffb1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1744.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "peds_2021 = Peds.scrape(horse_id_list)\n",
    "pe_2021 = Peds(peds_2021)\n",
    "pe_2021.regularize_peds()\n",
    "pe_2021.peds_re.to_csv(path_mac+'peds_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1db0da-3505-4825-8408-e7dd58205c96",
   "metadata": {},
   "source": [
    "# Return scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56a4d97d-94cc-477f-b643-5144c7173613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5292e06b9648fd83de7f902192fdc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=120.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "returns_2021 = Return.scrape(race_id_list)\n",
    "returns_2021.to_csv(path_mac+'returns_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e175b9a-1a2d-4d5d-a5e2-e771c86dd8d2",
   "metadata": {},
   "source": [
    "# update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "428fa2b8-2058-4c1d-af05-ec10e9f3768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = update_data(load_csv(path_mac+'results.csv'), load_csv(path_mac+'results_new.csv'))\n",
    "new_horse_results = update_data(load_csv(path_mac+'horse_results.csv'), load_csv(path_mac+'horse_results_new.csv'))\n",
    "new_peds = update_data(load_csv(path_mac+'peds.csv'), load_csv(path_mac+'peds_new.csv'))\n",
    "new_return = update_data(load_csv(path_mac+'return.csv'), load_csv(path_mac+'returns_new.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77364dd-545a-43d4-97aa-070ca0595356",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "875dc8e7-f696-4b78-933d-4f62f3603430",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results.to_csv(path_mac2+'results.csv')\n",
    "new_horse_results.to_csv(path_mac2+'horse_results.csv')\n",
    "new_peds.to_csv(path_mac2+'peds.csv')\n",
    "new_return.to_csv(path_mac2+'return.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64e35c3-7240-4c3a-9a17-e840ccfcd68b",
   "metadata": {},
   "source": [
    "# 今後の方針\n",
    "1. XGB試してみる\n",
    "2. ME 自己流につくりかえる\n",
    "3. シミュレーションとか, 自分流に変える."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5274e51f-047b-4f8a-903d-47cb0ef3f1e1",
   "metadata": {},
   "source": [
    "# rank　学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12ff12d5-29ce-4ab4-8c8a-43c30d3653a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b21be002eca4ebd94e100863812a1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17450.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7b7219ee14487982e783c5c2ddffa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=241.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922f8c11032a4810bb23c82eb8d096b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=241.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be0452235444b888e5bec5e5b711483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=241.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# peds_id = results['horse_id'].astype(str).unique()\n",
    "# peds_tmp = Peds.scrape(peds_id)\n",
    "# new_peds = update_data(peds, peds_tmp)\n",
    "# ここで初めて学習データを作る\n",
    "date = '2022/12/31'\n",
    "# model_ft 作成　\n",
    "model_ft = ft.train_unsupervised('test.txt',dim=62,minn=2,maxn=14)\n",
    "\n",
    "pe = Peds(peds)\n",
    "# pe.regularize_peds()\n",
    "pe.vectorize(pe.peds,model_ft)\n",
    "\n",
    "\n",
    "# pe.categorize()\n",
    "r = Results(results)\n",
    "#前処理\n",
    "r.preprocessing()\n",
    "#馬の過去成績データ追加\n",
    "# 過去聖遺跡データも最新にupdateする\n",
    "# horse_id_list = data['horse_id'].astype(str).unique()\n",
    "# horse_results_tmp = HorseResults.scrape(horse_id_list)\n",
    "# new_horse_results = update_data(horse_results,horse_results_tmp)\n",
    "hr = HorseResults(horse_results)\n",
    "r.merge_horse_results(hr)\n",
    "\n",
    "r.merge_peds(pe.peds_vec)\n",
    "\n",
    "# r.merge_peds(pe.peds_cat)\n",
    "\n",
    "#カテゴリ変数の処理\n",
    "# pedsは既にカテゴリ化したdataをconcatしているので, ここでカテゴリ化せずとも良い\n",
    "r.process_categorical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52ac3a4a-1f62-4605-8edf-307aed2cc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値は 0 とした\n",
    "train, test = split_data(r.data_c.fillna(0),test_size=0.2,rank_learning=False)\n",
    "# x_train = train.drop(['rank', 'date','体重','体重変化','単勝'], axis=1)\n",
    "x_train = train.drop(['rank', 'date','単勝'], axis=1)\n",
    "y_train = train['rank']\n",
    "\n",
    "x_test = test.drop(['rank', 'date','単勝'], axis=1)\n",
    "y_test = test['rank']\n",
    "\n",
    "train_query = x_train.groupby(x_train.index).size()\n",
    "test_query = x_test.groupby(x_test.index).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edc24cf8-2253-4a67-bfc8-2149d412700d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 45821\n",
      "[LightGBM] [Info] Number of data points in the train set: 83611, number of used features: 172\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgbm_params = {\n",
    "    'lambdarank_truncation_level': 2,\n",
    "    'metric': 'ndcg',\n",
    "    'objective': 'lambdarank',\n",
    "    'ndcg_eval_at': [1,2,3],\n",
    "    'learning_rate': 0.06748036714102541,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 777\n",
    "}\n",
    "\n",
    " #学習 \n",
    "train = lgb.Dataset(x_train, y_train, group=train_query)\n",
    "valid = lgb.Dataset(x_test, y_test, reference=train, group=test_query)\n",
    "\n",
    "lgb_rank = lgb.train(\n",
    "   lgbm_params,\n",
    "   train,\n",
    "   num_boost_round=100,\n",
    "#    valid_sets=valid,\n",
    "   valid_names=['train'],\n",
    "#    early_stopping_rounds=20,\n",
    "#    verbose_eval=5\n",
    ")\n",
    "\n",
    "# early stopping -> test data ないと怒られる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b5244-fc8d-4f9d-b9cd-69b895851b73",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4c5a59d7-adb9-4e89-b317-ef9eb4ade4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>枠番</th>\n",
       "      <th>馬番</th>\n",
       "      <th>斤量</th>\n",
       "      <th>course_len</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>年齢</th>\n",
       "      <th>体重</th>\n",
       "      <th>体重変化</th>\n",
       "      <th>n_horse</th>\n",
       "      <th>...</th>\n",
       "      <th>race_type_ダート</th>\n",
       "      <th>race_type_芝</th>\n",
       "      <th>race_type_障害</th>\n",
       "      <th>ground_state_稍重</th>\n",
       "      <th>ground_state_良</th>\n",
       "      <th>ground_state_不良</th>\n",
       "      <th>ground_state_重</th>\n",
       "      <th>性_牡</th>\n",
       "      <th>性_牝</th>\n",
       "      <th>性_セ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202106040907</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12477</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>486</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106040907</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>57.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4070</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "      <td>482</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106040907</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11380</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>-2</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106040907</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8542</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>496</td>\n",
       "      <td>-12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106040907</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>57.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7064</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>438</td>\n",
       "      <td>-14</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202206030408</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>52.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9517</td>\n",
       "      <td>132</td>\n",
       "      <td>4</td>\n",
       "      <td>462</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202206030408</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6192</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>506</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202206030408</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>52.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3743</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "      <td>456</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202206030408</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3605</td>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "      <td>432</td>\n",
       "      <td>-2</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202206030408</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8432</td>\n",
       "      <td>133</td>\n",
       "      <td>4</td>\n",
       "      <td>422</td>\n",
       "      <td>-2</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20599 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              枠番  馬番    斤量  course_len horse_id jockey_id  年齢   体重  体重変化  \\\n",
       "202106040907   2   2  54.0        22.0    12477       120   3  486     2   \n",
       "202106040907   6   6  57.0        22.0     4070        74   4  482     0   \n",
       "202106040907   8   8  54.0        22.0    11380       161   3  480    -2   \n",
       "202106040907   3   3  54.0        22.0     8542         8   3  496   -12   \n",
       "202106040907   4   4  57.0        22.0     7064        61   4  438   -14   \n",
       "...           ..  ..   ...         ...      ...       ...  ..  ...   ...   \n",
       "202206030408   5   7  52.0        18.0     9517       132   4  462     6   \n",
       "202206030408   1   1  57.0        18.0     6192         1   5  506     8   \n",
       "202206030408   7  10  52.0        18.0     3743       126   6  456     8   \n",
       "202206030408   6   9  55.0        18.0     3605        58   6  432    -2   \n",
       "202206030408   2   2  52.0        18.0     8432       133   4  422    -2   \n",
       "\n",
       "              n_horse  ...  race_type_ダート  race_type_芝  race_type_障害  \\\n",
       "202106040907        9  ...              0            1             0   \n",
       "202106040907        9  ...              0            1             0   \n",
       "202106040907        9  ...              0            1             0   \n",
       "202106040907        9  ...              0            1             0   \n",
       "202106040907        9  ...              0            1             0   \n",
       "...               ...  ...            ...          ...           ...   \n",
       "202206030408       13  ...              1            0             0   \n",
       "202206030408       13  ...              1            0             0   \n",
       "202206030408       13  ...              1            0             0   \n",
       "202206030408       13  ...              1            0             0   \n",
       "202206030408       13  ...              1            0             0   \n",
       "\n",
       "              ground_state_稍重  ground_state_良  ground_state_不良  \\\n",
       "202106040907                1               0                0   \n",
       "202106040907                1               0                0   \n",
       "202106040907                1               0                0   \n",
       "202106040907                1               0                0   \n",
       "202106040907                1               0                0   \n",
       "...                       ...             ...              ...   \n",
       "202206030408                1               0                0   \n",
       "202206030408                1               0                0   \n",
       "202206030408                1               0                0   \n",
       "202206030408                1               0                0   \n",
       "202206030408                1               0                0   \n",
       "\n",
       "              ground_state_重  性_牡  性_牝  性_セ  \n",
       "202106040907               0    1    0    0  \n",
       "202106040907               0    1    0    0  \n",
       "202106040907               0    1    0    0  \n",
       "202106040907               0    1    0    0  \n",
       "202106040907               0    1    0    0  \n",
       "...                      ...  ...  ...  ...  \n",
       "202206030408               0    0    1    0  \n",
       "202206030408               0    0    0    1  \n",
       "202206030408               0    0    1    0  \n",
       "202206030408               0    0    1    0  \n",
       "202206030408               0    0    1    0  \n",
       "\n",
       "[20599 rows x 172 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "fa0af40b-fb3b-42b6-a50e-0943959c14f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = lgb.Dataset(x_train, y_train, group=train_query)\n",
    "valid = lgb.Dataset(x_test.iloc[:10599], y_test.iloc[:10599], reference=train, group=test_query)\n",
    "trials = Trials()\n",
    "optimize(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebee6f9a-20ac-4523-adb6-378f9fcfcf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    print(\"Training start:\")\n",
    "\n",
    "    N_boost_round = []\n",
    "    Score = []\n",
    "\n",
    "    lgb_results={}  #履歴格納用\n",
    "    train = lgb.Dataset(x_train, y_train, group=train_query)\n",
    "    valid = lgb.Dataset(x_test, y_test, reference=train, group=test_query)\n",
    "\n",
    "    \n",
    "    lgb_clf = lgb.train(\n",
    "       params,\n",
    "       train,\n",
    "       num_boost_round=1000,\n",
    "       valid_sets=valid,\n",
    "       valid_names=['valid'],\n",
    "       early_stopping_rounds=20,\n",
    "       verbose_eval=5,\n",
    "       evals_result=lgb_results\n",
    "    )\n",
    "#     return lgb_results\n",
    "    return {'loss': -1.0 * lgb_results['valid']['ndcg@3'][lgb_clf.best_iteration], 'status': STATUS_OK}\n",
    "\n",
    "def optimize(trials):\n",
    "#探索スペース\n",
    "    space = {\n",
    "        'objective': 'lambdarank',\n",
    "        'metric': 'ndcg',\n",
    "        'ndcg_eval_at': [1,2,3],\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.1),\n",
    "#         なぜか, uniformだと strに変換されてしまう\n",
    "#         lambda_rank_truncation_levelは int型\n",
    "#         よって, int以外はstrに勝手に変換されてしまい, エラーとなったのではないか\n",
    "        'lambdarank_truncation_level': hp.choice('lambdarank_truncation_level',[ 1,2\n",
    "                                                                                ,4,6,8,10]),\n",
    "#         best paramsの返り値は, choiceだとindexか？\n",
    "#         n_estimaterとか サーチしてみたい\n",
    "#         'n_estimators': hp.choice('n_estimators',[ 1,10,100,500,750]),\n",
    "        'boosting_type': 'gbdt',\n",
    "        'random_state': 777,\n",
    "    }\n",
    "\n",
    "    max_evals = 50      #探索回数(25くらいで十分)\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=max_evals)\n",
    "\n",
    "    print(\"best parameters:\", best)\n",
    "\n",
    "#     return {'loss': -1.0 * lgb_results['ndcg@3'][lgb_clf.best_iteration], 'status': STATUS_OK}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6985907-c8c8-426d-be48-086c7ba1af64",
   "metadata": {},
   "source": [
    "# milestone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67532ce2-4766-485a-b767-2d20e84ebc74",
   "metadata": {},
   "source": [
    "# 実際に予測するときの手順"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ecd8daf5-2a98-4901-aaec-a88887b81c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "race_id_list = ['2022050202{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "race_id_list += ['2022090210{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "race_id_list += ['2022030104{}'.format(str(i).zfill(2)) for i in range(1,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7a13685f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062ae7c0da7048e2a0949ce9f2813c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data =  ShutubaTable.scrape(race_id_list, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d2f548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nopeds_id_list = []\n",
    "for ind in data['horse_id'].astype(int).unique():\n",
    "    if ind not in peds.index:\n",
    "        nopeds_id_list.append(str(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4aafaaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2077d39dfe4267b77216a179e94f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34121a3e9b8948e88c07b4900e115afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17475.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pe finish\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6926f36433f4fddb85593038ec07116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=503.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4df312e7244867a4a27816a816d7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=241.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f959b3a4534b4cb4751bbd7d7bdbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=241.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78151d2d2b684a049129aa660909d323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=241.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# peds_id = data['horse_id'].astype(str).unique( peds_tmp = Peds.scrape(peds_id)\n",
    "peds_tmp = Peds.scrape(nopeds_id_list)\n",
    "new_peds = update_data(peds, peds_tmp)\n",
    "# ここで初めて学習データを作る\n",
    "date = '2022/12/31'\n",
    "# model_ft 作成　\n",
    "model_ft = ft.train_unsupervised('test.txt',dim=62,minn=2,maxn=14)\n",
    "\n",
    "pe = Peds(new_peds)\n",
    "# pe.regularize_peds()\n",
    "pe.vectorize(pe.peds,model_ft)\n",
    "print(\"pe finish\")\n",
    "\n",
    "# pe.categorize()\n",
    "r = Results(results)\n",
    "#前処理\n",
    "r.preprocessing()\n",
    "#馬の過去成績データ追加\n",
    "# 過去聖遺跡データも最新にupdateする\n",
    "horse_id_list = data['horse_id'].astype(str).unique()\n",
    "horse_results_tmp = HorseResults.scrape(horse_id_list)\n",
    "new_horse_results = update_data(horse_results,horse_results_tmp)\n",
    "hr = HorseResults(horse_results)\n",
    "r.merge_horse_results(hr)\n",
    "\n",
    "r.merge_peds(pe.peds_vec)\n",
    "\n",
    "# r.merge_peds(pe.peds_cat)\n",
    "\n",
    "#カテゴリ変数の処理\n",
    "# pedsは既にカテゴリ化したdataをconcatしているので, ここでカテゴリ化せずとも良い\n",
    "r.process_categorical()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e023bb",
   "metadata": {},
   "source": [
    "# grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eca46264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start:                                       \n",
      "[LightGBM] [Warning]                                  \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.063405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                     \n",
      "Total Bins 45821                                      \n",
      "[LightGBM] [Info]                                     \n",
      "Number of data points in the train set: 83611, number of used features: 172\n",
      "  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rince/Library/Python/3.7/lib/python/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "\n",
      "/Users/rince/Library/Python/3.7/lib/python/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[5]\tvalid's ndcg@1: 0.505945\tvalid's ndcg@2: 0.500469\tvalid's ndcg@3: 0.488679\n",
      "[10]\tvalid's ndcg@1: 0.507266\tvalid's ndcg@2: 0.50144\tvalid's ndcg@3: 0.491415\n",
      "[15]\tvalid's ndcg@1: 0.509908\tvalid's ndcg@2: 0.501877\tvalid's ndcg@3: 0.493117\n",
      "[20]\tvalid's ndcg@1: 0.51321\tvalid's ndcg@2: 0.505246\tvalid's ndcg@3: 0.496331\n",
      "Early stopping, best iteration is:                    \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.062858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.505284\tvalid's ndcg@2: 0.500131\tvalid's ndcg@3: 0.490005    \n",
      "[10]\tvalid's ndcg@1: 0.514531\tvalid's ndcg@2: 0.502896\tvalid's ndcg@3: 0.49155    \n",
      "[15]\tvalid's ndcg@1: 0.513871\tvalid's ndcg@2: 0.501308\tvalid's ndcg@3: 0.493678   \n",
      "[20]\tvalid's ndcg@1: 0.509247\tvalid's ndcg@2: 0.502211\tvalid's ndcg@3: 0.493206   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.065950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.510568\tvalid's ndcg@2: 0.496889\tvalid's ndcg@3: 0.490177    \n",
      "[10]\tvalid's ndcg@1: 0.514531\tvalid's ndcg@2: 0.504012\tvalid's ndcg@3: 0.493606   \n",
      "[15]\tvalid's ndcg@1: 0.519155\tvalid's ndcg@2: 0.503714\tvalid's ndcg@3: 0.497652   \n",
      "[20]\tvalid's ndcg@1: 0.517173\tvalid's ndcg@2: 0.50621\tvalid's ndcg@3: 0.498569    \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.116118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.511889\tvalid's ndcg@2: 0.498976\tvalid's ndcg@3: 0.492893    \n",
      "[10]\tvalid's ndcg@1: 0.517173\tvalid's ndcg@2: 0.503427\tvalid's ndcg@3: 0.494402   \n",
      "[15]\tvalid's ndcg@1: 0.523118\tvalid's ndcg@2: 0.503911\tvalid's ndcg@3: 0.497161   \n",
      "[20]\tvalid's ndcg@1: 0.532365\tvalid's ndcg@2: 0.509231\tvalid's ndcg@3: 0.503166   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.016827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.514531\tvalid's ndcg@2: 0.505706\tvalid's ndcg@3: 0.495078    \n",
      "[10]\tvalid's ndcg@1: 0.520476\tvalid's ndcg@2: 0.504591\tvalid's ndcg@3: 0.500231   \n",
      "[15]\tvalid's ndcg@1: 0.521797\tvalid's ndcg@2: 0.508723\tvalid's ndcg@3: 0.502342   \n",
      "[20]\tvalid's ndcg@1: 0.521136\tvalid's ndcg@2: 0.509689\tvalid's ndcg@3: 0.501236   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.540951\tvalid's ndcg@2: 0.517778\tvalid's ndcg@3: 0.50076\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.062167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.508587\tvalid's ndcg@2: 0.492662\tvalid's ndcg@3: 0.488577    \n",
      "[10]\tvalid's ndcg@1: 0.51255\tvalid's ndcg@2: 0.497364\tvalid's ndcg@3: 0.490553    \n",
      "[15]\tvalid's ndcg@1: 0.516513\tvalid's ndcg@2: 0.497845\tvalid's ndcg@3: 0.49362    \n",
      "[20]\tvalid's ndcg@1: 0.519155\tvalid's ndcg@2: 0.50518\tvalid's ndcg@3: 0.494553    \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.091718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.517834\tvalid's ndcg@2: 0.502366\tvalid's ndcg@3: 0.493504    \n",
      "[10]\tvalid's ndcg@1: 0.51255\tvalid's ndcg@2: 0.505958\tvalid's ndcg@3: 0.496668    \n",
      "[15]\tvalid's ndcg@1: 0.511229\tvalid's ndcg@2: 0.507192\tvalid's ndcg@3: 0.498303   \n",
      "[20]\tvalid's ndcg@1: 0.513871\tvalid's ndcg@2: 0.503607\tvalid's ndcg@3: 0.494772   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.076928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.519815\tvalid's ndcg@2: 0.502236\tvalid's ndcg@3: 0.495093    \n",
      "[10]\tvalid's ndcg@1: 0.518494\tvalid's ndcg@2: 0.507464\tvalid's ndcg@3: 0.496467   \n",
      "[15]\tvalid's ndcg@1: 0.51321\tvalid's ndcg@2: 0.50573\tvalid's ndcg@3: 0.497272     \n",
      "[20]\tvalid's ndcg@1: 0.509247\tvalid's ndcg@2: 0.506205\tvalid's ndcg@3: 0.497365   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.540951\tvalid's ndcg@2: 0.517778\tvalid's ndcg@3: 0.50076\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.070736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.521797\tvalid's ndcg@2: 0.508561\tvalid's ndcg@3: 0.497358    \n",
      "[10]\tvalid's ndcg@1: 0.519815\tvalid's ndcg@2: 0.513774\tvalid's ndcg@3: 0.50196    \n",
      "[15]\tvalid's ndcg@1: 0.52576\tvalid's ndcg@2: 0.511569\tvalid's ndcg@3: 0.500288    \n",
      "[20]\tvalid's ndcg@1: 0.514531\tvalid's ndcg@2: 0.509028\tvalid's ndcg@3: 0.502171   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.542933\tvalid's ndcg@2: 0.521965\tvalid's ndcg@3: 0.507486\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.012181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.516513\tvalid's ndcg@2: 0.497051\tvalid's ndcg@3: 0.491143    \n",
      "[10]\tvalid's ndcg@1: 0.525099\tvalid's ndcg@2: 0.504426\tvalid's ndcg@3: 0.497784   \n",
      "[15]\tvalid's ndcg@1: 0.510568\tvalid's ndcg@2: 0.500277\tvalid's ndcg@3: 0.496941   \n",
      "[20]\tvalid's ndcg@1: 0.51321\tvalid's ndcg@2: 0.504708\tvalid's ndcg@3: 0.498536    \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.540951\tvalid's ndcg@2: 0.517778\tvalid's ndcg@3: 0.50076\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.060073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.514531\tvalid's ndcg@2: 0.500435\tvalid's ndcg@3: 0.489611     \n",
      "[10]\tvalid's ndcg@1: 0.510568\tvalid's ndcg@2: 0.500883\tvalid's ndcg@3: 0.489672    \n",
      "[15]\tvalid's ndcg@1: 0.505945\tvalid's ndcg@2: 0.49747\tvalid's ndcg@3: 0.493133     \n",
      "[20]\tvalid's ndcg@1: 0.511229\tvalid's ndcg@2: 0.501732\tvalid's ndcg@3: 0.495535    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.059314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.51321\tvalid's ndcg@2: 0.504452\tvalid's ndcg@3: 0.492973      \n",
      "[10]\tvalid's ndcg@1: 0.51321\tvalid's ndcg@2: 0.504103\tvalid's ndcg@3: 0.493534     \n",
      "[15]\tvalid's ndcg@1: 0.51255\tvalid's ndcg@2: 0.504625\tvalid's ndcg@3: 0.499671     \n",
      "[20]\tvalid's ndcg@1: 0.509908\tvalid's ndcg@2: 0.505494\tvalid's ndcg@3: 0.495868    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.540951\tvalid's ndcg@2: 0.517778\tvalid's ndcg@3: 0.50076\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.059721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.503303\tvalid's ndcg@2: 0.500072\tvalid's ndcg@3: 0.492531     \n",
      "[10]\tvalid's ndcg@1: 0.511229\tvalid's ndcg@2: 0.501893\tvalid's ndcg@3: 0.496837    \n",
      "[15]\tvalid's ndcg@1: 0.516513\tvalid's ndcg@2: 0.501206\tvalid's ndcg@3: 0.495111    \n",
      "[20]\tvalid's ndcg@1: 0.518494\tvalid's ndcg@2: 0.504815\tvalid's ndcg@3: 0.499912    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.124058 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.503303\tvalid's ndcg@2: 0.503838\tvalid's ndcg@3: 0.492178     \n",
      "[10]\tvalid's ndcg@1: 0.506605\tvalid's ndcg@2: 0.50078\tvalid's ndcg@3: 0.49283      \n",
      "[15]\tvalid's ndcg@1: 0.513871\tvalid's ndcg@2: 0.503607\tvalid's ndcg@3: 0.497198    \n",
      "[20]\tvalid's ndcg@1: 0.511229\tvalid's ndcg@2: 0.503615\tvalid's ndcg@3: 0.495179    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.064903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.506605\tvalid's ndcg@2: 0.497203\tvalid's ndcg@3: 0.486521     \n",
      "[10]\tvalid's ndcg@1: 0.51321\tvalid's ndcg@2: 0.50183\tvalid's ndcg@3: 0.493617      \n",
      "[15]\tvalid's ndcg@1: 0.515192\tvalid's ndcg@2: 0.506111\tvalid's ndcg@3: 0.497223    \n",
      "[20]\tvalid's ndcg@1: 0.514531\tvalid's ndcg@2: 0.507723\tvalid's ndcg@3: 0.495853    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.072753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.508587\tvalid's ndcg@2: 0.499506\tvalid's ndcg@3: 0.488573     \n",
      "[10]\tvalid's ndcg@1: 0.513871\tvalid's ndcg@2: 0.503701\tvalid's ndcg@3: 0.491525    \n",
      "[15]\tvalid's ndcg@1: 0.515852\tvalid's ndcg@2: 0.505172\tvalid's ndcg@3: 0.494866    \n",
      "[20]\tvalid's ndcg@1: 0.513871\tvalid's ndcg@2: 0.503957\tvalid's ndcg@3: 0.493336    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.067356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.517173\tvalid's ndcg@2: 0.507044\tvalid's ndcg@3: 0.49208      \n",
      "[10]\tvalid's ndcg@1: 0.513871\tvalid's ndcg@2: 0.505113\tvalid's ndcg@3: 0.495569    \n",
      "[15]\tvalid's ndcg@1: 0.51255\tvalid's ndcg@2: 0.505419\tvalid's ndcg@3: 0.495171     \n",
      "[20]\tvalid's ndcg@1: 0.522457\tvalid's ndcg@2: 0.506317\tvalid's ndcg@3: 0.49892     \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.058961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.521797\tvalid's ndcg@2: 0.501407\tvalid's ndcg@3: 0.492781     \n",
      "[10]\tvalid's ndcg@1: 0.519815\tvalid's ndcg@2: 0.50393\tvalid's ndcg@3: 0.493228     \n",
      "[15]\tvalid's ndcg@1: 0.519815\tvalid's ndcg@2: 0.504697\tvalid's ndcg@3: 0.493877    \n",
      "[20]\tvalid's ndcg@1: 0.51255\tvalid's ndcg@2: 0.505325\tvalid's ndcg@3: 0.493887     \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.061233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.508587\tvalid's ndcg@2: 0.49964\tvalid's ndcg@3: 0.488159     \n",
      "[10]\tvalid's ndcg@1: 0.501321\tvalid's ndcg@2: 0.49403\tvalid's ndcg@3: 0.489041    \n",
      "[15]\tvalid's ndcg@1: 0.521136\tvalid's ndcg@2: 0.503946\tvalid's ndcg@3: 0.497286   \n",
      "[20]\tvalid's ndcg@1: 0.525099\tvalid's ndcg@2: 0.505515\tvalid's ndcg@3: 0.50088    \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.132820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.522457\tvalid's ndcg@2: 0.501879\tvalid's ndcg@3: 0.493233    \n",
      "[10]\tvalid's ndcg@1: 0.525099\tvalid's ndcg@2: 0.507198\tvalid's ndcg@3: 0.498354   \n",
      "[15]\tvalid's ndcg@1: 0.521136\tvalid's ndcg@2: 0.509595\tvalid's ndcg@3: 0.49851    \n",
      "[20]\tvalid's ndcg@1: 0.520476\tvalid's ndcg@2: 0.509957\tvalid's ndcg@3: 0.498539   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.542933\tvalid's ndcg@2: 0.521965\tvalid's ndcg@3: 0.507486\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.012431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.520476\tvalid's ndcg@2: 0.506191\tvalid's ndcg@3: 0.491899    \n",
      "[10]\tvalid's ndcg@1: 0.521797\tvalid's ndcg@2: 0.509045\tvalid's ndcg@3: 0.496722   \n",
      "[15]\tvalid's ndcg@1: 0.516513\tvalid's ndcg@2: 0.511332\tvalid's ndcg@3: 0.499662   \n",
      "[20]\tvalid's ndcg@1: 0.509908\tvalid's ndcg@2: 0.505332\tvalid's ndcg@3: 0.497802   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.012326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.517834\tvalid's ndcg@2: 0.497471\tvalid's ndcg@3: 0.492154    \n",
      "[10]\tvalid's ndcg@1: 0.516513\tvalid's ndcg@2: 0.501111\tvalid's ndcg@3: 0.492817   \n",
      "[15]\tvalid's ndcg@1: 0.511229\tvalid's ndcg@2: 0.497616\tvalid's ndcg@3: 0.494206   \n",
      "[20]\tvalid's ndcg@1: 0.517834\tvalid's ndcg@2: 0.50406\tvalid's ndcg@3: 0.499795    \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.017125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.516513\tvalid's ndcg@2: 0.505577\tvalid's ndcg@3: 0.493607    \n",
      "[10]\tvalid's ndcg@1: 0.506605\tvalid's ndcg@2: 0.500658\tvalid's ndcg@3: 0.494197   \n",
      "[15]\tvalid's ndcg@1: 0.506605\tvalid's ndcg@2: 0.499825\tvalid's ndcg@3: 0.495209   \n",
      "[20]\tvalid's ndcg@1: 0.505945\tvalid's ndcg@2: 0.503091\tvalid's ndcg@3: 0.497073   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.065853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.518494\tvalid's ndcg@2: 0.505165\tvalid's ndcg@3: 0.496263    \n",
      "[10]\tvalid's ndcg@1: 0.520476\tvalid's ndcg@2: 0.507724\tvalid's ndcg@3: 0.496498   \n",
      "[15]\tvalid's ndcg@1: 0.52576\tvalid's ndcg@2: 0.511219\tvalid's ndcg@3: 0.500341    \n",
      "[20]\tvalid's ndcg@1: 0.523778\tvalid's ndcg@2: 0.510543\tvalid's ndcg@3: 0.499154   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.072185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 45821                                                                  \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 83611, number of used features: 172       \n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.509247\tvalid's ndcg@2: 0.494062\tvalid's ndcg@3: 0.491044    \n",
      "[10]\tvalid's ndcg@1: 0.506605\tvalid's ndcg@2: 0.491031\tvalid's ndcg@3: 0.489713   \n",
      "[15]\tvalid's ndcg@1: 0.506605\tvalid's ndcg@2: 0.491286\tvalid's ndcg@3: 0.490731   \n",
      "[20]\tvalid's ndcg@1: 0.509908\tvalid's ndcg@2: 0.494117\tvalid's ndcg@3: 0.490967   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.012968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.508587\tvalid's ndcg@2: 0.495674\tvalid's ndcg@3: 0.493666     \n",
      "[10]\tvalid's ndcg@1: 0.507266\tvalid's ndcg@2: 0.493519\tvalid's ndcg@3: 0.488212    \n",
      "[15]\tvalid's ndcg@1: 0.510568\tvalid's ndcg@2: 0.498638\tvalid's ndcg@3: 0.490334    \n",
      "[20]\tvalid's ndcg@1: 0.517834\tvalid's ndcg@2: 0.500093\tvalid's ndcg@3: 0.495174    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.075298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.513871\tvalid's ndcg@2: 0.497758\tvalid's ndcg@3: 0.493796     \n",
      "[10]\tvalid's ndcg@1: 0.513871\tvalid's ndcg@2: 0.497341\tvalid's ndcg@3: 0.495657    \n",
      "[15]\tvalid's ndcg@1: 0.509908\tvalid's ndcg@2: 0.494561\tvalid's ndcg@3: 0.494349    \n",
      "[20]\tvalid's ndcg@1: 0.511889\tvalid's ndcg@2: 0.499676\tvalid's ndcg@3: 0.495585    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.016284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.517173\tvalid's ndcg@2: 0.502849\tvalid's ndcg@3: 0.493226     \n",
      "[10]\tvalid's ndcg@1: 0.513871\tvalid's ndcg@2: 0.504051\tvalid's ndcg@3: 0.49603     \n",
      "[15]\tvalid's ndcg@1: 0.527081\tvalid's ndcg@2: 0.507713\tvalid's ndcg@3: 0.501268    \n",
      "[20]\tvalid's ndcg@1: 0.525099\tvalid's ndcg@2: 0.513075\tvalid's ndcg@3: 0.504293    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.542933\tvalid's ndcg@2: 0.521965\tvalid's ndcg@3: 0.507486\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.012089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.521797\tvalid's ndcg@2: 0.501662\tvalid's ndcg@3: 0.492821     \n",
      "[10]\tvalid's ndcg@1: 0.518494\tvalid's ndcg@2: 0.502354\tvalid's ndcg@3: 0.493749    \n",
      "[15]\tvalid's ndcg@1: 0.511889\tvalid's ndcg@2: 0.500093\tvalid's ndcg@3: 0.489611    \n",
      "[20]\tvalid's ndcg@1: 0.51255\tvalid's ndcg@2: 0.502259\tvalid's ndcg@3: 0.491044     \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.012291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.513871\tvalid's ndcg@2: 0.500635\tvalid's ndcg@3: 0.493724     \n",
      "[10]\tvalid's ndcg@1: 0.509247\tvalid's ndcg@2: 0.494828\tvalid's ndcg@3: 0.491212    \n",
      "[15]\tvalid's ndcg@1: 0.516513\tvalid's ndcg@2: 0.503022\tvalid's ndcg@3: 0.494638    \n",
      "[20]\tvalid's ndcg@1: 0.513871\tvalid's ndcg@2: 0.504629\tvalid's ndcg@3: 0.496681    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.014691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.505945\tvalid's ndcg@2: 0.49642\tvalid's ndcg@3: 0.489226      \n",
      "[10]\tvalid's ndcg@1: 0.524439\tvalid's ndcg@2: 0.502999\tvalid's ndcg@3: 0.498078    \n",
      "[15]\tvalid's ndcg@1: 0.518494\tvalid's ndcg@2: 0.505581\tvalid's ndcg@3: 0.4969      \n",
      "[20]\tvalid's ndcg@1: 0.519815\tvalid's ndcg@2: 0.506391\tvalid's ndcg@3: 0.496697    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.067501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.507926\tvalid's ndcg@2: 0.49964\tvalid's ndcg@3: 0.487874      \n",
      "[10]\tvalid's ndcg@1: 0.516513\tvalid's ndcg@2: 0.500722\tvalid's ndcg@3: 0.489921    \n",
      "[15]\tvalid's ndcg@1: 0.513871\tvalid's ndcg@2: 0.499519\tvalid's ndcg@3: 0.491772    \n",
      "[20]\tvalid's ndcg@1: 0.508587\tvalid's ndcg@2: 0.497718\tvalid's ndcg@3: 0.489902    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.074292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.513871\tvalid's ndcg@2: 0.498914\tvalid's ndcg@3: 0.491708     \n",
      "[10]\tvalid's ndcg@1: 0.522457\tvalid's ndcg@2: 0.505295\tvalid's ndcg@3: 0.497208    \n",
      "[15]\tvalid's ndcg@1: 0.520476\tvalid's ndcg@2: 0.505802\tvalid's ndcg@3: 0.495545    \n",
      "[20]\tvalid's ndcg@1: 0.51321\tvalid's ndcg@2: 0.503297\tvalid's ndcg@3: 0.494868     \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.069102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.51321\tvalid's ndcg@2: 0.504668\tvalid's ndcg@3: 0.493746      \n",
      "[10]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.515478\tvalid's ndcg@3: 0.504623    \n",
      "[15]\tvalid's ndcg@1: 0.52642\tvalid's ndcg@2: 0.516507\tvalid's ndcg@3: 0.505035     \n",
      "[20]\tvalid's ndcg@1: 0.52576\tvalid's ndcg@2: 0.516707\tvalid's ndcg@3: 0.504836     \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.542933\tvalid's ndcg@2: 0.521965\tvalid's ndcg@3: 0.507486\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.067195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.509247\tvalid's ndcg@2: 0.502911\tvalid's ndcg@3: 0.493669     \n",
      "[10]\tvalid's ndcg@1: 0.509908\tvalid's ndcg@2: 0.504593\tvalid's ndcg@3: 0.496509    \n",
      "[15]\tvalid's ndcg@1: 0.517834\tvalid's ndcg@2: 0.510542\tvalid's ndcg@3: 0.501027    \n",
      "[20]\tvalid's ndcg@1: 0.515852\tvalid's ndcg@2: 0.509072\tvalid's ndcg@3: 0.499469    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.017178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.511889\tvalid's ndcg@2: 0.494337\tvalid's ndcg@3: 0.489873     \n",
      "[10]\tvalid's ndcg@1: 0.509908\tvalid's ndcg@2: 0.49955\tvalid's ndcg@3: 0.492459     \n",
      "[15]\tvalid's ndcg@1: 0.518494\tvalid's ndcg@2: 0.507047\tvalid's ndcg@3: 0.498704    \n",
      "[20]\tvalid's ndcg@1: 0.518494\tvalid's ndcg@2: 0.506859\tvalid's ndcg@3: 0.499415    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.072056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.503963\tvalid's ndcg@2: 0.497116\tvalid's ndcg@3: 0.490732     \n",
      "[10]\tvalid's ndcg@1: 0.514531\tvalid's ndcg@2: 0.504106\tvalid's ndcg@3: 0.498555    \n",
      "[15]\tvalid's ndcg@1: 0.515192\tvalid's ndcg@2: 0.505856\tvalid's ndcg@3: 0.496973    \n",
      "[20]\tvalid's ndcg@1: 0.509908\tvalid's ndcg@2: 0.503732\tvalid's ndcg@3: 0.496514    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.013731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.509908\tvalid's ndcg@2: 0.494978\tvalid's ndcg@3: 0.48839      \n",
      "[10]\tvalid's ndcg@1: 0.515852\tvalid's ndcg@2: 0.502456\tvalid's ndcg@3: 0.496237    \n",
      "[15]\tvalid's ndcg@1: 0.519815\tvalid's ndcg@2: 0.504724\tvalid's ndcg@3: 0.495179    \n",
      "[20]\tvalid's ndcg@1: 0.515192\tvalid's ndcg@2: 0.502467\tvalid's ndcg@3: 0.495032    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.064695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.518494\tvalid's ndcg@2: 0.500821\tvalid's ndcg@3: 0.494435     \n",
      "[10]\tvalid's ndcg@1: 0.508587\tvalid's ndcg@2: 0.502734\tvalid's ndcg@3: 0.493845    \n",
      "[15]\tvalid's ndcg@1: 0.511889\tvalid's ndcg@2: 0.503737\tvalid's ndcg@3: 0.497919    \n",
      "[20]\tvalid's ndcg@1: 0.507926\tvalid's ndcg@2: 0.50354\tvalid's ndcg@3: 0.496564     \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.540951\tvalid's ndcg@2: 0.517778\tvalid's ndcg@3: 0.50076\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.070109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.505945\tvalid's ndcg@2: 0.500119\tvalid's ndcg@3: 0.493593     \n",
      "[10]\tvalid's ndcg@1: 0.527081\tvalid's ndcg@2: 0.50938\tvalid's ndcg@3: 0.501181     \n",
      "[15]\tvalid's ndcg@1: 0.519815\tvalid's ndcg@2: 0.508368\tvalid's ndcg@3: 0.498002    \n",
      "[20]\tvalid's ndcg@1: 0.523778\tvalid's ndcg@2: 0.50901\tvalid's ndcg@3: 0.501787     \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.069563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.515192\tvalid's ndcg@2: 0.499952\tvalid's ndcg@3: 0.495286     \n",
      "[10]\tvalid's ndcg@1: 0.518494\tvalid's ndcg@2: 0.504209\tvalid's ndcg@3: 0.498454    \n",
      "[15]\tvalid's ndcg@1: 0.515192\tvalid's ndcg@2: 0.507578\tvalid's ndcg@3: 0.49843     \n",
      "[20]\tvalid's ndcg@1: 0.515192\tvalid's ndcg@2: 0.507295\tvalid's ndcg@3: 0.498966    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.520077\tvalid's ndcg@3: 0.502421\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.012274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.513871\tvalid's ndcg@2: 0.500541\tvalid's ndcg@3: 0.490915     \n",
      "[10]\tvalid's ndcg@1: 0.517173\tvalid's ndcg@2: 0.495856\tvalid's ndcg@3: 0.492533    \n",
      "[15]\tvalid's ndcg@1: 0.511889\tvalid's ndcg@2: 0.493638\tvalid's ndcg@3: 0.490465    \n",
      "[20]\tvalid's ndcg@1: 0.515192\tvalid's ndcg@2: 0.495663\tvalid's ndcg@3: 0.493543    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.540951\tvalid's ndcg@2: 0.517778\tvalid's ndcg@3: 0.50076\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.069934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.505284\tvalid's ndcg@2: 0.492882\tvalid's ndcg@3: 0.486789     \n",
      "[10]\tvalid's ndcg@1: 0.508587\tvalid's ndcg@2: 0.497301\tvalid's ndcg@3: 0.489239    \n",
      "[15]\tvalid's ndcg@1: 0.51255\tvalid's ndcg@2: 0.500014\tvalid's ndcg@3: 0.492998     \n",
      "[20]\tvalid's ndcg@1: 0.511889\tvalid's ndcg@2: 0.500698\tvalid's ndcg@3: 0.494607    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.535007\tvalid's ndcg@2: 0.519633\tvalid's ndcg@3: 0.502932\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.011825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.520476\tvalid's ndcg@2: 0.497558\tvalid's ndcg@3: 0.492761     \n",
      "[10]\tvalid's ndcg@1: 0.515852\tvalid's ndcg@2: 0.503761\tvalid's ndcg@3: 0.495289    \n",
      "[15]\tvalid's ndcg@1: 0.519815\tvalid's ndcg@2: 0.513318\tvalid's ndcg@3: 0.49736     \n",
      "[20]\tvalid's ndcg@1: 0.522457\tvalid's ndcg@2: 0.509639\tvalid's ndcg@3: 0.497099    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.542933\tvalid's ndcg@2: 0.521965\tvalid's ndcg@3: 0.507486\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.065366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.513871\tvalid's ndcg@2: 0.501657\tvalid's ndcg@3: 0.493551     \n",
      "[10]\tvalid's ndcg@1: 0.509247\tvalid's ndcg@2: 0.500517\tvalid's ndcg@3: 0.495956    \n",
      "[15]\tvalid's ndcg@1: 0.509247\tvalid's ndcg@2: 0.504927\tvalid's ndcg@3: 0.49788     \n",
      "[20]\tvalid's ndcg@1: 0.503303\tvalid's ndcg@2: 0.503421\tvalid's ndcg@3: 0.497848    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.542933\tvalid's ndcg@2: 0.521965\tvalid's ndcg@3: 0.507486\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.012070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.519815\tvalid's ndcg@2: 0.509713\tvalid's ndcg@3: 0.498215     \n",
      "[10]\tvalid's ndcg@1: 0.521136\tvalid's ndcg@2: 0.510967\tvalid's ndcg@3: 0.502399    \n",
      "[15]\tvalid's ndcg@1: 0.530383\tvalid's ndcg@2: 0.513382\tvalid's ndcg@3: 0.502911    \n",
      "[20]\tvalid's ndcg@1: 0.524439\tvalid's ndcg@2: 0.512359\tvalid's ndcg@3: 0.501613    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.542933\tvalid's ndcg@2: 0.521965\tvalid's ndcg@3: 0.507486\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.065967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.529062\tvalid's ndcg@2: 0.506762\tvalid's ndcg@3: 0.502206     \n",
      "[10]\tvalid's ndcg@1: 0.529062\tvalid's ndcg@2: 0.510367\tvalid's ndcg@3: 0.503717    \n",
      "[15]\tvalid's ndcg@1: 0.522457\tvalid's ndcg@2: 0.508522\tvalid's ndcg@3: 0.50128     \n",
      "[20]\tvalid's ndcg@1: 0.519815\tvalid's ndcg@2: 0.505786\tvalid's ndcg@3: 0.499989    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.542933\tvalid's ndcg@2: 0.521965\tvalid's ndcg@3: 0.507486\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.068400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.519155\tvalid's ndcg@2: 0.503808\tvalid's ndcg@3: 0.496357     \n",
      "[10]\tvalid's ndcg@1: 0.511889\tvalid's ndcg@2: 0.501842\tvalid's ndcg@3: 0.497913    \n",
      "[15]\tvalid's ndcg@1: 0.518494\tvalid's ndcg@2: 0.502448\tvalid's ndcg@3: 0.497687    \n",
      "[20]\tvalid's ndcg@1: 0.514531\tvalid's ndcg@2: 0.504779\tvalid's ndcg@3: 0.496856    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.542933\tvalid's ndcg@2: 0.521965\tvalid's ndcg@3: 0.507486\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.061220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.514531\tvalid's ndcg@2: 0.504173\tvalid's ndcg@3: 0.4969       \n",
      "[10]\tvalid's ndcg@1: 0.517173\tvalid's ndcg@2: 0.503871\tvalid's ndcg@3: 0.490443    \n",
      "[15]\tvalid's ndcg@1: 0.507926\tvalid's ndcg@2: 0.502746\tvalid's ndcg@3: 0.496348    \n",
      "[20]\tvalid's ndcg@1: 0.517834\tvalid's ndcg@2: 0.507126\tvalid's ndcg@3: 0.498328    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.542933\tvalid's ndcg@2: 0.521965\tvalid's ndcg@3: 0.507486\n",
      "Training start:                                                                    \n",
      "[LightGBM] [Warning]                                                               \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.075142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                  \n",
      "Total Bins 45821                                                                   \n",
      "[LightGBM] [Info]                                                                  \n",
      "Number of data points in the train set: 83611, number of used features: 172        \n",
      "Training until validation scores don't improve for 20 rounds                       \n",
      "[5]\tvalid's ndcg@1: 0.517173\tvalid's ndcg@2: 0.500777\tvalid's ndcg@3: 0.490222     \n",
      "[10]\tvalid's ndcg@1: 0.509908\tvalid's ndcg@2: 0.498461\tvalid's ndcg@3: 0.491719    \n",
      "[15]\tvalid's ndcg@1: 0.521797\tvalid's ndcg@2: 0.505495\tvalid's ndcg@3: 0.497568    \n",
      "[20]\tvalid's ndcg@1: 0.522457\tvalid's ndcg@2: 0.507339\tvalid's ndcg@3: 0.499573    \n",
      "Early stopping, best iteration is:                                                 \n",
      "[1]\tvalid's ndcg@1: 0.542933\tvalid's ndcg@2: 0.521965\tvalid's ndcg@3: 0.507486\n",
      "100%|██████████| 50/50 [02:23<00:00,  2.87s/trial, best loss: -0.49744374991711987]\n",
      "best parameters: {'lambdarank_truncation_level': 0, 'learning_rate': 0.03705171865722612}\n"
     ]
    }
   ],
   "source": [
    "# 欠損値は 0 とした\n",
    "train, test = split_data(r.data_c.fillna(0),test_size=0.2,rank_learning=False)\n",
    "# x_train = train.drop(['rank', 'date','体重','体重変化','単勝'], axis=1)\n",
    "x_train = train.drop(['rank', 'date','単勝'], axis=1)\n",
    "y_train = train['rank']\n",
    "\n",
    "x_test = test.drop(['rank', 'date','単勝'], axis=1)\n",
    "y_test = test['rank']\n",
    "\n",
    "train_query = x_train.groupby(x_train.index).size()\n",
    "test_query = x_test.groupby(x_test.index).size()\n",
    "\n",
    "\n",
    "train = lgb.Dataset(x_train, y_train, group=train_query)\n",
    "valid = lgb.Dataset(x_test, y_test, reference=train, group=test_query)\n",
    "trials = Trials()\n",
    "optimize(trials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1385f355",
   "metadata": {},
   "source": [
    "# Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e286b3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 45821\n",
      "[LightGBM] [Info] Number of data points in the train set: 83611, number of used features: 172\n"
     ]
    }
   ],
   "source": [
    "# 'lambdarank_truncation_level': 0, 'learning_rate': 0.03705171865722612\n",
    "lgbm_params = {\n",
    "    'lambdarank_truncation_level': 2,\n",
    "    'metric': 'ndcg',\n",
    "    'objective': 'lambdarank',\n",
    "    'ndcg_eval_at': [1,2,3],\n",
    "    'learning_rate':0.03705171865722612,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 777\n",
    "}\n",
    "\n",
    " #学習 \n",
    "train = lgb.Dataset(x_train, y_train, group=train_query)\n",
    "valid = lgb.Dataset(x_test, y_test, reference=train, group=test_query)\n",
    "\n",
    "lgb_rank = lgb.train(\n",
    "   lgbm_params,\n",
    "   train,\n",
    "   num_boost_round=100,\n",
    "#    valid_sets=valid,\n",
    "#    valid_names=['train'],\n",
    "#    early_stopping_rounds=20,\n",
    "#    verbose_eval=5\n",
    ")\n",
    "\n",
    "# early stopping -> test data ないと怒られる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5a38cc",
   "metadata": {},
   "source": [
    "# 福島"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "582846ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f037548c25e241b0adf67a6488aaa343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca9cf7b67234af4bf9fbcfd211895e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54affec469a6487a9fa4579c2734a3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625d1ef517544f63907830b262d8337d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>馬番</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>16</td>\n",
       "      <td>-0.347316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.487014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.613774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.641546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>12</td>\n",
       "      <td>-1.169239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>9</td>\n",
       "      <td>-1.173335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>13</td>\n",
       "      <td>-1.214738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.297549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>8</td>\n",
       "      <td>-1.335746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>7</td>\n",
       "      <td>-1.418716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>14</td>\n",
       "      <td>-1.469132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>15</td>\n",
       "      <td>-1.756284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.931996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.361873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>10</td>\n",
       "      <td>-2.428898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202203010307</th>\n",
       "      <td>11</td>\n",
       "      <td>-2.428898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              馬番    scores\n",
       "202203010307  16 -0.347316\n",
       "202203010307   6 -0.487014\n",
       "202203010307   1 -0.613774\n",
       "202203010307   5 -0.641546\n",
       "202203010307  12 -1.169239\n",
       "202203010307   9 -1.173335\n",
       "202203010307  13 -1.214738\n",
       "202203010307   2 -1.297549\n",
       "202203010307   8 -1.335746\n",
       "202203010307   7 -1.418716\n",
       "202203010307  14 -1.469132\n",
       "202203010307  15 -1.756284\n",
       "202203010307   4 -1.931996\n",
       "202203010307   3 -2.361873\n",
       "202203010307  10 -2.428898\n",
       "202203010307  11 -2.428898"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 東京\n",
    "race_id = 202203010307\n",
    "# race_id_list = ['2022070102{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "data =  ShutubaTable.scrape([str(race_id)], date)\n",
    "\n",
    "# race_id_list = ['2020010106{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "st = ShutubaTable(data)\n",
    "\n",
    "\n",
    "#前処理\n",
    "st.preprocessing()\n",
    "\n",
    "#馬の過去成績データ追加\n",
    "st.merge_horse_results(hr)\n",
    "\n",
    "#血統データ追加\n",
    "st.merge_peds(pe.peds_vec)\n",
    "\n",
    "#カテゴリ変数の処理\n",
    "# ここで初めてdeta_cができる\n",
    "st.process_categorical(r.le_horse, r.le_jockey, r.data_pe)\n",
    "sl = RankSimulater(lgb_rank)\n",
    "sl.return_pred_table(st.data_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298c2e39",
   "metadata": {},
   "source": [
    "# 阪神"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4782efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798a9612b6014bacbc94f8ecf0fe5de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc4454ab0944477bb39171334fe2fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b327b58e0c46499c888f5f1c77fc69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cdd447c73847e0b03a658148096709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>馬番</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202209020908</th>\n",
       "      <td>10</td>\n",
       "      <td>0.413193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202209020908</th>\n",
       "      <td>2</td>\n",
       "      <td>0.066315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202209020908</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.067301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202209020908</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.131124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202209020908</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.256977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202209020908</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.263322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202209020908</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.346877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202209020908</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.393592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202209020908</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.808658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202209020908</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.851345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202209020908</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.894834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202209020908</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.964796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202209020908</th>\n",
       "      <td>11</td>\n",
       "      <td>-1.040351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202209020908</th>\n",
       "      <td>6</td>\n",
       "      <td>-1.052602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202209020908</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.160124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              馬番    scores\n",
       "202209020908  10  0.413193\n",
       "202209020908   2  0.066315\n",
       "202209020908  15 -0.067301\n",
       "202209020908   1 -0.131124\n",
       "202209020908   4 -0.256977\n",
       "202209020908  12 -0.263322\n",
       "202209020908   5 -0.346877\n",
       "202209020908  14 -0.393592\n",
       "202209020908   8 -0.808658\n",
       "202209020908  13 -0.851345\n",
       "202209020908   7 -0.894834\n",
       "202209020908   9 -0.964796\n",
       "202209020908  11 -1.040351\n",
       "202209020908   6 -1.052602\n",
       "202209020908   3 -1.160124"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 東京\n",
    "race_id = 202209020908\n",
    "# race_id_list = ['2022070102{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "data =  ShutubaTable.scrape([str(race_id)], date)\n",
    "\n",
    "# race_id_list = ['2020010106{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "st = ShutubaTable(data)\n",
    "\n",
    "\n",
    "#前処理\n",
    "st.preprocessing()\n",
    "\n",
    "#馬の過去成績データ追加\n",
    "st.merge_horse_results(hr)\n",
    "\n",
    "#血統データ追加\n",
    "st.merge_peds(pe.peds_vec)\n",
    "\n",
    "#カテゴリ変数の処理\n",
    "# ここで初めてdeta_cができる\n",
    "st.process_categorical(r.le_horse, r.le_jockey, r.data_pe)\n",
    "sl = RankSimulater(lgb_rank)\n",
    "sl.return_pred_table(st.data_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebc00d0",
   "metadata": {},
   "source": [
    "# 東京"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d7091fe-528d-4964-91e1-8adb4dcda22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3352e351e12c4466bf19829d765ea7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc71559b637a4eb18efe2a3cd49ec7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27bf906238594fea8b882507a678b63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838e3b7af09b49cca95647282a0823c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>馬番</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202205020108</th>\n",
       "      <td>6</td>\n",
       "      <td>1.228955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202205020108</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.028493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202205020108</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.326073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202205020108</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.364029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202205020108</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.411081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202205020108</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.432029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202205020108</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.630979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202205020108</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.739869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202205020108</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.744779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202205020108</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.877849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202205020108</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.952914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202205020108</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.106052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202205020108</th>\n",
       "      <td>7</td>\n",
       "      <td>-1.258035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202205020108</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.451258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              馬番    scores\n",
       "202205020108   6  1.228955\n",
       "202205020108  12 -0.028493\n",
       "202205020108  11 -0.326073\n",
       "202205020108   9 -0.364029\n",
       "202205020108   2 -0.411081\n",
       "202205020108   8 -0.432029\n",
       "202205020108  10 -0.630979\n",
       "202205020108   5 -0.739869\n",
       "202205020108   4 -0.744779\n",
       "202205020108  14 -0.877849\n",
       "202205020108  13 -0.952914\n",
       "202205020108   1 -1.106052\n",
       "202205020108   7 -1.258035\n",
       "202205020108   3 -1.451258"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 東京\n",
    "race_id = 202205020108\n",
    "# race_id_list = ['2022070102{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "data =  ShutubaTable.scrape([str(race_id)], date)\n",
    "\n",
    "# race_id_list = ['2020010106{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "st = ShutubaTable(data)\n",
    "\n",
    "\n",
    "#前処理\n",
    "st.preprocessing()\n",
    "\n",
    "#馬の過去成績データ追加\n",
    "st.merge_horse_results(hr)\n",
    "\n",
    "#血統データ追加\n",
    "st.merge_peds(pe.peds_vec)\n",
    "\n",
    "#カテゴリ変数の処理\n",
    "# ここで初めてdeta_cができる\n",
    "st.process_categorical(r.le_horse, r.le_jockey, r.data_pe)\n",
    "sl = RankSimulater(lgb_rank)\n",
    "sl.return_pred_table(st.data_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb0ca11-eae4-4d5e-b833-3184f6e85f85",
   "metadata": {},
   "source": [
    "# 重要度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c64f0ed3-8651-4105-aa14-83bfa45b20c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               features  importances\n",
      "4              horse_id         2172\n",
      "5             jockey_id          407\n",
      "25      賞金_race_type_5R           81\n",
      "52      着順_race_type_9R           42\n",
      "11                賞金_5R           27\n",
      "10                着順_5R           26\n",
      "7                    体重           25\n",
      "24      着順_race_type_5R           23\n",
      "6                    年齢           23\n",
      "32             賞金_開催_5R           21\n",
      "38                着順_9R           18\n",
      "80    着順_race_type_allR           17\n",
      "53      賞金_race_type_9R           13\n",
      "40                着差_9R           10\n",
      "9               n_horse           10\n",
      "60             賞金_開催_9R            9\n",
      "12                着差_5R            9\n",
      "45     着順_course_len_9R            7\n",
      "73   着順_course_len_allR            7\n",
      "18     賞金_course_len_5R            6\n",
      "26      着差_race_type_5R            5\n",
      "74   賞金_course_len_allR            4\n",
      "68              着差_allR            4\n",
      "8                  体重変化            4\n",
      "46     賞金_course_len_9R            3\n",
      "39                賞金_9R            3\n",
      "17     着順_course_len_5R            3\n",
      "75   着差_course_len_allR            2\n",
      "95               peds_1            2\n",
      "103              peds_9            2\n"
     ]
    }
   ],
   "source": [
    "importances = pd.DataFrame(\n",
    "{'features' : x_train.columns, 'importances' : lgb_rank.feature_importance()})\n",
    "print(importances.sort_values('importances', ascending=False)[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb716e-ef27-4c7b-8854-c68efd89d7be",
   "metadata": {},
   "source": [
    "# Rank Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "19d8dbd3-4a97-47d0-91c9-e2001aafcb56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282178b367f94150a2df4ad8a22ef5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8e31afcb534f97a05b31dce7839b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202205020201   9 -0.058017\n",
      "202205020201   8 -0.446785\n",
      "202205020201   3 -0.734875\n",
      "actual\n",
      "                0              1                 2            3\n",
      "202205020201   単勝              9              170円          1人気\n",
      "202205020201   複勝         9 16 6    110円150円1,110円   1人気2人気10人気\n",
      "202205020201   枠連            5 8              310円          2人気\n",
      "202205020201   馬連           9 16              310円          1人気\n",
      "202205020201  ワイド  9 16 6 9 6 16  220円2,360円3,790円  2人気21人気27人気\n",
      "202205020201   馬単           9 16              500円          1人気\n",
      "202205020201  3連複         6 9 16            6,500円         16人気\n",
      "202205020201  3連単         9 16 6           13,640円         42人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202205020202   1 -0.349133\n",
      "202205020202   4 -0.792832\n",
      "202205020202   8 -1.297549\n",
      "actual\n",
      "                0                  1                 2            3\n",
      "202205020202   単勝                 16              640円          3人気\n",
      "202205020202   複勝           16 13 12      260円880円150円    5人気9人気1人気\n",
      "202205020202   枠連                7 8           12,410円         24人気\n",
      "202205020202   馬連              13 16           13,630円         27人気\n",
      "202205020202  ワイド  13 16 12 16 12 13  2,690円500円2,160円  23人気4人気18人気\n",
      "202205020202   馬単              16 13           18,950円         43人気\n",
      "202205020202  3連複           12 13 16           14,090円         36人気\n",
      "202205020202  3連単           16 13 12          132,680円        315人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202205020203  10 -0.338982\n",
      "202205020203  18 -0.775916\n",
      "202205020203   9 -1.297549\n",
      "actual\n",
      "                0                1                    2              3\n",
      "202205020203   単勝               18                 250円            2人気\n",
      "202205020203   複勝          18 13 9     170円1,810円3,000円    2人気13人気15人気\n",
      "202205020203   枠連              7 8               2,990円           10人気\n",
      "202205020203   馬連            13 18              15,140円           31人気\n",
      "202205020203  ワイド  13 18 9 18 9 13  3,880円6,540円89,990円  29人気43人気130人気\n",
      "202205020203   馬単            18 13              19,220円           44人気\n",
      "202205020203  3連複          9 13 18             516,120円          360人気\n",
      "202205020203  3連単          18 13 9           2,027,360円        1,592人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202205020204  14 -0.369842\n",
      "202205020204   8 -0.426359\n",
      "202205020204   1 -0.577423\n",
      "actual\n",
      "                0                1             2          3\n",
      "202205020204   単勝               14          190円        1人気\n",
      "202205020204   複勝          14 8 16  110円120円200円  1人気2人気5人気\n",
      "202205020204   枠連              4 7          290円        1人気\n",
      "202205020204   馬連             8 14          280円        1人気\n",
      "202205020204  ワイド  8 14 14 16 8 16  170円380円540円  1人気5人気7人気\n",
      "202205020204   馬単             14 8          490円        1人気\n",
      "202205020204  3連複          8 14 16          880円        3人気\n",
      "202205020204  3連単          14 8 16        2,750円        4人気\n",
      "profit 170\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202205020205   7 -0.099525\n",
      "202205020205  15 -0.793922\n",
      "202205020205   2 -1.211758\n",
      "actual\n",
      "                0              1             2          3\n",
      "202205020205   単勝              7          230円        1人気\n",
      "202205020205   複勝         7 9 15  110円190円110円  1人気4人気2人気\n",
      "202205020205   枠連            4 5        1,020円        5人気\n",
      "202205020205   馬連            7 9        1,130円        2人気\n",
      "202205020205  ワイド  7 9 7 15 9 15  290円150円410円  2人気1人気5人気\n",
      "202205020205   馬単            7 9        1,670円        3人気\n",
      "202205020205  3連複         7 9 15          650円        1人気\n",
      "202205020205  3連単         7 9 15        3,350円        8人気\n",
      "profit 150\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202205020206   5 -0.037881\n",
      "202205020206   8 -0.207460\n",
      "202205020206  14 -0.252366\n",
      "actual\n",
      "                0              1               2           3\n",
      "202205020206   単勝             14            160円         1人気\n",
      "202205020206   複勝         14 8 1    110円210円480円  1人気3人気10人気\n",
      "202205020206   枠連            4 7            250円         1人気\n",
      "202205020206   馬連           8 14            650円         2人気\n",
      "202205020206  ワイド  8 14 1 14 1 8  290円920円3,050円  1人気8人気30人気\n",
      "202205020206   馬単           14 8            740円         2人気\n",
      "202205020206  3連複         1 8 14          5,710円        21人気\n",
      "202205020206  3連単         14 8 1         12,440円        35人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202205020207   4 -0.218989\n",
      "202205020207   3 -0.452456\n",
      "202205020207   6 -0.555642\n",
      "actual\n",
      "                0            1             2          3\n",
      "202205020207   単勝            4          160円        1人気\n",
      "202205020207   複勝        4 1 5  110円140円180円  1人気2人気4人気\n",
      "202205020207   枠連          1 4          340円        1人気\n",
      "202205020207   馬連          1 4          350円        1人気\n",
      "202205020207  ワイド  1 4 4 5 1 5  160円280円460円  1人気3人気6人気\n",
      "202205020207   馬単          4 1          540円        1人気\n",
      "202205020207  3連複        1 4 5          690円        1人気\n",
      "202205020207  3連単        4 1 5        1,860円        1人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202205020208  10  0.961714\n",
      "202205020208   2 -0.120499\n",
      "202205020208   9 -0.468410\n",
      "actual\n",
      "                0                1                 2            3\n",
      "202205020208   単勝               10              630円          4人気\n",
      "202205020208   複勝          10 8 12      220円740円220円    2人気8人気3人気\n",
      "202205020208   枠連              6 7            6,300円         16人気\n",
      "202205020208   馬連             8 10           12,010円         24人気\n",
      "202205020208  ワイド  8 10 10 12 8 12  2,150円590円2,870円  21人気7人気25人気\n",
      "202205020208   馬単             10 8           18,370円         40人気\n",
      "202205020208  3連複          8 10 12           15,390円         36人気\n",
      "202205020208  3連単          10 8 12          126,900円        236人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202205020209   7  1.040890\n",
      "202205020209   9  0.942425\n",
      "202205020209   1  0.463078\n",
      "actual\n",
      "                0              1             2          3\n",
      "202205020209   単勝              1        1,130円        4人気\n",
      "202205020209   複勝         1 10 8  170円110円140円  4人気1人気3人気\n",
      "202205020209   枠連            1 8          650円        2人気\n",
      "202205020209   馬連           1 10          740円        3人気\n",
      "202205020209  ワイド  1 10 1 8 8 10  260円490円180円  3人気7人気1人気\n",
      "202205020209   馬単           1 10        2,430円        9人気\n",
      "202205020209  3連複         1 8 10          840円        3人気\n",
      "202205020209  3連単         1 10 8        8,900円       30人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202205020210  11  0.351231\n",
      "202205020210  15 -0.195857\n",
      "202205020210   3 -0.208198\n",
      "actual\n",
      "                0                1                 2            3\n",
      "202205020210   単勝                8              140円          1人気\n",
      "202205020210   複勝          8 16 12      110円650円150円   1人気12人気2人気\n",
      "202205020210   枠連              4 8              790円          4人気\n",
      "202205020210   馬連             8 16            3,320円         11人気\n",
      "202205020210  ワイド  8 16 8 12 12 16  1,110円210円3,490円  13人気1人気32人気\n",
      "202205020210   馬単             8 16            3,960円         14人気\n",
      "202205020210  3連複          8 12 16            5,160円         18人気\n",
      "202205020210  3連単          8 16 12           18,030円         49人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202205020211   4 -0.163561\n",
      "202205020211   6 -0.236922\n",
      "202205020211   7 -0.239021\n",
      "actual\n",
      "                0              1                   2             3\n",
      "202205020211   単勝              2              1,360円           5人気\n",
      "202205020211   複勝         2 3 14        380円270円610円     5人気4人気8人気\n",
      "202205020211   枠連            2 2              6,180円          23人気\n",
      "202205020211   馬連            2 3              5,710円          21人気\n",
      "202205020211  ワイド  2 3 2 14 3 14  1,940円6,130円3,100円  21人気51人気30人気\n",
      "202205020211   馬単            2 3             13,240円          44人気\n",
      "202205020211  3連複         2 3 14             46,490円         126人気\n",
      "202205020211  3連単         2 3 14            258,710円         636人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202205020212  15  0.540613\n",
      "202205020212  11  0.539390\n",
      "202205020212   8  0.475347\n",
      "actual\n",
      "                0                1                 2            3\n",
      "202205020212   単勝               14              360円          1人気\n",
      "202205020212   複勝          14 15 5    170円250円1,070円   1人気5人気11人気\n",
      "202205020212   枠連              7 8            1,100円          3人気\n",
      "202205020212   馬連            14 15            1,160円          2人気\n",
      "202205020212  ワイド  14 15 5 14 5 15  540円2,860円5,840円  4人気24人気49人気\n",
      "202205020212   馬単            14 15            2,030円          2人気\n",
      "202205020212  3連複          5 14 15           16,840円         43人気\n",
      "202205020212  3連単          14 15 5           50,460円        169人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202209021001   7 -0.137555\n",
      "202209021001   4 -0.390805\n",
      "202209021001   2 -1.109302\n",
      "actual\n",
      "                0              1                  2            3\n",
      "202209021001   単勝              7               130円          1人気\n",
      "202209021001   複勝         7 12 5     110円1,950円280円   1人気12人気5人気\n",
      "202209021001   枠連            5 7             1,570円          5人気\n",
      "202209021001   馬連           7 12             5,470円         13人気\n",
      "202209021001  ワイド  7 12 5 7 5 12  1,990円310円11,770円  17人気3人気49人気\n",
      "202209021001   馬単           7 12             6,600円         16人気\n",
      "202209021001  3連複         5 7 12            11,050円         32人気\n",
      "202209021001  3連単         7 12 5            42,900円        114人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202209021002   1 -0.082265\n",
      "202209021002  12 -0.380715\n",
      "202209021002  15 -0.650274\n",
      "actual\n",
      "                0                1                 2            3\n",
      "202209021002   単勝               12              320円          2人気\n",
      "202209021002   複勝          12 9 15      160円600円240円    2人気7人気4人気\n",
      "202209021002   枠連              5 6            2,780円          9人気\n",
      "202209021002   馬連             9 12            4,470円         13人気\n",
      "202209021002  ワイド  9 12 12 15 9 15  1,320円570円3,690円  14人気5人気28人気\n",
      "202209021002   馬単             12 9            7,800円         23人気\n",
      "202209021002  3連複          9 12 15           15,570円         39人気\n",
      "202209021002  3連単          12 9 15           62,280円        161人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202209021003   5 -0.318787\n",
      "202209021003   3 -0.460815\n",
      "202209021003   2 -0.691966\n",
      "actual\n",
      "                0            1                   2             3\n",
      "202209021003   単勝            6                990円           5人気\n",
      "202209021003   複勝        6 4 3        270円780円200円     5人気7人気2人気\n",
      "202209021003   枠連          3 4                490円           1人気\n",
      "202209021003   馬連          4 6             15,370円          35人気\n",
      "202209021003  ワイド  4 6 3 6 3 4  3,460円1,140円2,400円  29人気11人気20人気\n",
      "202209021003   馬単          6 4             27,340円          57人気\n",
      "202209021003  3連複        3 4 6             22,180円          60人気\n",
      "202209021003  3連単        6 4 3            159,940円         368人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202209021004   4 -0.112498\n",
      "202209021004  16 -0.121023\n",
      "202209021004   3 -0.487014\n",
      "actual\n",
      "                0              1             2          3\n",
      "202209021004   単勝             16          340円        2人気\n",
      "202209021004   複勝         16 2 4  130円280円120円  2人気5人気1人気\n",
      "202209021004   枠連            1 8        2,070円        7人気\n",
      "202209021004   馬連           2 16        2,590円        7人気\n",
      "202209021004  ワイド  2 16 4 16 2 4  780円230円550円  7人気1人気5人気\n",
      "202209021004   馬単           16 2        4,150円       13人気\n",
      "202209021004  3連複         2 4 16        1,620円        3人気\n",
      "202209021004  3連単         16 2 4       10,260円       19人気\n",
      "profit 780\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202209021005   3 -0.181415\n",
      "202209021005  16 -0.288583\n",
      "202209021005  15 -0.293850\n",
      "actual\n",
      "                0                1               2            3\n",
      "202209021005   単勝                9            700円          3人気\n",
      "202209021005   複勝          9 14 16    250円230円260円    5人気3人気6人気\n",
      "202209021005   枠連              5 7          1,870円         10人気\n",
      "202209021005   馬連             9 14          2,650円         11人気\n",
      "202209021005  ワイド  9 14 9 16 14 16  980円1,320円730円  11人気18人気7人気\n",
      "202209021005   馬単             9 14          4,840円         19人気\n",
      "202209021005  3連複          9 14 16          6,060円         16人気\n",
      "202209021005  3連単          9 14 16         32,670円        101人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202209021006  11 -0.145804\n",
      "202209021006   9 -0.229886\n",
      "202209021006  12 -0.252366\n",
      "actual\n",
      "                0                1             2          3\n",
      "202209021006   単勝               11          270円        1人気\n",
      "202209021006   複勝          11 12 2  120円150円200円  1人気3人気4人気\n",
      "202209021006   枠連              6 7          620円        2人気\n",
      "202209021006   馬連            11 12          640円        2人気\n",
      "202209021006  ワイド  11 12 2 11 2 12  320円450円680円  2人気4人気7人気\n",
      "202209021006   馬単            11 12        1,340円        4人気\n",
      "202209021006  3連複          2 11 12        2,380円        5人気\n",
      "202209021006  3連単          11 12 2        8,380円       12人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番   scores\n",
      "202209021007   2 -0.19718\n",
      "202209021007   5 -0.22825\n",
      "202209021007   6 -0.53768\n",
      "actual\n",
      "                0            1             2           3\n",
      "202209021007   単勝            6          650円         4人気\n",
      "202209021007   複勝        6 5 7  180円130円230円   4人気1人気5人気\n",
      "202209021007   枠連          5 6          470円         1人気\n",
      "202209021007   馬連          5 6          740円         3人気\n",
      "202209021007  ワイド  5 6 6 7 5 7  360円840円410円  3人気12人気5人気\n",
      "202209021007   馬単          6 5        1,660円         6人気\n",
      "202209021007  3連複        5 6 7        1,860円         7人気\n",
      "202209021007  3連単        6 5 7        9,500円        29人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202209021008   6 -0.182849\n",
      "202209021008  13 -0.255105\n",
      "202209021008   7 -0.499248\n",
      "actual\n",
      "                0            1             2          3\n",
      "202209021008   単勝            2          400円        2人気\n",
      "202209021008   複勝        2 6 7  150円140円180円  2人気1人気4人気\n",
      "202209021008   枠連          2 4          510円        1人気\n",
      "202209021008   馬連          2 6          600円        1人気\n",
      "202209021008  ワイド  2 6 2 7 6 7  260円550円410円  1人気5人気3人気\n",
      "202209021008   馬単          2 6        1,170円        1人気\n",
      "202209021008  3連複        2 6 7        1,430円        1人気\n",
      "202209021008  3連単        2 6 7        6,400円        2人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202209021009   5  0.638122\n",
      "202209021009   6 -0.194543\n",
      "202209021009   4 -0.330000\n",
      "actual\n",
      "                0            1             2          3\n",
      "202209021009   単勝            4          170円        1人気\n",
      "202209021009   複勝          4 7      110円250円     1人気4人気\n",
      "202209021009   馬連          4 7          640円        3人気\n",
      "202209021009  ワイド  4 7 4 5 5 7  200円120円230円  4人気1人気5人気\n",
      "202209021009   馬単          4 7        1,000円        4人気\n",
      "202209021009  3連複        4 5 7          280円        2人気\n",
      "202209021009  3連単        4 7 5        1,640円        6人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202209021010   5  1.156522\n",
      "202209021010   1 -0.114677\n",
      "202209021010  10 -0.151068\n",
      "actual\n",
      "                0              1                   2             3\n",
      "202209021010   単勝              8              1,690円           6人気\n",
      "202209021010   複勝         8 7 10        580円550円170円     8人気7人気1人気\n",
      "202209021010   枠連            4 5                960円           5人気\n",
      "202209021010   馬連            7 8             14,650円          35人気\n",
      "202209021010  ワイド  7 8 8 10 7 10  3,260円1,580円1,680円  33人気17人気18人気\n",
      "202209021010   馬単            8 7             28,050円          72人気\n",
      "202209021010  3連複         7 8 10             22,730円          69人気\n",
      "202209021010  3連単         8 7 10            204,980円         544人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202209021011   7  1.212988\n",
      "202209021011   4  0.434645\n",
      "202209021011   3  0.425608\n",
      "actual\n",
      "                0              1               2            3\n",
      "202209021011   単勝             13            780円          6人気\n",
      "202209021011   複勝         13 7 3    280円180円220円    6人気1人気3人気\n",
      "202209021011   枠連            4 7          1,190円          7人気\n",
      "202209021011   馬連           7 13          2,390円         12人気\n",
      "202209021011  ワイド  7 13 3 13 3 7  890円1,060円630円  12人気17人気3人気\n",
      "202209021011   馬単           13 7          5,200円         31人気\n",
      "202209021011  3連複         3 7 13          5,560円         23人気\n",
      "202209021011  3連単         13 7 3         31,970円        146人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202209021012   9 -0.186101\n",
      "202209021012   7 -0.310937\n",
      "202209021012   4 -0.453227\n",
      "actual\n",
      "                0                1                 2            3\n",
      "202209021012   単勝                7              350円          1人気\n",
      "202209021012   複勝          7 16 13      180円690円310円   1人気10人気5人気\n",
      "202209021012   枠連              4 8            1,830円          8人気\n",
      "202209021012   馬連             7 16            7,270円         26人気\n",
      "202209021012  ワイド  7 16 7 13 13 16  2,300円860円6,470円  26人気6人気66人気\n",
      "202209021012   馬単             7 16           10,250円         40人気\n",
      "202209021012  3連複          7 13 16           28,410円         95人気\n",
      "202209021012  3連単          7 16 13          136,510円        446人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202203010401   4 -0.163294\n",
      "202203010401   2 -0.786540\n",
      "202203010401  12 -0.798724\n",
      "actual\n",
      "                0                1                 2             3\n",
      "202203010401   単勝                5              940円           4人気\n",
      "202203010401   複勝          5 12 13      300円220円440円     4人気2人気5人気\n",
      "202203010401   枠連              3 7              430円           1人気\n",
      "202203010401   馬連             5 12            3,030円          12人気\n",
      "202203010401  ワイド  5 12 5 13 12 13  990円1,600円1,290円  10人気19人気15人気\n",
      "202203010401   馬単             5 12            5,750円          22人気\n",
      "202203010401  3連複          5 12 13           12,060円          36人気\n",
      "202203010401  3連単          5 12 13           63,110円         196人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202203010402   8 -0.367510\n",
      "202203010402  15 -0.557662\n",
      "202203010402   7 -0.857907\n",
      "actual\n",
      "                0            1                    2             3\n",
      "202203010402   単勝            8                 290円           1人気\n",
      "202203010402   複勝        8 5 1       190円1,530円670円    2人気12人気7人気\n",
      "202203010402   枠連          3 4               2,020円           8人気\n",
      "202203010402   馬連          5 8              11,500円          33人気\n",
      "202203010402  ワイド  5 8 1 8 1 5  3,920円1,470円14,910円  36人気14人気74人気\n",
      "202203010402   馬単          8 5              14,140円          43人気\n",
      "202203010402  3連複        1 5 8              59,200円         127人気\n",
      "202203010402  3連単        8 5 1             214,700円         514人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202203010403   4 -0.347316\n",
      "202203010403   2 -0.355188\n",
      "202203010403  10 -0.439029\n",
      "actual\n",
      "                0              1                   2             3\n",
      "202203010403   単勝              4                340円           2人気\n",
      "202203010403   複勝         4 6 12        150円640円570円     1人気9人気8人気\n",
      "202203010403   枠連            3 4              1,430円           4人気\n",
      "202203010403   馬連            4 6              3,970円          13人気\n",
      "202203010403  ワイド  4 6 4 12 6 12  1,470円1,670円7,070円  14人気19人気43人気\n",
      "202203010403   馬単            4 6              7,000円          26人気\n",
      "202203010403  3連複         4 6 12             25,930円          68人気\n",
      "202203010403  3連単         4 6 12            117,030円         325人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202203010404   3 -0.985909\n",
      "202203010404   4 -0.993896\n",
      "202203010404   9 -1.264832\n",
      "actual\n",
      "                0            1             2          3\n",
      "202203010404   単勝            2          830円        4人気\n",
      "202203010404   複勝        2 4 3  200円140円140円  4人気2人気1人気\n",
      "202203010404   枠連          2 3          930円        3人気\n",
      "202203010404   馬連          2 4        2,180円        8人気\n",
      "202203010404  ワイド  2 4 2 3 3 4  770円610円250円  9人気6人気1人気\n",
      "202203010404   馬単          2 4        3,770円       14人気\n",
      "202203010404  3連複        2 3 4        1,590円        2人気\n",
      "202203010404  3連単        2 4 3       10,440円       19人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202203010405  16 -0.217500\n",
      "202203010405   8 -0.360192\n",
      "202203010405   7 -0.644292\n",
      "actual\n",
      "                0              1                 2            3\n",
      "202203010405   単勝              8              180円          1人気\n",
      "202203010405   複勝         8 16 6      120円210円870円    1人気4人気9人気\n",
      "202203010405   枠連            4 8              610円          3人気\n",
      "202203010405   馬連           8 16              870円          4人気\n",
      "202203010405  ワイド  8 16 6 8 6 16  360円1,480円4,480円  3人気18人気36人気\n",
      "202203010405   馬単           8 16            1,120円          4人気\n",
      "202203010405  3連複         6 8 16            8,840円         25人気\n",
      "202203010405  3連単         8 16 6           23,730円         74人気\n",
      "profit 360\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202203010406  14 -0.518320\n",
      "202203010406   1 -0.528699\n",
      "202203010406  16 -0.618575\n",
      "actual\n",
      "                0              1                   2             3\n",
      "202203010406   単勝              9              4,970円          15人気\n",
      "202203010406   複勝         9 5 14      1,640円640円180円   16人気11人気2人気\n",
      "202203010406   枠連            3 5              9,160円          29人気\n",
      "202203010406   馬連            5 9             28,240円          92人気\n",
      "202203010406  ワイド  5 9 9 14 5 14  7,720円3,720円2,190円  90人気44人気25人気\n",
      "202203010406   馬単            9 5             63,760円         187人気\n",
      "202203010406  3連複         5 9 14             55,880円         206人気\n",
      "202203010406  3連単         9 5 14            420,090円       1,440人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202203010407   9 -0.182496\n",
      "202203010407   1 -0.429527\n",
      "202203010407   2 -0.500379\n",
      "actual\n",
      "                0              1               2             3\n",
      "202203010407   単勝             12            600円           4人気\n",
      "202203010407   複勝         12 6 9    210円260円250円     4人気6人気5人気\n",
      "202203010407   枠連            5 8          2,750円          12人気\n",
      "202203010407   馬連           6 12          4,090円          18人気\n",
      "202203010407  ワイド  6 12 9 12 6 9  1,240円940円940円  20人気14人気15人気\n",
      "202203010407   馬単           12 6          6,660円          30人気\n",
      "202203010407  3連複         6 9 12         11,390円          41人気\n",
      "202203010407  3連単         12 6 9         40,240円         156人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202203010408  12 -0.183013\n",
      "202203010408   5 -0.412901\n",
      "202203010408  13 -0.592678\n",
      "actual\n",
      "                0              1                 2            3\n",
      "202203010408   単勝             12              460円          2人気\n",
      "202203010408   複勝         12 5 2      160円150円660円   2人気1人気11人気\n",
      "202203010408   枠連            3 7              320円          1人気\n",
      "202203010408   馬連           5 12              670円          1人気\n",
      "202203010408  ワイド  5 12 2 12 2 5  300円2,870円1,580円  1人気31人気19人気\n",
      "202203010408   馬単           12 5            1,540円          3人気\n",
      "202203010408  3連複         2 5 12            6,790円         20人気\n",
      "202203010408  3連単         12 5 2           28,820円         77人気\n",
      "profit 300\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202203010409   5 -0.357094\n",
      "202203010409  14 -0.400065\n",
      "202203010409  16 -0.401832\n",
      "actual\n",
      "                0              1                 2            3\n",
      "202203010409   単勝              5              360円          1人気\n",
      "202203010409   複勝         5 7 13    170円250円1,360円   1人気5人気12人気\n",
      "202203010409   枠連            3 4              680円          1人気\n",
      "202203010409   馬連            5 7            1,400円          5人気\n",
      "202203010409  ワイド  5 7 5 13 7 13  680円3,130円6,410円  6人気32人気56人気\n",
      "202203010409   馬単            5 7            2,440円          5人気\n",
      "202203010409  3連複         5 7 13           27,140円         85人気\n",
      "202203010409  3連単         5 7 13           93,580円        306人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202203010410   6  0.041076\n",
      "202203010410   7 -0.340631\n",
      "202203010410  13 -0.378660\n",
      "actual\n",
      "                0            1                 2            3\n",
      "202203010410   単勝            6              440円          2人気\n",
      "202203010410   複勝        6 5 8      160円850円150円   2人気11人気1人気\n",
      "202203010410   枠連          3 3            9,880円         30人気\n",
      "202203010410   馬連          5 6           10,010円         37人気\n",
      "202203010410  ワイド  5 6 6 8 5 8  2,990円450円2,160円  37人気1人気27人気\n",
      "202203010410   馬単          6 5           14,990円         56人気\n",
      "202203010410  3連複        5 6 8            8,550円         28人気\n",
      "202203010410  3連単        6 5 8           77,530円        279人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202203010411   5  0.544768\n",
      "202203010411   7  0.299744\n",
      "202203010411   1 -0.121703\n",
      "actual\n",
      "                0              1                   2             3\n",
      "202203010411   単勝              8                530円           2人気\n",
      "202203010411   複勝         8 6 15        200円370円490円     1人気6人気8人気\n",
      "202203010411   枠連            3 4              2,880円          13人気\n",
      "202203010411   馬連            6 8              4,710円          22人気\n",
      "202203010411  ワイド  6 8 8 15 6 15  1,460円1,710円4,430円  16人気25人気51人気\n",
      "202203010411   馬単            8 6              7,830円          30人気\n",
      "202203010411  3連複         6 8 15             31,820円         113人気\n",
      "202203010411  3連単         8 6 15            131,650円         481人気\n",
      "-------------------\n",
      "predict\n",
      "              馬番    scores\n",
      "202203010412   3 -0.457053\n",
      "202203010412   8 -0.787603\n",
      "202203010412   5 -0.862145\n",
      "actual\n",
      "                0              1               2            3\n",
      "202203010412   単勝              6            880円          5人気\n",
      "202203010412   複勝         6 8 11    290円200円320円    5人気2人気6人気\n",
      "202203010412   枠連            5 6            910円          1人気\n",
      "202203010412   馬連            6 8          2,360円          7人気\n",
      "202203010412  ワイド  6 8 6 11 8 11  860円1,670円920円  7人気29人気10人気\n",
      "202203010412   馬単            6 8          4,920円         18人気\n",
      "202203010412  3連複         6 8 11          7,960円         28人気\n",
      "202203010412  3連単         6 8 11         44,490円        190人気\n",
      "---------------------\n",
      "単勝\n",
      "的中率 : 12 / 36\n",
      "収支   : 70 円\n",
      "的中レース ['01', '04', '05', '07', '08', '01', '06', '02', '03', '08', '09', '10']\n",
      "---------------------\n",
      "複勝\n",
      "的中率 : 20 / 36\n",
      "収支   : -410 円\n",
      "的中レース ['01', '04', '05', '07', '08', '12', '01', '04', '06', '08', '11', '02', '03', '04', '05', '06', '07', '08', '09', '10']\n",
      "---------------------\n",
      "ワイド\n",
      "的中率 : 5 / 36\n",
      "収支   : -1840 円\n",
      "的中レース ['04', '05', '04', '05', '08']\n"
     ]
    }
   ],
   "source": [
    "# data =  ShutubaTable.scrape(race_id_list, date)\n",
    "# st = ShutubaTable(data)\n",
    "# st.preprocessing()\n",
    "# st.merge_horse_results(hr)\n",
    "# st.merge_peds(pe.peds_vec)\n",
    "# st.process_categorical(r.le_horse, r.le_jockey, r.data_pe)\n",
    "sl = RankSimulater(lgb_rank)\n",
    "sl.return_table_today(race_id_list)\n",
    "sl.show_results(st ,race_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc1142-ff9b-4568-80b8-18ef0d9010c1",
   "metadata": {},
   "source": [
    "# fastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea29d7bf-5052-44dc-ac80-dea59ed65444",
   "metadata": {},
   "source": [
    "流れ\n",
    "1. fasttext用の血統データの学習データを作る (血統の情報のみ, index ヘッダはいらない)\n",
    "2. fasttext学習\n",
    "3. 学習モデルを使って, 血統データをベクトル化\n",
    "4. ベクトル化して r.data_cに concat\n",
    "5. 学習\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d375b9-e292-4d4a-97c2-905e3060419f",
   "metadata": {},
   "source": [
    "教師あり, 教師なしでも生成されるベクトルは等しい"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de5229f-9b05-4bc1-820a-0e275a1d6c8f",
   "metadata": {},
   "source": [
    "# model_ft 作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554f0c62-72c2-4a2e-b45e-b0b4d37c2e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 相対パスしかできない\n",
    "# dim : 出力の次元\n",
    "# minn : n_gramの最小単位\n",
    "# maxn : n_gramの最大単位\n",
    "model_ft = ft.train_unsupervised('test.txt',dim=62,minn=2,maxn=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "94807517-3ed5-427d-9886-72c42b7589cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.23876448e-05,  1.15252602e-04, -9.46200526e-05,  1.97496520e-05,\n",
       "       -3.14811296e-05,  6.10383358e-05,  3.84694722e-05,  4.08472006e-05,\n",
       "       -2.62596750e-05, -6.39620412e-05,  2.14720822e-05, -4.69113438e-05,\n",
       "        3.77046381e-05, -1.26615938e-04,  4.62611060e-05, -4.64162804e-05,\n",
       "       -1.04648252e-05,  8.02415016e-05,  5.22616428e-05,  2.21860992e-05,\n",
       "       -1.75977038e-05, -8.26951291e-05,  3.14370882e-05,  6.86578787e-05,\n",
       "       -3.35702607e-05,  1.14919050e-04, -8.21495541e-06, -9.01657186e-05,\n",
       "       -7.84629883e-05,  2.17205616e-05, -1.27823092e-04,  7.07987565e-05,\n",
       "        2.46920517e-05,  2.06759105e-05,  1.44077581e-04,  2.31686881e-05,\n",
       "       -3.09964562e-05, -7.95884553e-05, -4.59835537e-05, -1.93069845e-05,\n",
       "        3.55003340e-06,  1.18724784e-04, -6.99495213e-05, -5.45399816e-05,\n",
       "       -7.00177625e-05,  4.58251998e-05, -5.90208510e-05,  1.51029690e-05,\n",
       "        1.06203879e-05, -4.25494000e-05, -5.48500502e-05,  1.97607969e-05,\n",
       "       -1.11221507e-05, -1.12135414e-04, -6.92541580e-05, -3.56512865e-05,\n",
       "        4.80831432e-06, -1.21586090e-04, -5.42530252e-05,  9.49262467e-05,\n",
       "        6.24590248e-05,  6.67856802e-05], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_txt['hoge'] で 'hoge'の単語ベクトル入手\n",
    "model_ft[model_ft.words[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b63a1982-6425-4887-94bc-fcd793492242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8503,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.get_subwords(model_ft.words[1])[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "199fde55-17f7-4ecf-9f0f-58682ea4712a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>',\n",
       " 'ディープインパクト,クロウキャニオン,サンデーサイレンス,ウインドインハーヘア,フレンチデピュティ,クロカミ,Halo,WishingWell,Alzao,Burghclere,DeputyMinister,Mitterand,Caerleon,ミルド,HailtoReason,Cosmah,Understanding,MountainFlower,Lyphard,LadyRebecca,Busted,Highclere,ViceRegent,MintCopy,HoldYourPeace,LaredoLass,Nijinsky,Foreseer,DesertWine,MargieBelle,Turnto,Nothirdchance,CosmicBomb,Almahmoud,PromisedLand,PrettyWays,Montparnasse,Edelweiss,NorthernDancer,Goofed,SirIvor,Pocahontas,Crepello,SansleSou,QueensHussar,Highlight,NorthernDancer,VictoriaRegina,BuntysFlight,Shakney,SpeakJohn,BlueMoon,BoldRuler,FortunateIsle,NorthernDancer,FlamingPage,RoundTable,RegalGleam,Damascus,AnneCampbell,VaguelyNoble,Margravine',\n",
       " 'ディープインパクト,ロベルタ,サンデーサイレンス,ウインドインハーヘア,ブライアンズタイム,グレースアドマイヤ,Halo,WishingWell,Alzao,Burghclere,Roberto,KelleysDay,トニービン,バレークイーン,HailtoReason,Cosmah,Understanding,MountainFlower,Lyphard,LadyRebecca,Busted,Highclere,HailtoReason,Bramalea,Graustark,GoldenTrail,カンパラ,SevernBridge,SadlersWells,SunPrincess,Turnto,Nothirdchance,CosmicBomb,Almahmoud,PromisedLand,PrettyWays,Montparnasse,Edelweiss,NorthernDancer,Goofed,SirIvor,Pocahontas,Crepello,SansleSou,QueensHussar,Highlight,Turnto,Nothirdchance,Nashua,Rarelea,Ribot,FlowerBowl,HastyRoad,SunnyVale,Kalamoun,StatePension,Hornbeam,PriddyFair,NorthernDancer,FairyBridge,イングリッシュプリンス,SunnyValley',\n",
       " 'ディープインパクト,ナイトマジック,サンデーサイレンス,ウインドインハーヘア,Sholokhov,NightWoman,Halo,WishingWell,Alzao,Burghclere,SadlersWells,LaMeilleure,Monsun,Noveka,HailtoReason,Cosmah,Understanding,MountainFlower,Lyphard,LadyRebecca,Busted,Highclere,NorthernDancer,FairyBridge,LordGayle,Gradille,Konigsstuhl,Mosella,Kalaglow,Novelle,Turnto,Nothirdchance,CosmicBomb,Almahmoud,PromisedLand,PrettyWays,Montparnasse,Edelweiss,NorthernDancer,Goofed,SirIvor,Pocahontas,Crepello,SansleSou,QueensHussar,Highlight,Nearctic,Natalma,BoldReason,Special,SirGaylord,StickyCase,HomeGuard,Gradiva,DschingisKhan,Konigskronung,Surumu,Monasia,Kalamoun,Rossitor,Northfields,Nigeria',\n",
       " 'ディープインパクト,シユーマ,サンデーサイレンス,ウインドインハーヘア,Medicean,Sichilla,Halo,WishingWell,Alzao,Burghclere,Machiavellian,MysticGoddess,デインヒル,SlipstreamQueen,HailtoReason,Cosmah,Understanding,MountainFlower,Lyphard,LadyRebecca,Busted,Highclere,MrProspector,CoupdeFolie,StormBird,RoseGoddess,Danzig,Razyana,ConquistadorCielo,CountryQueen,Turnto,Nothirdchance,CosmicBomb,Almahmoud,PromisedLand,PrettyWays,Montparnasse,Edelweiss,NorthernDancer,Goofed,SirIvor,Pocahontas,Crepello,SansleSou,QueensHussar,Highlight,RaiseaNative,GoldDigger,Halo,RaisetheStandard,NorthernDancer,SouthOcean,Sassafras,Cocarde,NorthernDancer,PasdeNom,HisMajesty,SpringAdieu,MrProspector,KDPrincess,イクスプロウデント,CarriesRough',\n",
       " 'ディープインパクト,ミスアンコール,サンデーサイレンス,ウインドインハーヘア,キングカメハメハ,ブロードアピール,Halo,WishingWell,Alzao,Burghclere,Kingmambo,マンファス,BroadBrush,ValidAllure,HailtoReason,Cosmah,Understanding,MountainFlower,Lyphard,LadyRebecca,Busted,Highclere,MrProspector,Miesque,ラストタイクーン,PilotBird,AckAck,HayPatcher,ValidAppeal,AlluringGirl,Turnto,Nothirdchance,CosmicBomb,Almahmoud,PromisedLand,PrettyWays,Montparnasse,Edelweiss,NorthernDancer,Goofed,SirIvor,Pocahontas,Crepello,SansleSou,QueensHussar,Highlight,RaiseaNative,GoldDigger,Nureyev,Pasadoble,トライマイベスト,MillPrincess,Blakeney,TheDancer,BattleJoined,FastTurn,HoisttheFlag,TurntoTalent,InReality,DesertTrial,Secretariat,WaterCress']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1e2be52-3b04-4390-9769-c63ce59a643d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.5724351e-03,  2.1741162e-03, -6.2224795e-03,  7.9450803e-03,\n",
       "        9.2663774e-03,  1.2499948e-03, -1.9003255e-03, -1.4434209e-03,\n",
       "       -7.0348015e-04, -2.3646757e-03,  8.4775481e-03,  7.6517521e-04,\n",
       "        1.2443915e-04,  6.6868594e-04, -2.2353258e-03, -3.1006148e-03,\n",
       "       -5.1603146e-04, -6.8897572e-03,  8.9530461e-03,  6.7916275e-03,\n",
       "        2.7701540e-03, -1.4256138e-03,  9.4705867e-03, -9.9947751e-03,\n",
       "       -4.6277489e-03, -7.6256958e-03,  7.5081405e-03, -3.4463892e-03,\n",
       "       -3.8665808e-03,  1.7099102e-03,  9.7447438e-03, -7.7348817e-03,\n",
       "       -2.9115018e-04, -3.1618846e-03,  6.5541668e-03, -7.9466682e-03,\n",
       "       -5.2352938e-05, -8.1277534e-04, -1.2927600e-03, -9.0491874e-03,\n",
       "       -4.8794332e-03, -1.3042025e-03, -8.9057656e-03, -2.9853662e-03,\n",
       "        6.7775971e-03,  9.9755134e-03, -2.7005693e-03,  5.2640764e-03,\n",
       "       -6.6113472e-03,  5.9692696e-04, -9.7892229e-03, -4.3281284e-03,\n",
       "        6.6364333e-03, -9.9991390e-04,  3.3466963e-03, -7.2530257e-03,\n",
       "        1.4511276e-03,  9.4374539e-03,  6.8324972e-03,  1.0399714e-03,\n",
       "        6.0194843e-03,  5.8186194e-03,  3.8527260e-03,  6.5378621e-03,\n",
       "       -3.9170850e-03,  9.6854856e-03,  4.2792736e-03,  7.6427357e-04,\n",
       "       -4.8055393e-03,  9.4173355e-03,  9.0470780e-03,  9.1776745e-03,\n",
       "        6.0645705e-03, -7.4923565e-03, -2.5749654e-03, -1.7557642e-03,\n",
       "        3.6343501e-04,  7.6567060e-03,  4.2951941e-03, -5.3092451e-03,\n",
       "       -2.7257178e-03,  5.8091432e-03, -3.5633314e-03, -3.1582750e-03,\n",
       "        9.5966822e-03, -6.4879083e-03, -3.9101331e-03,  4.1160994e-04,\n",
       "       -7.1197501e-03, -2.3638823e-03, -5.1401439e-03,  3.2334772e-03,\n",
       "        7.0011085e-03, -8.3606951e-03, -9.8121529e-03, -9.1953417e-03,\n",
       "        5.8084358e-03, -2.6821357e-03, -5.3060763e-03,  3.9062789e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.get_input_vector(ind=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd9030-310c-414d-8c91-6178159c00e6",
   "metadata": {},
   "source": [
    "model[model.words[1]] と model.get_input_vector(ind=1) は等価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0f5e42fb-7fb1-4449-9d16-c1a21d87aff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.64855465e-05,  1.37111065e-05,  1.41594879e-04,  3.69198642e-05,\n",
       "        9.37314871e-06,  9.83630889e-05, -4.32917550e-05, -5.60286717e-05,\n",
       "       -1.21071007e-05,  3.47241585e-05, -1.29177488e-05,  5.48821408e-05,\n",
       "       -7.11681787e-05,  1.35873206e-05, -6.51547089e-05,  1.05369854e-05,\n",
       "        2.46712134e-05, -2.98814448e-05, -6.97223822e-06,  5.47772688e-05,\n",
       "       -4.34648828e-05, -6.77032876e-05,  3.82750259e-05,  4.62639291e-05,\n",
       "        3.87809414e-05, -5.79457264e-05, -3.11739132e-05, -3.45420995e-05,\n",
       "        2.56179737e-05,  1.88591548e-05, -1.06936168e-04, -3.09621441e-06,\n",
       "       -3.30380026e-05, -2.44859002e-05,  2.54371498e-05,  2.28005192e-05,\n",
       "       -1.14125714e-05, -7.71405212e-06, -2.62292688e-05,  4.95023669e-05,\n",
       "        6.83483158e-05,  7.41472240e-06, -7.45871466e-06, -1.99570986e-05,\n",
       "       -8.77055936e-06,  6.14155870e-05, -3.37384336e-05, -7.03690312e-05,\n",
       "       -6.21120780e-05, -3.50524570e-05, -2.38443281e-05,  3.41939740e-05,\n",
       "       -5.05409917e-05, -3.19997957e-06, -3.45971457e-05,  2.91866854e-05,\n",
       "        8.44113019e-05,  3.85636376e-05, -3.52261850e-05, -7.60995536e-05,\n",
       "        4.26866463e-05,  6.05096320e-05], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[test_str]\n",
    "\n",
    "# model[model.words[1]] と model.get_input_vector(ind=1) は等価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f6836443-36c4-4f2e-aa7e-c911fd9b31ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22636686,  0.0358811 ,  0.3706047 ,  0.09663288,  0.02452924,\n",
       "        0.2574478 , -0.11331306, -0.1466456 , -0.03169499,  0.0908782 ,\n",
       "       -0.03380894,  0.14364257, -0.18627687,  0.03555746, -0.17052874,\n",
       "        0.0275799 ,  0.06457247, -0.07821366, -0.01824913,  0.14337559,\n",
       "       -0.11376097, -0.1772068 ,  0.10017442,  0.12109151,  0.10149854,\n",
       "       -0.15165876, -0.08159366, -0.09040555,  0.0670519 ,  0.04935378,\n",
       "       -0.27988228, -0.00810147, -0.08646543, -0.06408333,  0.06658382,\n",
       "        0.05967693, -0.02987295, -0.02018429, -0.06864916,  0.12956837,\n",
       "        0.17888325,  0.01940197, -0.0195243 , -0.05223562, -0.02295211,\n",
       "        0.16074347, -0.08830138, -0.18417585, -0.16256206, -0.09174566,\n",
       "       -0.06240372,  0.0894906 , -0.1322762 , -0.00837872, -0.09055168,\n",
       "        0.076395  ,  0.22093119,  0.10093257, -0.09220136, -0.19917955,\n",
       "        0.11172937,  0.15837023], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文字列のベクトル表現\n",
    "model.get_sentence_vector(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84bd217d-81fc-4dd4-8c84-983f25649a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01349934,  0.01271002, -0.01006453, ...,  0.00531607,\n",
       "        -0.0106207 ,  0.00814016],\n",
       "       [ 0.01048684,  0.00816879, -0.00584027, ...,  0.01594336,\n",
       "         0.00641512,  0.01121091],\n",
       "       [-0.01389093, -0.00994238, -0.01586624, ...,  0.00450218,\n",
       "         0.00770794,  0.00581788],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# これまで入力した行列を返す関数\n",
    "model.get_input_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3a74eb78-be1b-4437-9dd3-0848392ff303",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = model.get_word_vector('サトノダイヤモンド')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1542697-b382-473e-9290-de1f9f1982fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "S2 = model.get_word_vector('ディープインパクト')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c05b6629-3c9c-42a3-82b9-06bf42417ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(97,122)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d49ced-60d6-4abd-85f8-160b5d6d5895",
   "metadata": {},
   "source": [
    "# ランダム文字列でテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5da0cf7-dbb0-4d7f-8637-14a273583b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for i in range(62):\n",
    "    rand_name = ''\n",
    "    for j in range(4):\n",
    "        rand_name += chr(random.randint(97,122))\n",
    "    word_list.append(rand_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac8bc506-a0e6-4bbb-a32a-6903b97093ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = \",\".join(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0a26e83e-1f72-44e6-884b-05d3b9a0254b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ポイントフラッグ', 0.951915442943573),\n",
       " ('カレイメモワール', 0.8899344801902771),\n",
       " ('リヤンドファミユ', 0.8506640791893005),\n",
       " ('パストラリズム', 0.8343662619590759),\n",
       " ('コスモスカイライン', 0.8293111324310303),\n",
       " ('ドリームジャーニー', 0.828325092792511),\n",
       " ('ハッシュバンバン', 0.8259212374687195),\n",
       " ('ナカヤマフェスタ', 0.8249091506004333),\n",
       " ('タイセイレジェンド', 0.8150109648704529),\n",
       " ('オーシャンブルー', 0.8144512176513672)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim \n",
    "gen_model = gensim.models.KeyedVectors.load_word2vec_format('fastText/ketto_model.vec', binary=False)\n",
    "\n",
    "# most_similarメソッドを使って演算\n",
    "# positiveに足し合わせるデータをリストで渡し、negativeに差し引くデータをリストで渡す。\n",
    "\n",
    "gen_model.most_similar(\n",
    "    positive=[ \"ゴールドシップ\"],\n",
    "#     negative=[\"ディープインパクト\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ca4955e3-7b1f-4955-9066-9b7a2232f7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ウインドインハーヘア', 0.8664582371711731),\n",
       " ('ローリエ', 0.7226738333702087),\n",
       " ('オンヴェラ', 0.7160682082176208),\n",
       " ('アイスドール', 0.7097043395042419),\n",
       " ('アローム', 0.7028155326843262),\n",
       " ('サトノアラジン', 0.7014816403388977),\n",
       " ('クロノロジスト', 0.6986632943153381),\n",
       " ('ピンクアリエス', 0.6985989212989807),\n",
       " ('ナイトマジック', 0.6953324675559998),\n",
       " ('ヘヴンリークルーズ', 0.6944254636764526)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.most_similar(\n",
    "    positive=[ \"ディープインパクト\"],\n",
    "#     negative=[\"ディープインパクト\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85747d8f-c452-4eaf-ab8a-1d964ca42805",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_txt = ft.train_unsupervised('fastText/text.txt',minn=2,maxn=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6752119-bd97-4367-8094-9bd13cd0d3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9368"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_txt.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7cb7c503-6504-4e5a-a4cb-ef33b90ea30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50ed1c05-6afa-45e7-b6f5-b089279995a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors  = model_txt['キズナ'].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e80ec-9450-43b0-8e0d-f170f67086c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "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"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85f41fe-1013-4eaf-9776-07d8819750b1",
   "metadata": {},
   "source": [
    "# 今後の方針\n",
    "1. とりあえず, Peds class で, 馬名 -> 馬名正規化\n",
    "2. 仕様は決めていないが, 学習ずみ, fasttext モデルで血統をベクトル化\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed0b75c-8969-4b49-b522-1c0df7bbb166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
