{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9bc3441",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa116d3b-51ac-42de-bf7a-fb55eb148689",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import time\n",
    "from graphviz import *\n",
    "import lightgbm as lgb\n",
    "from hyperopt import hp, tpe, Trials, fmin,STATUS_OK\n",
    "import fasttext as ft\n",
    "# import importlib\n",
    "# importlib.reload(hoge)\n",
    "from my_library.horse import *\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1782806f-f29f-40fe-9c06-7dfca7dd2339",
   "metadata": {},
   "source": [
    "# path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a4008e3-1c76-4f8e-b375-0f3533379d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ubu = '/home/hipro/デスクトップ/Horse/Data/20_21'\n",
    "path_win2 = '/Users/rince/Desktop/Horse/Data/saishin2/'\n",
    "path_win = '/Users/rince/Desktop/Horse/Data/saishin/'\n",
    "path_win = '/Users/Owner/Desktop/program/Horse/Data/saishin/'\n",
    "path_win2 = '/Users/Owner/Desktop/program/Horse/Data/saishin2/'\n",
    "path_ft = '/Users/Owner/Desktop/Horse/ft_data/peds_ft.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a920e716-5257-45d8-9831-2effe586aa2c",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cafb76f-29dc-4841-bb1b-2792c246cd20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = load_csv(path_win+'results.csv')\n",
    "horse_results = load_csv(path_win+'horse_results.csv')\n",
    "peds = load_csv(path_win+'peds.csv')\n",
    "# 何回やってもロードすると, nanが出る\n",
    "peds.fillna('nan',inplace=True)\n",
    "return_tables = load_csv(path_win+'return.csv')\n",
    "return_tables.rename(columns={'0':0,'1':1,'2':2,'3':3},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897b3ed-08f1-452f-bc5c-840f04015aed",
   "metadata": {},
   "source": [
    "# race_id 命名規則"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f840d19f-0d83-4c24-a9d6-245b20e6eac6",
   "metadata": {},
   "source": [
    "race_id 202105040802\\\n",
    "yyyy_pp_xx_xxrr\\\n",
    "y : year\\\n",
    "p : palce\\\n",
    "x : 謎\\\n",
    "r : race番号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "499fc011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<my_library.horse.HorseResults at 0x1e8159a9940>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll.hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c895357f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3652e3f3f7174c779997a1223f48a2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18673 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pe finish\n",
      "pe regularizrd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4812f997de814c01b1659906375af9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60adc2dde4a4ea88b00e149c1288ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d637cdd8b11c401c93abcc6c2bea44b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 76081\n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n"
     ]
    }
   ],
   "source": [
    "ll = LearnLGBM(peds,results,horse_results)\n",
    "ll.path_ft = '/Users/Owner/Desktop/Horse/horse/peds_ft.txt'\n",
    "ll.learn_lgb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b038db",
   "metadata": {},
   "source": [
    "# Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "40dbc718",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulater():\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.return_tables = None\n",
    "        self.pred_df = None\n",
    "        self.is_long = True\n",
    "    \n",
    "\n",
    "    #     当日のデータでシミュレートするとあかん\n",
    "    def return_table(self, race_id_list):\n",
    "        return_tables = Return.scrape(race_id_list)\n",
    "        return_tables.rename(columns={'0':0,'1':1,'2':2,'3':3},inplace=True)\n",
    "        self.return_tables = return_tables\n",
    "    \n",
    "    \n",
    "    def return_table_today(self,race_id_list):\n",
    "        return_tables = {}\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            try:\n",
    "                url = 'https://race.netkeiba.com/race/result.html?race_id='+race_id+'&amp;rf=race_submenu'\n",
    "                dfs = pd.read_html(url)\n",
    "                df = pd.concat([dfs[1], dfs[2]])\n",
    "                df.index = [race_id] * len(df)\n",
    "                return_tables[race_id] = df\n",
    "                time.sleep(0.5)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "            #pd.DataFrame型にして一つのデータにまとめる\n",
    "        return_tables_df = pd.concat([return_tables[key] for key in return_tables])\n",
    "        # return_tables_df.index = return_tables_df.index.astype(int)\n",
    "        self.return_tables = return_tables_df\n",
    "    \n",
    "    \n",
    "    def return_pred_table(self,data_c,is_long=False):\n",
    "        # is_long って何？\n",
    "        #予測\n",
    "        if not is_long:\n",
    "            scores = pd.Series(self.model.predict(data_c.drop(['date'],axis=1)),index=data_c.index)\n",
    "        else:\n",
    "            scores = pd.Series(self.model.predict(data_c.drop(['date','rank','単勝'],axis=1)),index=data_c.index)\n",
    "        pred = data_c[['馬番']].copy()\n",
    "        pred['scores'] = scores\n",
    "        pred = pred.sort_values('scores',ascending=False)\n",
    "        return pred\n",
    "\n",
    "#     odds以上の馬券しか買わない\n",
    "    def get_result_df(self, data_c, return_tables, is_long=True, odds=2.0, bet = 100):\n",
    "        race_id_list = list(set(data_c.index))\n",
    "        race_dict = {}\n",
    "\n",
    "        for race_id in race_id_list:\n",
    "            pred_list,actual_rank_list,tansho_odds,fukusho_odds,umaren_odds,wide_odds,umatan_odds,sanrenpuku_odds,sanrentan_odds,wide_comb,odds_list = self.return_race_result(data_c,race_id,return_tables)\n",
    "            row_list = [pred_list,actual_rank_list,tansho_odds,fukusho_odds,umaren_odds,wide_odds,umatan_odds,sanrenpuku_odds,sanrentan_odds,wide_comb,odds_list]\n",
    "            race_dict[int(race_id)] = row_list\n",
    "        all_result = pd.DataFrame(race_dict).T\n",
    "        all_result.rename(columns={\n",
    "            0:'pred_list',\n",
    "            1:'actual_rank_list',\n",
    "            2:'tansho_odds',\n",
    "            3:'fukusho_odds',\n",
    "            4:'umaren_odds',\n",
    "            5:'wide_odds',\n",
    "            6:'umatan_odds',\n",
    "            7:'sanrenpuku_odds',\n",
    "            8:'sanrentan_odds',\n",
    "            9:'wide_comb',\n",
    "            10:'odds_list'\n",
    "            },inplace=True)\n",
    "        return all_result\n",
    "        \n",
    "\n",
    "    def return_race_result(self, data_c ,race_id, return_tables):\n",
    "        race_id = int(race_id)\n",
    "        pred_df = self.return_pred_table(data_c.loc[race_id],is_long=self.is_long)\n",
    "        pred_df = pred_df.loc[race_id]\n",
    "        pred_df = pred_df.sort_values('scores',ascending=False)\n",
    "        dc = data_c.loc[race_id]\n",
    "        return_table  = return_tables.loc[race_id]\n",
    "        \n",
    "        \n",
    "        pred_list = [int(pred_df['馬番'].iloc[i]) for i in range(len(pred_df))]\n",
    "\n",
    "        score_1 = pred_df['scores'].iloc[0]\n",
    "        score_2 = pred_df['scores'].iloc[1]\n",
    "        is_same_score = False\n",
    "\n",
    "        try:\n",
    "        \n",
    "            tansho_row = return_table[return_table[0]=='単勝']\n",
    "            fukusho_row = return_table[return_table[0]=='複勝']\n",
    "            umaren_row =  return_table[return_table[0]=='馬連']\n",
    "            umatan_row =  return_table[return_table[0]=='馬単']\n",
    "            wide_row =  return_table[return_table[0]=='ワイド']\n",
    "            sanrentan_row =  return_table[return_table[0]=='三連単']\n",
    "            sanrenpuku_row =  return_table[return_table[0]=='三連複']\n",
    "            \n",
    "            # odds 順番は予測した順\n",
    "            odds_list = []\n",
    "            for ub in pred_df['馬番'].tolist():\n",
    "                odds_list.append(dc[dc['馬番']==ub]['単勝'].values[0])\n",
    "        \n",
    "            if score_1 == score_2:\n",
    "                is_same_score =True\n",
    "                \n",
    "            # １着が同着    \n",
    "            if int(tansho_row[1].str.count('br'))==1:\n",
    "                actual_tmp0 = sanrentan_row[1].str.split('br').values[0][0]\n",
    "                actual_tmp1 = sanrentan_row[1].str.split('br').values[0][1]\n",
    "                actual_rank_list0 = list(map(int,actual_tmp0.split('→')))\n",
    "                actual_rank_list1 = list(map(int,actual_tmp1.split('→')))\n",
    "                actual_rank_list = [actual_rank_list0,actual_rank_list1]\n",
    "                \n",
    "                tansho_odds_list = tansho_row[2].str.split('br').values[0][0:3]\n",
    "                tansho_odds_list = [i for i in tansho_odds_list if i!='']\n",
    "                tansho_odds = list(map(lambda x: int(x.replace(',',''))/100 ,tansho_odds_list))\n",
    "                \n",
    "                umatan_odds_list = umatan_row[2].str.split('br').values[0][0:3]\n",
    "                umatan_odds_list = [i for i in umatan_odds_list if i!='']\n",
    "                umatan_odds = list(map(lambda x: int(x.replace(',',''))/100 ,umatan_odds_list))\n",
    "                \n",
    "                sanrentan_odds_list = sanrentan_row[2].str.split('br').values[0][0:3]\n",
    "                sanrentan_odds_list = [i for i in sanrentan_odds_list if i!='']\n",
    "                sanrentan_odds = list(map(lambda x: int(x.replace(',',''))/100 ,sanrentan_odds_list))\n",
    "        \n",
    "                umaren_odds = int(umaren_row[2])/100\n",
    "                sanrenpuku_odds = int(sanrenpuku_row[2])/100\n",
    "                fukusho_odds_list = fukusho_row[2].str.split('br').values[0][0:3]\n",
    "                fukusho_odds_list = [i for i in fukusho_odds_list if i!='']\n",
    "                fukusho_odds = list(map(lambda x: int(x.replace(',',''))/100 , fukusho_odds_list))\n",
    "                \n",
    "                wide_odds = list(map(lambda x: int(x.replace(',',''))/100 , wide_row[2].str.split('br').values[0][0:3]))\n",
    "                \n",
    "                tmp_list = list(map(lambda x:x.replace(' - ',' '),wide_row[1].str.split('br').values[0][0:3]))\n",
    "                wide_comb = []\n",
    "                for tl in tmp_list:\n",
    "                    pair_list = list(map(lambda x: int(x),tl.split(' ')))\n",
    "                    wide_comb.append(pair_list)\n",
    "                    \n",
    "            # S2\n",
    "            elif int(umaren_row[1].str.count('br'))==1:\n",
    "                actual_tmp0 = sanrentan_row[1].str.split('br').values[0][0]\n",
    "                actual_tmp1 = sanrentan_row[1].str.split('br').values[0][1]\n",
    "                actual_rank_list0 = list(map(int,actual_tmp0.split('→')))\n",
    "                actual_rank_list1 = list(map(int,actual_tmp1.split('→')))\n",
    "                actual_rank_list = [actual_rank_list0,actual_rank_list1]\n",
    "                \n",
    "                tansho_odds = int(tansho_row[2])/100\n",
    "                fukusho_odds_list = fukusho_row[2].str.split('br').values[0][0:3]\n",
    "                fukusho_odds_list = [i for i in fukusho_odds_list if i!='']\n",
    "                fukusho_odds = list(map(lambda x: int(x.replace(',',''))/100 , fukusho_odds_list))\n",
    "                \n",
    "                umaren_odds_list = umaren_row[2].str.split('br').values[0][0:3]\n",
    "                umaren_odds_list = [i for i in umaren_odds_list if i!='']\n",
    "                umaren_odds = list(map(lambda x: int(x.replace(',',''))/100 ,umaren_odds_list))\n",
    "                \n",
    "                umatan_odds_list = umatan_row[2].str.split('br').values[0][0:3]\n",
    "                umatan_odds_list = [i for i in umatan_odds_list if i!='']\n",
    "                umatan_odds = list(map(lambda x: int(x.replace(',',''))/100 ,umatan_odds_list))\n",
    "                \n",
    "                wide_odds = list(map(lambda x: int(x.replace(',',''))/100 , wide_row[2].str.split('br').values[0][0:3]))\n",
    "                \n",
    "                tmp_list = list(map(lambda x:x.replace(' - ',' '),wide_row[1].str.split('br').values[0][0:3]))\n",
    "                wide_comb = []\n",
    "                for tl in tmp_list:\n",
    "                    pair_list = list(map(lambda x: int(x),tl.split(' ')))\n",
    "                    wide_comb.append(pair_list)\n",
    "                    \n",
    "                sanrenpuku_odds = int(sanrenpuku_row[2])/100\n",
    "                sanrentan_odds_list = sanrentan_row[2].str.split('br').values[0][0:3]\n",
    "                sanrentan_odds_list = [i for i in sanrentan_odds_list if i!='']\n",
    "                sanrentan_odds = list(map(lambda x: int(x.replace(',',''))/100 ,sanrentan_odds_list))\n",
    "            \n",
    "            # S3\n",
    "            elif int(sanrenpuku_row[1].str.count('br'))==1:\n",
    "                actual_tmp0 = sanrentan_row[1].str.split('br').values[0][0]\n",
    "                actual_tmp1 = sanrentan_row[1].str.split('br').values[0][1]\n",
    "                actual_rank_list0 = list(map(int,actual_tmp0.split('→')))\n",
    "                actual_rank_list1 = list(map(int,actual_tmp1.split('→')))\n",
    "                actual_rank_list = [actual_rank_list0,actual_rank_list1]\n",
    "                \n",
    "                tansho_odds = int(tansho_row[2])/100\n",
    "                fukusho_odds_list = fukusho_row[2].str.split('br').values[0][0:4]\n",
    "                fukusho_odds_list = [i for i in fukusho_odds_list if i!='']\n",
    "                fukusho_odds = list(map(lambda x: int(x.replace(',',''))/100 , fukusho_odds_list))\n",
    "                umaren_odds = int(umaren_row[2])/100\n",
    "                umatan_odds = int(umatan_row[2])/100\n",
    "                \n",
    "                wide_odds = list(map(lambda x: int(x.replace(',',''))/100 , wide_row[2].str.split('br').values[0][0:5]))\n",
    "                tmp_list = list(map(lambda x:x.replace(' - ',' '),wide_row[1].str.split('br').values[0][0:5]))\n",
    "                wide_comb = []\n",
    "                for tl in tmp_list:\n",
    "                    pair_list = list(map(lambda x: int(x),tl.split(' ')))\n",
    "                    wide_comb.append(pair_list)\n",
    "                \n",
    "                sanrenpuku_odds_list = sanrenpuku_row[2].str.split('br').values[0][0:3]\n",
    "                sanrenpuku_odds_list = [i for i in sanrenpuku_odds_list if i!='']\n",
    "                sanrenpuku_odds = list(map(lambda x: int(x.replace(',',''))/100 ,sanrenpuku_odds_list))\n",
    "                \n",
    "                sanrentan_odds_list = sanrentan_row[2].str.split('br').values[0][0:3]\n",
    "                sanrentan_odds_list = [i for i in sanrentan_odds_list if i!='']\n",
    "                sanrentan_odds = list(map(lambda x: int(x.replace(',',''))/100 ,sanrentan_odds_list))\n",
    "            else:\n",
    "                actual_rank_list = list(map(int,sanrentan_row[1].str.split('→').values[0]))\n",
    "                \n",
    "                tansho_odds = int(tansho_row[2])/100\n",
    "                umaren_odds = int(umaren_row[2])/100\n",
    "                sanrenpuku_odds = int(sanrenpuku_row[2])/100\n",
    "                fukusho_odds_list = fukusho_row[2].str.split('br').values[0][0:3]\n",
    "                fukusho_odds_list = [i for i in fukusho_odds_list if i!='']\n",
    "                fukusho_odds = list(map(lambda x: int(x.replace(',',''))/100 , fukusho_odds_list))\n",
    "                \n",
    "                wide_odds = list(map(lambda x: int(x.replace(',',''))/100 , wide_row[2].str.split('br').values[0][0:3]))\n",
    "                \n",
    "                tmp_list = list(map(lambda x:x.replace(' - ',' '),wide_row[1].str.split('br').values[0][0:3]))\n",
    "                wide_comb = []\n",
    "                for tl in tmp_list:\n",
    "                    pair_list = list(map(lambda x: int(x),tl.split(' ')))\n",
    "                    wide_comb.append(pair_list)\n",
    "                \n",
    "                umatan_odds = int(umatan_row[2])/100\n",
    "                \n",
    "                sanrentan_odds = int(sanrentan_row[2])/100\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(race_id)\n",
    "            return\n",
    "        \n",
    "        \n",
    "        return  pred_list,actual_rank_list,tansho_odds,fukusho_odds,umaren_odds,wide_odds,umatan_odds,sanrenpuku_odds,sanrentan_odds,wide_comb,odds_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "aac676b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = Simulater(ll.model)\n",
    "\n",
    "race_id_list = list(set(ll.x_test.index))\n",
    "data_c = ll.r.data_c.loc[ll.x_test.index[0]:]\n",
    "\n",
    "all_results = sl.get_result_df(data_c, return_tables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "44084cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "的中率 0.22687224669603523\n",
      "収益   102230.0 円\n"
     ]
    }
   ],
   "source": [
    "length = len(all_results)\n",
    "tekichu = 0\n",
    "profit = 0\n",
    "bet = 100\n",
    "odds_alpha = 6\n",
    "race_hit_dist = {'{}'.format(str(i).zfill(2)):0 for i in range(1,13)}\n",
    "\n",
    "\n",
    "for race_id in all_results.index:\n",
    "    ar = all_results.loc[race_id]\n",
    "    pred_list = ar['pred_list']\n",
    "    actual_list = ar['actual_rank_list']\n",
    "    tansho_odds = ar['tansho_odds']\n",
    "    pred_odds = ar['odds_list'][0]\n",
    "    \n",
    "    if pred_odds>=odds_alpha:\n",
    "        profit -= bet\n",
    "        \n",
    "    if pred_list[0]==actual_list[0]:\n",
    "        tekichu+=1\n",
    "        profit += bet*tansho_odds\n",
    "\n",
    "print('的中率 {0}'.format(tekichu/length))\n",
    "print(\"収益   {0} 円\".format(profit))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a38a8fc",
   "metadata": {},
   "source": [
    "# LearnXGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "34cd896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnLGBM():\n",
    "    \n",
    "    \n",
    "    def __init__(self,peds,results,horse_results):\n",
    "        self.model = None\n",
    "        self.model_ft = None\n",
    "        self.date = '2022/12/31'\n",
    "        self.pe = None\n",
    "        self.r = None\n",
    "        self.horse_results = None\n",
    "        self.peds = peds\n",
    "        self.results = results\n",
    "        self.horse_results = horse_results\n",
    "        self.x_train = None\n",
    "        self.x_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.path_ft = '/Users/Owner/Desktop/Horse/horse/peds_ft.txt'\n",
    "\n",
    "        self.lgbm_params = {\n",
    "                'metric': 'ndcg',\n",
    "                'objective': 'lambdarank',\n",
    "                'ndcg_eval_at': [1,2,3],\n",
    "                'boosting_type': 'gbdt',\n",
    "                'random_state': 777,\n",
    "                'lambdarank_truncation_level': 10,\n",
    "                'learning_rate': 0.02273417953255777,\n",
    "                'n_estimators': 97,\n",
    "                'num_leaves': 42,\n",
    "                'force_col_wise':True\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "    def learn_model_ft(self,minn=2,maxn=14):\n",
    "        path_ft = self.path_ft\n",
    "        model_ft = ft.train_unsupervised(path_ft,dim=62,minn=minn,maxn=maxn)\n",
    "        self.model_ft = model_ft\n",
    "\n",
    "\n",
    "    def get_model_ft(self):\n",
    "        return self.model_ft\n",
    "    \n",
    "\n",
    "    def process_pe(self,peds):\n",
    "        pe = Peds(peds)\n",
    "        pe.regularize_peds()\n",
    "        # 血統データ　カテゴリ変数処理\n",
    "        pe.categorize()\n",
    "        # pe.vectorize(pe.peds_re,self.model_ft)\n",
    "        self.pe = pe\n",
    "        print(\"pe finish\")\n",
    "        print(\"pe regularizrd\")\n",
    "\n",
    "\n",
    "    def process_hr(self,results,horse_results):\n",
    "        r = Results(results)\n",
    "        r.preprocessing()\n",
    "        #馬の過去成績データ追加\n",
    "        hr = HorseResults(horse_results)\n",
    "        self.hr = hr\n",
    "        r.merge_horse_results(hr)\n",
    "        r.merge_peds(self.pe.peds_cat)\n",
    "        # r.merge_peds(pe.peds_cat)\n",
    "        #カテゴリ変数の処理\n",
    "        # pedsは既にカテゴリ化したdataをconcatしているので, ここでカテゴリ化せずとも良い\n",
    "        r.process_categorical()\n",
    "        self.r = r\n",
    "\n",
    "\n",
    "    def process_data(self):\n",
    "        peds = self.peds.copy()\n",
    "        results = self.results.copy()\n",
    "        horse_results = self.horse_results.copy()\n",
    "        # self.learn_model_ft()\n",
    "        self.process_pe(peds)\n",
    "        self.process_hr(results,horse_results)\n",
    "        \n",
    "        \n",
    "    def get_train_data(self,test_size=0.2):\n",
    "        self.process_data()\n",
    "        train, test = split_data(self.r.data_c.fillna(0),test_size=test_size,rank_learning=False)\n",
    "        x_train = train.drop(['rank', 'date','単勝'], axis=1)\n",
    "        y_train = train['rank']\n",
    "        x_test = test.drop(['rank', 'date','単勝'], axis=1)\n",
    "        y_test = test['rank']\n",
    "        train_query = x_train.groupby(x_train.index).size()\n",
    "        test_query = x_test.groupby(x_test.index).size()\n",
    "        train = lgb.Dataset(x_train, y_train, group=train_query)\n",
    "        test = lgb.Dataset(x_test, y_test, reference=train, group=test_query)\n",
    "        self.x_train = x_train\n",
    "        self.x_test = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        return train, test\n",
    "\n",
    "    \n",
    "    def get_train_data2(self):\n",
    "        x_train = self.x_train\n",
    "        x_test = self.x_test\n",
    "        y_train = self.y_train\n",
    "        y_test = self.y_test\n",
    "        train_query = x_train.groupby(x_train.index).size()\n",
    "        test_query = x_test.groupby(x_test.index).size()\n",
    "        train = lgb.Dataset(x_train, y_train, group=train_query)\n",
    "        test = lgb.Dataset(x_test, y_test, reference=train, group=test_query)\n",
    "        return train, test\n",
    "\n",
    "\n",
    "    def learn_lgb(self,lgbm_params=None,test_size=0.2):\n",
    "        if lgbm_params==None:\n",
    "            lgbm_params = self.lgbm_params\n",
    "        \n",
    "        train, test = self.get_train_data(test_size=test_size)\n",
    "        lgb_rank = lgb.train(\n",
    "                lgbm_params,\n",
    "                train,\n",
    "                # valid_sets=test,\n",
    "                num_boost_round=100,\n",
    "                valid_names=['train'],\n",
    "                # early_stopping_rounds=20,\n",
    "            )\n",
    "\n",
    "        self.model = lgb_rank\n",
    "\n",
    "# train data を与えて学習させるのが learn_lgb2\n",
    "    def learn_lgb2(self,train,lgbm_params=None):\n",
    "        if lgbm_params==None:\n",
    "            lgbm_params = self.lgbm_params\n",
    "        \n",
    "        lgb_rank = lgb.train(\n",
    "                lgbm_params,\n",
    "                train,\n",
    "                # valid_sets=test,\n",
    "                num_boost_round=100,\n",
    "                valid_names=['train'],\n",
    "                # early_stopping_rounds=20,\n",
    "            )\n",
    "\n",
    "        self.model = lgb_rank\n",
    "    \n",
    "\n",
    "class Predictor(LearnLGBM):\n",
    "\n",
    "\n",
    "    def __init__(self,peds,results,horse_results,race_id_list):\n",
    "        super(Predictor, self).__init__(peds,results,horse_results)\n",
    "        self.race_id_list = race_id_list\n",
    "        self.nopeds_id_list = []\n",
    "        \n",
    "\n",
    "    def process_hr(self,results,horse_results):\n",
    "        r = Results(results)\n",
    "        r.preprocessing()\n",
    "        horse_id_list = self.data['horse_id'].astype(str).unique()\n",
    "        horse_results_tmp = HorseResults.scrape(horse_id_list)\n",
    "        new_horse_results = update_data(horse_results,horse_results_tmp)\n",
    "        self.hores_results = new_horse_results.copy()\n",
    "        hr = HorseResults(new_horse_results)\n",
    "        self.hr = hr\n",
    "        print(\"hr finish\")\n",
    "        r.merge_horse_results(hr)\n",
    "        r.merge_peds(self.pe.peds_cat)\n",
    "        r.process_categorical()  \n",
    "        self.r = r\n",
    "        \n",
    "\n",
    "    def process_data(self):\n",
    "        race_id_list = self.race_id_list.copy()\n",
    "        data =  ShutubaTable.scrape(race_id_list, self.date)\n",
    "        self.data = data\n",
    "        peds = self.peds.copy()\n",
    "        results = self.results.copy()\n",
    "        horse_results = self.horse_results.copy()\n",
    "        nopeds_id_list = []\n",
    "\n",
    "\n",
    "        for ind in data['horse_id'].astype(int).unique():\n",
    "            if ind not in peds.index:\n",
    "                nopeds_id_list.append(str(ind))\n",
    "\n",
    "        if len(nopeds_id_list)!=0:\n",
    "            peds_tmp = Peds.scrape(nopeds_id_list)\n",
    "            pe_tmp = Peds(peds_tmp)\n",
    "            pe_tmp.regularize_peds() \n",
    "            new_peds = update_data(peds, pe_tmp.peds_re)\n",
    "        else:\n",
    "            new_peds = peds.copy()\n",
    "        \n",
    "        self.nopeds_id_list = nopeds_id_list\n",
    "        self.peds = new_peds.copy()\n",
    "        path_ft =  self.path_ft \n",
    "        \n",
    "        new_peds.to_csv(path_ft,header=False,index=False,sep=',')\n",
    "        self.learn_model_ft()\n",
    "        self.process_pe(new_peds)\n",
    "        self.process_hr(results,horse_results)\n",
    "\n",
    "    \n",
    "    def predict(self, race_id):\n",
    "        data =  ShutubaTable.scrape([str(race_id)], self.date)\n",
    "        st = ShutubaTable(data)\n",
    "        st.preprocessing()\n",
    "        st.merge_horse_results(self.hr)\n",
    "        st.merge_peds(self.pe.peds_cat)\n",
    "        st.process_categorical(self.r.le_horse, self.r.le_jockey, self.r.data_pe)\n",
    "        self.st = st\n",
    "        sl = Simulater(self.model)\n",
    "        pred_table = sl.return_pred_table(st.data_c)\n",
    "        self.sl = sl\n",
    "        print(pred_table)\n",
    "            \n",
    "\n",
    "    def show_results_today(self):\n",
    "        data =  ShutubaTable.scrape(self.race_id_list, self.date)\n",
    "        self.data = data.copy()\n",
    "        st = ShutubaTable(self.data)\n",
    "        st.preprocessing()\n",
    "        st.merge_horse_results(self.hr)\n",
    "        st.merge_peds(self.pe.peds_cat)\n",
    "        st.process_categorical(self.r.le_horse, self.r.le_jockey, self.r.data_pe)\n",
    "        sl = RankSimulater(self.model)\n",
    "        sl.return_table_today(self.race_id_list)\n",
    "        sl.show_results_today(st ,self.race_id_list)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27efe69c",
   "metadata": {},
   "source": [
    "# grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "32108465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start:                                       \n",
      "  0%|          | 0/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "\n",
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "  0%|          | 0/25 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "\n",
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalid's ndcg@1: 0.527604\tvalid's ndcg@2: 0.509235\tvalid's ndcg@3: 0.503558\n",
      "[10]\tvalid's ndcg@1: 0.517359\tvalid's ndcg@2: 0.502096\tvalid's ndcg@3: 0.497436\n",
      "[15]\tvalid's ndcg@1: 0.512237\tvalid's ndcg@2: 0.501435\tvalid's ndcg@3: 0.497283\n",
      "[20]\tvalid's ndcg@1: 0.507684\tvalid's ndcg@2: 0.504808\tvalid's ndcg@3: 0.500056\n",
      "Early stopping, best iteration is:                    \n",
      "[4]\tvalid's ndcg@1: 0.525896\tvalid's ndcg@2: 0.509207\tvalid's ndcg@3: 0.508317\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.479226\tvalid's ndcg@2: 0.483152\tvalid's ndcg@3: 0.479322   \n",
      "[10]\tvalid's ndcg@1: 0.478088\tvalid's ndcg@2: 0.487993\tvalid's ndcg@3: 0.477381  \n",
      "[15]\tvalid's ndcg@1: 0.494024\tvalid's ndcg@2: 0.488622\tvalid's ndcg@3: 0.482766  \n",
      "[20]\tvalid's ndcg@1: 0.49687\tvalid's ndcg@2: 0.492545\tvalid's ndcg@3: 0.485668   \n",
      "[25]\tvalid's ndcg@1: 0.491747\tvalid's ndcg@2: 0.49105\tvalid's ndcg@3: 0.486492   \n",
      "[30]\tvalid's ndcg@1: 0.493455\tvalid's ndcg@2: 0.492073\tvalid's ndcg@3: 0.484365  \n",
      "[35]\tvalid's ndcg@1: 0.499146\tvalid's ndcg@2: 0.492064\tvalid's ndcg@3: 0.48516   \n",
      "Early stopping, best iteration is:                                               \n",
      "[16]\tvalid's ndcg@1: 0.500285\tvalid's ndcg@2: 0.491915\tvalid's ndcg@3: 0.483651\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.515652\tvalid's ndcg@2: 0.506994\tvalid's ndcg@3: 0.49925    \n",
      "[10]\tvalid's ndcg@1: 0.507114\tvalid's ndcg@2: 0.505259\tvalid's ndcg@3: 0.498582  \n",
      "[15]\tvalid's ndcg@1: 0.517359\tvalid's ndcg@2: 0.508319\tvalid's ndcg@3: 0.501857  \n",
      "[20]\tvalid's ndcg@1: 0.511098\tvalid's ndcg@2: 0.508663\tvalid's ndcg@3: 0.502203  \n",
      "Early stopping, best iteration is:                                               \n",
      "[2]\tvalid's ndcg@1: 0.524758\tvalid's ndcg@2: 0.508648\tvalid's ndcg@3: 0.494481\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.517928\tvalid's ndcg@2: 0.511066\tvalid's ndcg@3: 0.499671   \n",
      "[10]\tvalid's ndcg@1: 0.520205\tvalid's ndcg@2: 0.50858\tvalid's ndcg@3: 0.498989   \n",
      "[15]\tvalid's ndcg@1: 0.511098\tvalid's ndcg@2: 0.505418\tvalid's ndcg@3: 0.499446  \n",
      "[20]\tvalid's ndcg@1: 0.507684\tvalid's ndcg@2: 0.506685\tvalid's ndcg@3: 0.499474  \n",
      "Early stopping, best iteration is:                                               \n",
      "[1]\tvalid's ndcg@1: 0.524189\tvalid's ndcg@2: 0.505078\tvalid's ndcg@3: 0.49348\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.512806\tvalid's ndcg@2: 0.501703\tvalid's ndcg@3: 0.497261   \n",
      "[10]\tvalid's ndcg@1: 0.50313\tvalid's ndcg@2: 0.498771\tvalid's ndcg@3: 0.495968   \n",
      "[15]\tvalid's ndcg@1: 0.508822\tvalid's ndcg@2: 0.503721\tvalid's ndcg@3: 0.497795  \n",
      "[20]\tvalid's ndcg@1: 0.512806\tvalid's ndcg@2: 0.507265\tvalid's ndcg@3: 0.501095  \n",
      "Early stopping, best iteration is:                                               \n",
      "[1]\tvalid's ndcg@1: 0.524189\tvalid's ndcg@2: 0.505078\tvalid's ndcg@3: 0.49348\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.513375\tvalid's ndcg@2: 0.507753\tvalid's ndcg@3: 0.497083   \n",
      "[10]\tvalid's ndcg@1: 0.512237\tvalid's ndcg@2: 0.504738\tvalid's ndcg@3: 0.501114  \n",
      "[15]\tvalid's ndcg@1: 0.507114\tvalid's ndcg@2: 0.506671\tvalid's ndcg@3: 0.503005  \n",
      "[20]\tvalid's ndcg@1: 0.508822\tvalid's ndcg@2: 0.507881\tvalid's ndcg@3: 0.504027  \n",
      "Early stopping, best iteration is:                                               \n",
      "[1]\tvalid's ndcg@1: 0.524189\tvalid's ndcg@2: 0.505078\tvalid's ndcg@3: 0.49348\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.517359\tvalid's ndcg@2: 0.506012\tvalid's ndcg@3: 0.502534   \n",
      "[10]\tvalid's ndcg@1: 0.511668\tvalid's ndcg@2: 0.500043\tvalid's ndcg@3: 0.498352  \n",
      "[15]\tvalid's ndcg@1: 0.512237\tvalid's ndcg@2: 0.498109\tvalid's ndcg@3: 0.499684  \n",
      "[20]\tvalid's ndcg@1: 0.510529\tvalid's ndcg@2: 0.498522\tvalid's ndcg@3: 0.495628  \n",
      "Early stopping, best iteration is:                                               \n",
      "[1]\tvalid's ndcg@1: 0.524189\tvalid's ndcg@2: 0.505078\tvalid's ndcg@3: 0.49348\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.499146\tvalid's ndcg@2: 0.488205\tvalid's ndcg@3: 0.481512   \n",
      "[10]\tvalid's ndcg@1: 0.484348\tvalid's ndcg@2: 0.489515\tvalid's ndcg@3: 0.481682  \n",
      "[15]\tvalid's ndcg@1: 0.490609\tvalid's ndcg@2: 0.493272\tvalid's ndcg@3: 0.48631   \n",
      "[20]\tvalid's ndcg@1: 0.499715\tvalid's ndcg@2: 0.496295\tvalid's ndcg@3: 0.48676   \n",
      "Early stopping, best iteration is:                                               \n",
      "[3]\tvalid's ndcg@1: 0.499715\tvalid's ndcg@2: 0.491613\tvalid's ndcg@3: 0.484611\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.519067\tvalid's ndcg@2: 0.504962\tvalid's ndcg@3: 0.500861   \n",
      "[10]\tvalid's ndcg@1: 0.518497\tvalid's ndcg@2: 0.502991\tvalid's ndcg@3: 0.499258  \n",
      "[15]\tvalid's ndcg@1: 0.508822\tvalid's ndcg@2: 0.50408\tvalid's ndcg@3: 0.498528   \n",
      "[20]\tvalid's ndcg@1: 0.517928\tvalid's ndcg@2: 0.510046\tvalid's ndcg@3: 0.505594  \n",
      "Early stopping, best iteration is:                                               \n",
      "[2]\tvalid's ndcg@1: 0.532157\tvalid's ndcg@2: 0.509906\tvalid's ndcg@3: 0.496404\n",
      "Training start:                                                                  \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "[5]\tvalid's ndcg@1: 0.519636\tvalid's ndcg@2: 0.506331\tvalid's ndcg@3: 0.501854   \n",
      "[10]\tvalid's ndcg@1: 0.519067\tvalid's ndcg@2: 0.509064\tvalid's ndcg@3: 0.502278  \n",
      "[15]\tvalid's ndcg@1: 0.519067\tvalid's ndcg@2: 0.501683\tvalid's ndcg@3: 0.502952  \n",
      "[20]\tvalid's ndcg@1: 0.512237\tvalid's ndcg@2: 0.504436\tvalid's ndcg@3: 0.501752  \n",
      "Early stopping, best iteration is:                                               \n",
      "[1]\tvalid's ndcg@1: 0.524189\tvalid's ndcg@2: 0.505078\tvalid's ndcg@3: 0.49348\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.524758\tvalid's ndcg@2: 0.506772\tvalid's ndcg@3: 0.502791    \n",
      "[10]\tvalid's ndcg@1: 0.507114\tvalid's ndcg@2: 0.502257\tvalid's ndcg@3: 0.499019   \n",
      "[15]\tvalid's ndcg@1: 0.508253\tvalid's ndcg@2: 0.505957\tvalid's ndcg@3: 0.501408   \n",
      "[20]\tvalid's ndcg@1: 0.512237\tvalid's ndcg@2: 0.503393\tvalid's ndcg@3: 0.499525   \n",
      "Early stopping, best iteration is:                                                \n",
      "[2]\tvalid's ndcg@1: 0.532157\tvalid's ndcg@2: 0.512572\tvalid's ndcg@3: 0.502476\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.515083\tvalid's ndcg@2: 0.510862\tvalid's ndcg@3: 0.502978    \n",
      "[10]\tvalid's ndcg@1: 0.511668\tvalid's ndcg@2: 0.508931\tvalid's ndcg@3: 0.501185   \n",
      "[15]\tvalid's ndcg@1: 0.513375\tvalid's ndcg@2: 0.510036\tvalid's ndcg@3: 0.503845   \n",
      "[20]\tvalid's ndcg@1: 0.513375\tvalid's ndcg@2: 0.508715\tvalid's ndcg@3: 0.506128   \n",
      "Early stopping, best iteration is:                                                \n",
      "[2]\tvalid's ndcg@1: 0.544109\tvalid's ndcg@2: 0.517397\tvalid's ndcg@3: 0.502028\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.513944\tvalid's ndcg@2: 0.498044\tvalid's ndcg@3: 0.494164    \n",
      "[10]\tvalid's ndcg@1: 0.513375\tvalid's ndcg@2: 0.502214\tvalid's ndcg@3: 0.493763   \n",
      "[15]\tvalid's ndcg@1: 0.511098\tvalid's ndcg@2: 0.498559\tvalid's ndcg@3: 0.493802   \n",
      "[20]\tvalid's ndcg@1: 0.513375\tvalid's ndcg@2: 0.503095\tvalid's ndcg@3: 0.497811   \n",
      "Early stopping, best iteration is:                                                \n",
      "[3]\tvalid's ndcg@1: 0.524189\tvalid's ndcg@2: 0.503005\tvalid's ndcg@3: 0.496862\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.507684\tvalid's ndcg@2: 0.503267\tvalid's ndcg@3: 0.497794    \n",
      "[10]\tvalid's ndcg@1: 0.508253\tvalid's ndcg@2: 0.499954\tvalid's ndcg@3: 0.498784   \n",
      "[15]\tvalid's ndcg@1: 0.504838\tvalid's ndcg@2: 0.502901\tvalid's ndcg@3: 0.50124    \n",
      "[20]\tvalid's ndcg@1: 0.50996\tvalid's ndcg@2: 0.503098\tvalid's ndcg@3: 0.500813    \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.524189\tvalid's ndcg@2: 0.505078\tvalid's ndcg@3: 0.49348\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.515083\tvalid's ndcg@2: 0.501256\tvalid's ndcg@3: 0.496331    \n",
      "[10]\tvalid's ndcg@1: 0.508822\tvalid's ndcg@2: 0.508785\tvalid's ndcg@3: 0.500064   \n",
      "[15]\tvalid's ndcg@1: 0.507114\tvalid's ndcg@2: 0.510055\tvalid's ndcg@3: 0.502245   \n",
      "[20]\tvalid's ndcg@1: 0.510529\tvalid's ndcg@2: 0.510631\tvalid's ndcg@3: 0.504984   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.524189\tvalid's ndcg@2: 0.505078\tvalid's ndcg@3: 0.49348\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.521912\tvalid's ndcg@2: 0.507727\tvalid's ndcg@3: 0.501405    \n",
      "[10]\tvalid's ndcg@1: 0.51679\tvalid's ndcg@2: 0.510622\tvalid's ndcg@3: 0.504946    \n",
      "[15]\tvalid's ndcg@1: 0.513944\tvalid's ndcg@2: 0.509968\tvalid's ndcg@3: 0.505374   \n",
      "[20]\tvalid's ndcg@1: 0.521912\tvalid's ndcg@2: 0.51629\tvalid's ndcg@3: 0.507308    \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.524189\tvalid's ndcg@2: 0.505078\tvalid's ndcg@3: 0.49348\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.50996\tvalid's ndcg@2: 0.499958\tvalid's ndcg@3: 0.497196     \n",
      "[10]\tvalid's ndcg@1: 0.507114\tvalid's ndcg@2: 0.499429\tvalid's ndcg@3: 0.500329   \n",
      "[15]\tvalid's ndcg@1: 0.515652\tvalid's ndcg@2: 0.510215\tvalid's ndcg@3: 0.503724   \n",
      "[20]\tvalid's ndcg@1: 0.517359\tvalid's ndcg@2: 0.51256\tvalid's ndcg@3: 0.501622    \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.524189\tvalid's ndcg@2: 0.505078\tvalid's ndcg@3: 0.49348\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.52362\tvalid's ndcg@2: 0.513096\tvalid's ndcg@3: 0.504218     \n",
      "[10]\tvalid's ndcg@1: 0.521912\tvalid's ndcg@2: 0.508689\tvalid's ndcg@3: 0.50066    \n",
      "[15]\tvalid's ndcg@1: 0.517359\tvalid's ndcg@2: 0.504992\tvalid's ndcg@3: 0.501717   \n",
      "[20]\tvalid's ndcg@1: 0.515652\tvalid's ndcg@2: 0.505453\tvalid's ndcg@3: 0.503932   \n",
      "Early stopping, best iteration is:                                                \n",
      "[4]\tvalid's ndcg@1: 0.528173\tvalid's ndcg@2: 0.515471\tvalid's ndcg@3: 0.503056\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.519067\tvalid's ndcg@2: 0.508624\tvalid's ndcg@3: 0.502799    \n",
      "[10]\tvalid's ndcg@1: 0.510529\tvalid's ndcg@2: 0.497908\tvalid's ndcg@3: 0.499948   \n",
      "[15]\tvalid's ndcg@1: 0.507684\tvalid's ndcg@2: 0.49906\tvalid's ndcg@3: 0.496629    \n",
      "[20]\tvalid's ndcg@1: 0.505407\tvalid's ndcg@2: 0.503331\tvalid's ndcg@3: 0.49853    \n",
      "Early stopping, best iteration is:                                                \n",
      "[3]\tvalid's ndcg@1: 0.521343\tvalid's ndcg@2: 0.510518\tvalid's ndcg@3: 0.499962\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.512237\tvalid's ndcg@2: 0.505513\tvalid's ndcg@3: 0.499176    \n",
      "[10]\tvalid's ndcg@1: 0.520774\tvalid's ndcg@2: 0.506507\tvalid's ndcg@3: 0.503565   \n",
      "[15]\tvalid's ndcg@1: 0.505407\tvalid's ndcg@2: 0.503609\tvalid's ndcg@3: 0.49978    \n",
      "[20]\tvalid's ndcg@1: 0.511098\tvalid's ndcg@2: 0.505002\tvalid's ndcg@3: 0.500208   \n",
      "Early stopping, best iteration is:                                                \n",
      "[2]\tvalid's ndcg@1: 0.525327\tvalid's ndcg@2: 0.510179\tvalid's ndcg@3: 0.496875\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.513944\tvalid's ndcg@2: 0.499179\tvalid's ndcg@3: 0.499428    \n",
      "[10]\tvalid's ndcg@1: 0.511098\tvalid's ndcg@2: 0.501374\tvalid's ndcg@3: 0.497985   \n",
      "[15]\tvalid's ndcg@1: 0.514513\tvalid's ndcg@2: 0.50443\tvalid's ndcg@3: 0.499357    \n",
      "[20]\tvalid's ndcg@1: 0.512806\tvalid's ndcg@2: 0.500764\tvalid's ndcg@3: 0.499025   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.524189\tvalid's ndcg@2: 0.505078\tvalid's ndcg@3: 0.49348\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.511098\tvalid's ndcg@2: 0.505198\tvalid's ndcg@3: 0.499521    \n",
      "[10]\tvalid's ndcg@1: 0.512806\tvalid's ndcg@2: 0.503301\tvalid's ndcg@3: 0.500365   \n",
      "[15]\tvalid's ndcg@1: 0.519067\tvalid's ndcg@2: 0.509122\tvalid's ndcg@3: 0.501169   \n",
      "[20]\tvalid's ndcg@1: 0.514513\tvalid's ndcg@2: 0.508173\tvalid's ndcg@3: 0.503275   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.524189\tvalid's ndcg@2: 0.505078\tvalid's ndcg@3: 0.49348\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.520205\tvalid's ndcg@2: 0.509681\tvalid's ndcg@3: 0.50129     \n",
      "[10]\tvalid's ndcg@1: 0.514513\tvalid's ndcg@2: 0.50903\tvalid's ndcg@3: 0.500176    \n",
      "[15]\tvalid's ndcg@1: 0.515083\tvalid's ndcg@2: 0.510747\tvalid's ndcg@3: 0.500204   \n",
      "[20]\tvalid's ndcg@1: 0.508253\tvalid's ndcg@2: 0.504798\tvalid's ndcg@3: 0.498882   \n",
      "Early stopping, best iteration is:                                                \n",
      "[2]\tvalid's ndcg@1: 0.528173\tvalid's ndcg@2: 0.503964\tvalid's ndcg@3: 0.49856\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.510529\tvalid's ndcg@2: 0.502786\tvalid's ndcg@3: 0.500948    \n",
      "[10]\tvalid's ndcg@1: 0.505407\tvalid's ndcg@2: 0.49865\tvalid's ndcg@3: 0.498348    \n",
      "[15]\tvalid's ndcg@1: 0.517928\tvalid's ndcg@2: 0.504484\tvalid's ndcg@3: 0.503077   \n",
      "[20]\tvalid's ndcg@1: 0.515652\tvalid's ndcg@2: 0.501767\tvalid's ndcg@3: 0.499836   \n",
      "Early stopping, best iteration is:                                                \n",
      "[1]\tvalid's ndcg@1: 0.524189\tvalid's ndcg@2: 0.505078\tvalid's ndcg@3: 0.493614\n",
      "Training start:                                                                   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76081                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n",
      "Training until validation scores don't improve for 20 rounds                      \n",
      "[5]\tvalid's ndcg@1: 0.517928\tvalid's ndcg@2: 0.509525\tvalid's ndcg@3: 0.500601    \n",
      "[10]\tvalid's ndcg@1: 0.523051\tvalid's ndcg@2: 0.513987\tvalid's ndcg@3: 0.504547   \n",
      "[15]\tvalid's ndcg@1: 0.524758\tvalid's ndcg@2: 0.518638\tvalid's ndcg@3: 0.508335   \n",
      "[20]\tvalid's ndcg@1: 0.520774\tvalid's ndcg@2: 0.516079\tvalid's ndcg@3: 0.506742   \n",
      "Early stopping, best iteration is:                                                \n",
      "[2]\tvalid's ndcg@1: 0.535003\tvalid's ndcg@2: 0.512555\tvalid's ndcg@3: 0.50173\n",
      "100%|██████████| 25/25 [00:28<00:00,  1.14s/trial, best loss: -0.5042178611325363]\n",
      "best parameters: {'lambdarank_truncation_level': 26, 'learning_rate': 0.04043240395979999, 'num_iterations': 48}\n"
     ]
    }
   ],
   "source": [
    "train_data = ll.r.data_c\n",
    "train, valid = split_data(train_data,test_size=0.2,rank_learning=False)\n",
    "# 0.8 : 0.2\n",
    "\n",
    "x_train = train.drop(['rank', 'date','単勝'], axis=1)\n",
    "y_train = train['rank']\n",
    "x_valid = valid.drop(['rank', 'date','単勝'], axis=1)\n",
    "y_valid = valid['rank']\n",
    "train_query = x_train.groupby(x_train.index).size()\n",
    "train = lgb.Dataset(x_train, y_train, group=train_query)\n",
    "valid_query = x_valid.groupby(x_valid.index).size()\n",
    "valid = lgb.Dataset(x_valid, y_valid, reference=train, group=valid_query)\n",
    "\n",
    "\n",
    "def score(params):\n",
    "    print(\"Training start:\")\n",
    "\n",
    "    N_boost_round = []\n",
    "    Score = []\n",
    "\n",
    "    lgb_results={}  #履歴格納用\n",
    "\n",
    "    lgb_clf = lgb.train(\n",
    "        params,\n",
    "        train,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=valid,\n",
    "        valid_names=['valid'],\n",
    "        early_stopping_rounds=20,\n",
    "        verbose_eval=5,\n",
    "        evals_result=lgb_results,\n",
    "    )\n",
    "#     return lgb_results\n",
    "    return {'loss': -1.0 * lgb_results['valid']['ndcg@3'][lgb_clf.best_iteration], 'status': STATUS_OK}\n",
    "\n",
    "def optimize(trials):\n",
    "#探索スペース\n",
    "    space = {\n",
    "        'objective': 'lambdarank',\n",
    "        'metric': 'ndcg',\n",
    "        # 上位三着を考慮する\n",
    "        'ndcg_eval_at': [1,2,3],\n",
    "#         best paramsの返り値は, choiceだとindexか?\n",
    "        'lambdarank_truncation_level': hp.choice('lambdarank_truncation_level',range(1,50)),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.1),\n",
    "        # n_estimators == num_iterations\n",
    "        'num_iterations': hp.choice('num_iterations',range(50,120)),\n",
    "        'boosting_type': 'gbdt',\n",
    "        'random_state': 777\n",
    "    }\n",
    "\n",
    "    max_evals = 25      #探索回数(25くらいで十分)\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=max_evals)\n",
    "\n",
    "    print(\"best parameters:\", best)\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "optimize(trials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad70252",
   "metadata": {},
   "source": [
    "# milestone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977d2055",
   "metadata": {},
   "outputs": [],
   "source": [
    "'lambdarank_truncation_level':  {'lambdarank_truncation_level': 26, 'learning_rate': 0.04043240395979999, 'num_iterations': 48}46, 'learning_rate': 0.023221403531782224, 'num_iterations': 33}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6be3bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "                'metric': 'ndcg',\n",
    "                'objective': 'lambdarank',\n",
    "                'ndcg_eval_at': [1,2,3],\n",
    "                'boosting_type': 'gbdt',\n",
    "                'random_state': 777,\n",
    "                'lambdarank_truncation_level': 27,\n",
    "                'learning_rate': 0.04043240395979999,\n",
    "                'num_iterations': 98,\n",
    "                # 'lambdarank_truncation_level': 10,\n",
    "                # 'learning_rate': 0.02273417953255777,\n",
    "                # n_estimators は num_iterations と同義　default = 100\n",
    "                # 'n_estimators': 97,\n",
    "                # 'num_leaves': 42,\n",
    "                'force_col_wise':True\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "defd053c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 76081\n",
      "[LightGBM] [Info] Number of data points in the train set: 96940, number of used features: 172\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ll.learn_lgb2(train,lgbm_params=lgbm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30c738-f553-4488-8239-235c9808c184",
   "metadata": {},
   "source": [
    "# Simulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a51be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd\n",
    "save_path = '/Users/Owner/Desktop/Horse/ll_obj.pickle'\n",
    "\n",
    "def save_pickle(save_path,object_):\n",
    "    with open(save_path, mode=\"wb\") as f:\n",
    "        pickle.dump(object_, f)\n",
    "\n",
    "def load_pickle(save_path):\n",
    "    with open(save_path, mode=\"rb\") as f:\n",
    "        object_ = pickle.load(f)\n",
    "    return object_\n",
    "\n",
    "# save_pickle(save_path,ll)\n",
    "ll = load_pickle(save_path)\n",
    "ll.learn_model_ft()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4c3498b-a9bf-4891-9ec4-748f1681fe24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "odds 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for odds in [1]:\n",
    "    print()\n",
    "    sl = RankSimulater(ll.model)\n",
    "    print(\"odds\",odds)\n",
    "    fukusho_df = sl.get_result_df(ll.r.data_c.loc[ll.x_test.index[0]:],return_tables,kaime='fukusho',odds=odds)\n",
    "    tansho_df = sl.get_result_df(ll.r.data_c.loc[ll.x_test.index[0]:],return_tables,kaime='tansho',odds=odds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493518ec",
   "metadata": {},
   "source": [
    "# calc results df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba8fd1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fukusho_acc(fukusho_df,odds=1.1,bet=100):\n",
    "    race_num = len(fukusho_df)\n",
    "    count_in3 = 0\n",
    "    count_list = [0 for _ in range(3)]\n",
    "\n",
    "    for i in range(len(fukusho_df)):\n",
    "        col = fukusho_df.iloc[i]\n",
    "        actual_rank_list = col['actual rank list']\n",
    "        pred_list = col['pred list']\n",
    "        fukusho_list = col['fukusho list']\n",
    "        is_in = False\n",
    "        visited = False\n",
    "\n",
    "        for i,pred in enumerate(pred_list):\n",
    "            is_in =  pred in fukusho_list\n",
    "            if is_in and not visited:\n",
    "                count_in3 += 1\n",
    "                visited = True\n",
    "\n",
    "            if pred_list[i] in fukusho_list:\n",
    "                count_list[i] += 1\n",
    "                \n",
    "    # 予測した3頭の馬のうち, 1頭以上複勝圏に含まれている割合\n",
    "    acc_in3 = count_in3/race_num * 100\n",
    "    acc_list = [i/race_num * 100 for i in count_list]\n",
    "\n",
    "    print(\"予測した3頭の馬のうち, 1頭以上複勝圏に含まれている割合\",acc_in3)\n",
    "    print(\"予測した3頭のそれぞれの複勝率\",acc_list)\n",
    "    \n",
    "\n",
    "def calc_tansho_accuracy(result_df,bet=100):\n",
    "    race_num = len(result_df)\n",
    "    atari_num = result_df[result_df['is_atari']==True].sum()['is_atari']\n",
    "    acc = (atari_num/race_num) * 100\n",
    "    \n",
    "    buy_num = result_df[result_df['is_buy']==True].sum()['is_buy']\n",
    "    buy_df = result_df[result_df['is_buy']]\n",
    "    atari_buy_num = buy_df[buy_df['is_atari']==True].sum()['is_atari']\n",
    "    # 条件付き精度 (買ったもとで当たった確率)\n",
    "    acc_cond = (atari_buy_num/buy_num) * 100\n",
    "    total_expense = buy_num * bet\n",
    "    return_price = result_df.sum()['profit']\n",
    "    # 回収率\n",
    "    profit_rate = (total_expense + return_price)/total_expense * 100\n",
    "    atari_dist = {i:0 for i in range(1,13)}\n",
    "    atari_buy_df = buy_df[buy_df['is_atari']==True]\n",
    "\n",
    "    for race_id in atari_buy_df.index:\n",
    "        race_num = int(str(race_id)[-2:])\n",
    "        atari_dist[race_num] += (1/atari_buy_num) * 100\n",
    "    \n",
    "    print('acc ',acc)\n",
    "    print('acc cond',acc_cond)\n",
    "    print('profit rate',profit_rate)\n",
    "    print('atari race distribution',atari_dist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b2e3331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "予測した3頭の馬のうち, 1頭以上複勝圏に含まれている割合 86.20302860347728\n",
      "予測した3頭のそれぞれの複勝率 [50.1402131239484, 41.61525518788559, 38.75490745933819]\n"
     ]
    }
   ],
   "source": [
    "calc_fukusho_acc(fukusho_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64589db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc  22.994952327537856\n",
      "acc cond 22.87323943661972\n",
      "profit rate 104.82816901408452\n",
      "atari race distribution {1: 10.344827586206895, 2: 8.866995073891625, 3: 8.374384236453201, 4: 9.60591133004926, 5: 8.620689655172413, 6: 8.12807881773399, 7: 10.591133004926107, 8: 7.881773399014777, 9: 7.635467980295565, 10: 6.403940886699506, 11: 5.1724137931034475, 12: 8.374384236453201}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "calc_tansho_accuracy(tansho_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff135d8f-2a18-4583-8747-68c2938e6b79",
   "metadata": {},
   "source": [
    "# race_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ca02207f-1319-48d2-943f-195f395e1d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "race_id_list = ['2022040307{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "race_id_list += ['2022100407{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "race_id_list += ['2022010207{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "\n",
    "# race_id_list = ['2022040304{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022100404{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022010204{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "\n",
    "\n",
    "\n",
    "# race_id_list += ['2022050308{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "\n",
    "# race_id_list += ['2022090301{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022090302{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022090303{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022090304{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "\n",
    "# race_id_list += ['2022020103{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022020104{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022020105{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "# race_id_list += ['2022020106{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23038204",
   "metadata": {},
   "source": [
    "# Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "869c4470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f984fa64c3d7487290d9555094831c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5d2714fbe6428aa038a08597b32c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc7916902914cfb8dd739ba04a34b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5431fd26f9074ce4be73391d2400f9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18721 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pe finish\n",
      "pe regularizrd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261e9450352946628c092507a8c8cc53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/508 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hr finish\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7225bafbff044725a1aae6466c9db76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81190493efc642cdb8dabd9358cc4aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec322ebbcd454d768a033cc3d94f4fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 80267\n",
      "[LightGBM] [Info] Number of data points in the train set: 120792, number of used features: 172\n"
     ]
    }
   ],
   "source": [
    "pt = Predictor(peds,results,horse_results,race_id_list)\n",
    "# ********* test_size = 0  : ずっと0にしてなかった...\n",
    "pt.path_ft = '/Users/Owner/Desktop/Horse/horse/peds_ft.txt'\n",
    "pt.learn_lgb(lgbm_params=lgbm_params,test_size=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32941e34",
   "metadata": {},
   "source": [
    "# 新潟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6aaf56de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9cd847b09c4708a29fb081202a030d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e7e16a378d49de996ca976009dadd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721d713777864834911d4eb05c5aa123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006fc5aca30347a89a03397e4318e1de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              馬番    scores\n",
      "202204030703  12 -0.083040\n",
      "202204030703   7 -0.133025\n",
      "202204030703   3 -0.273863\n",
      "202204030703  15 -0.334509\n",
      "202204030703  13 -0.390595\n",
      "202204030703   8 -0.402360\n",
      "202204030703   1 -0.785690\n",
      "202204030703   4 -1.245195\n",
      "202204030703   9 -1.265238\n",
      "202204030703   6 -1.286396\n",
      "202204030703   5 -1.316701\n",
      "202204030703  14 -1.579693\n",
      "202204030703  11 -2.201587\n",
      "202204030703  10 -2.358785\n",
      "202204030703   2 -2.416950\n"
     ]
    }
   ],
   "source": [
    "base  = '2022040307'\n",
    "pt.predict(base+'03')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b57a3d",
   "metadata": {},
   "source": [
    "# 小倉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a6722cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b517b11cf68b41189eacea368bd2c1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700a43ffcf534348a1c4ca8f9df1c4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a007d9d5d94d4af5bbff202f12efd066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d14e77f59d4b949a03abdcf425bad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              馬番    scores\n",
      "202210040704   2  0.299285\n",
      "202210040704   5 -0.372617\n",
      "202210040704  16 -0.376470\n",
      "202210040704  11 -0.548466\n",
      "202210040704   9 -0.880869\n",
      "202210040704   3 -1.064032\n",
      "202210040704   1 -1.100521\n",
      "202210040704  13 -1.206352\n",
      "202210040704  15 -1.214258\n",
      "202210040704  10 -1.316961\n",
      "202210040704   6 -1.662008\n",
      "202210040704   8 -1.989135\n",
      "202210040704  14 -2.181520\n",
      "202210040704  12 -2.206638\n",
      "202210040704   4 -2.257664\n",
      "202210040704   7 -2.332593\n"
     ]
    }
   ],
   "source": [
    "base  = '2022100407'\n",
    "# for i in ['07','08','09','10','11']:\n",
    "pt.predict(base+'04')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e1ee5",
   "metadata": {},
   "source": [
    "# 札幌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "base  = '2022010207'\n",
    "pt.predict(base+'06')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c82bc",
   "metadata": {},
   "source": [
    "# 当日の収支計算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92025ba",
   "metadata": {},
   "source": [
    "return_tables　と, return_tables_todayで形式が異なるので, 形式をそろえる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f72488",
   "metadata": {},
   "source": [
    "# 当日 sim 手順"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7f9297d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7ab2047f6449929266c31f0f2eb234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data =  ShutubaTable.scrape(race_id_list, pt.date)\n",
    "# st = ShutubaTable(data)\n",
    "# st.preprocessing()\n",
    "# st.merge_horse_results(pt.hr)\n",
    "# st.merge_peds(pt.pe.peds_vec)\n",
    "# st.process_categorical(pt.r.le_horse, pt.r.le_jockey, pt.r.data_pe)\n",
    "\n",
    "\n",
    "tsl = TodaySimulater(pt.model)\n",
    "tsl.return_table_today(race_id_list)\n",
    "all_results = tsl.get_result_df( st.data_c, tsl.return_tables,race_id_list, kaime='all',odds=1)\n",
    "tansho_results = tsl.get_result_df( st.data_c, tsl.return_tables,race_id_list, kaime='tansho',odds=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59412d0",
   "metadata": {},
   "source": [
    "# previous params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5ada4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_list</th>\n",
       "      <th>actual_rank_list</th>\n",
       "      <th>tansho_odds</th>\n",
       "      <th>fukusho_odds</th>\n",
       "      <th>umaren_odds</th>\n",
       "      <th>wide_odds</th>\n",
       "      <th>umatan_odds</th>\n",
       "      <th>sanrenpuku_odds</th>\n",
       "      <th>sanrentan_odds</th>\n",
       "      <th>wide_comb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202204030501</th>\n",
       "      <td>[15, 8, 14, 12, 2, 7, 9, 10, 6, 4, 11, 3, 1, 5...</td>\n",
       "      <td>[15, 8, 12]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[1.2, 1.1, 2.2]</td>\n",
       "      <td>2.8</td>\n",
       "      <td>[1.6, 4.7, 3.5]</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>[[8, 15], [12, 15], [8, 12]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030502</th>\n",
       "      <td>[1, 15, 7, 13, 3, 14, 5, 10, 8, 11, 6, 2, 12, ...</td>\n",
       "      <td>[15, 5, 1]</td>\n",
       "      <td>5.8</td>\n",
       "      <td>[1.8, 6.8, 1.3]</td>\n",
       "      <td>88.7</td>\n",
       "      <td>[25.0, 3.0, 14.0]</td>\n",
       "      <td>170.0</td>\n",
       "      <td>50.2</td>\n",
       "      <td>435.9</td>\n",
       "      <td>[[5, 15], [1, 15], [1, 5]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030503</th>\n",
       "      <td>[1, 7, 12, 9, 15, 5, 13, 14, 2, 4, 11, 3, 10, 8]</td>\n",
       "      <td>[7, 9, 14]</td>\n",
       "      <td>6.9</td>\n",
       "      <td>[2.1, 4.4, 3.2]</td>\n",
       "      <td>58.4</td>\n",
       "      <td>[16.5, 8.9, 25.5]</td>\n",
       "      <td>109.5</td>\n",
       "      <td>164.0</td>\n",
       "      <td>942.7</td>\n",
       "      <td>[[7, 9], [7, 14], [9, 14]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030504</th>\n",
       "      <td>[3, 11, 10, 7, 6, 1, 4, 9, 8, 2, 5, 13, 14, 12]</td>\n",
       "      <td>[10, 13, 9]</td>\n",
       "      <td>5.6</td>\n",
       "      <td>[2.0, 6.3, 1.8]</td>\n",
       "      <td>82.4</td>\n",
       "      <td>[28.2, 5.6, 17.8]</td>\n",
       "      <td>124.4</td>\n",
       "      <td>93.0</td>\n",
       "      <td>706.4</td>\n",
       "      <td>[[10, 13], [9, 10], [9, 13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030505</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]</td>\n",
       "      <td>[10, 2, 7]</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[1.5, 1.8, 1.1]</td>\n",
       "      <td>31.1</td>\n",
       "      <td>[6.4, 2.5, 3.0]</td>\n",
       "      <td>58.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>106.7</td>\n",
       "      <td>[[2, 10], [7, 10], [2, 7]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030506</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[2, 6, 11]</td>\n",
       "      <td>6.6</td>\n",
       "      <td>[1.9, 2.5, 1.4]</td>\n",
       "      <td>42.2</td>\n",
       "      <td>[12.3, 4.9, 5.5]</td>\n",
       "      <td>69.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>[[2, 6], [2, 11], [6, 11]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030507</th>\n",
       "      <td>[18, 14, 15, 12, 16, 5, 13, 11, 10, 4, 3, 7, 2...</td>\n",
       "      <td>[12, 16, 4]</td>\n",
       "      <td>6.5</td>\n",
       "      <td>[2.0, 1.8, 2.2]</td>\n",
       "      <td>19.9</td>\n",
       "      <td>[6.8, 7.2, 7.5]</td>\n",
       "      <td>32.6</td>\n",
       "      <td>39.6</td>\n",
       "      <td>247.6</td>\n",
       "      <td>[[12, 16], [4, 12], [4, 16]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030508</th>\n",
       "      <td>[1, 12, 8, 15, 9, 7, 13, 11, 4, 5, 10, 6, 14, ...</td>\n",
       "      <td>[9, 13, 12]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[2.0, 5.8, 1.7]</td>\n",
       "      <td>69.7</td>\n",
       "      <td>[20.4, 3.9, 13.2]</td>\n",
       "      <td>94.9</td>\n",
       "      <td>57.9</td>\n",
       "      <td>473.8</td>\n",
       "      <td>[[9, 13], [9, 12], [12, 13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030509</th>\n",
       "      <td>[14, 10, 6, 9, 4, 7, 11, 8, 12, 13, 2, 5, 1, 3...</td>\n",
       "      <td>[8, 13, 6]</td>\n",
       "      <td>1.7</td>\n",
       "      <td>[1.1, 4.6, 1.4]</td>\n",
       "      <td>23.8</td>\n",
       "      <td>[8.1, 2.1, 18.7]</td>\n",
       "      <td>29.8</td>\n",
       "      <td>32.5</td>\n",
       "      <td>136.6</td>\n",
       "      <td>[[8, 13], [6, 8], [6, 13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030510</th>\n",
       "      <td>[2, 7, 1, 13, 5, 15, 11, 12, 4, 6, 8, 3, 10, 9...</td>\n",
       "      <td>[13, 11, 5]</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[1.5, 1.9, 2.2]</td>\n",
       "      <td>11.3</td>\n",
       "      <td>[4.5, 5.8, 8.3]</td>\n",
       "      <td>19.8</td>\n",
       "      <td>29.9</td>\n",
       "      <td>123.7</td>\n",
       "      <td>[[11, 13], [5, 13], [5, 11]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030511</th>\n",
       "      <td>[10, 4, 7, 1, 8, 14, 5, 3, 6, 2, 11, 9, 13, 12...</td>\n",
       "      <td>[6, 14, 12]</td>\n",
       "      <td>6.6</td>\n",
       "      <td>[2.3, 2.5, 10.3]</td>\n",
       "      <td>28.3</td>\n",
       "      <td>[11.0, 56.1, 48.5]</td>\n",
       "      <td>58.7</td>\n",
       "      <td>439.0</td>\n",
       "      <td>2315.1</td>\n",
       "      <td>[[6, 14], [6, 12], [12, 14]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202204030512</th>\n",
       "      <td>[5, 4, 6, 8, 12, 1, 18, 3, 15, 7, 10, 11, 14, ...</td>\n",
       "      <td>[4, 5, 2]</td>\n",
       "      <td>2.7</td>\n",
       "      <td>[1.5, 3.3, 7.1]</td>\n",
       "      <td>26.2</td>\n",
       "      <td>[9.4, 14.3, 73.1]</td>\n",
       "      <td>38.4</td>\n",
       "      <td>195.7</td>\n",
       "      <td>784.9</td>\n",
       "      <td>[[4, 5], [2, 4], [2, 5]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040501</th>\n",
       "      <td>[7, 1, 6, 2, 4, 5, 3, 8]</td>\n",
       "      <td>[7, 2, 1]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[1.1, 1.1, 1.1]</td>\n",
       "      <td>2.7</td>\n",
       "      <td>[1.2, 1.9, 1.5]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>[[2, 7], [1, 7], [1, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040502</th>\n",
       "      <td>[4, 2, 14, 12, 8, 6, 5, 1, 3, 10, 7, 9, 13, 11]</td>\n",
       "      <td>[4, 14, 3]</td>\n",
       "      <td>1.6</td>\n",
       "      <td>[1.1, 1.4, 16.3]</td>\n",
       "      <td>3.3</td>\n",
       "      <td>[1.8, 21.1, 66.7]</td>\n",
       "      <td>5.5</td>\n",
       "      <td>103.9</td>\n",
       "      <td>219.7</td>\n",
       "      <td>[[4, 14], [3, 4], [3, 14]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040503</th>\n",
       "      <td>[15, 12, 10, 2, 9, 1, 14, 6, 16, 11, 4, 18, 7,...</td>\n",
       "      <td>[15, 12, 14]</td>\n",
       "      <td>1.7</td>\n",
       "      <td>[1.1, 2.5, 5.1]</td>\n",
       "      <td>8.5</td>\n",
       "      <td>[3.9, 8.2, 41.8]</td>\n",
       "      <td>11.7</td>\n",
       "      <td>69.8</td>\n",
       "      <td>175.6</td>\n",
       "      <td>[[12, 15], [14, 15], [12, 14]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040504</th>\n",
       "      <td>[1, 9, 10, 16, 5, 4, 7, 6, 13, 2, 15, 8, 14, 3...</td>\n",
       "      <td>[5, 7, 1]</td>\n",
       "      <td>11.4</td>\n",
       "      <td>[2.7, 2.9, 1.4]</td>\n",
       "      <td>66.6</td>\n",
       "      <td>[22.2, 6.7, 7.0]</td>\n",
       "      <td>181.8</td>\n",
       "      <td>60.4</td>\n",
       "      <td>644.7</td>\n",
       "      <td>[[5, 7], [1, 5], [1, 7]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040505</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>[2, 9, 3]</td>\n",
       "      <td>6.4</td>\n",
       "      <td>[1.7, 1.3, 7.0]</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[3.6, 23.5, 22.6]</td>\n",
       "      <td>21.8</td>\n",
       "      <td>97.5</td>\n",
       "      <td>472.1</td>\n",
       "      <td>[[2, 9], [2, 3], [3, 9]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040506</th>\n",
       "      <td>[4, 11, 10, 8, 17, 5, 12, 6, 15, 14, 16, 2, 9,...</td>\n",
       "      <td>[4, 5, 11]</td>\n",
       "      <td>2.1</td>\n",
       "      <td>[1.2, 2.4, 1.5]</td>\n",
       "      <td>12.1</td>\n",
       "      <td>[5.2, 2.4, 6.9]</td>\n",
       "      <td>17.6</td>\n",
       "      <td>16.7</td>\n",
       "      <td>76.7</td>\n",
       "      <td>[[4, 5], [4, 11], [5, 11]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040507</th>\n",
       "      <td>[11, 7, 13, 12, 6, 8, 15, 10, 1, 2, 4, 3, 9, 1...</td>\n",
       "      <td>[7, 2, 1]</td>\n",
       "      <td>1.5</td>\n",
       "      <td>[1.1, 2.5, 1.6]</td>\n",
       "      <td>11.2</td>\n",
       "      <td>[4.9, 2.7, 10.0]</td>\n",
       "      <td>12.7</td>\n",
       "      <td>17.9</td>\n",
       "      <td>51.8</td>\n",
       "      <td>[[2, 7], [1, 7], [1, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040508</th>\n",
       "      <td>[5, 8, 13, 3, 1, 7, 4, 10, 2, 9, 11, 6, 12]</td>\n",
       "      <td>[9, 1, 8]</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[1.4, 1.5, 4.4]</td>\n",
       "      <td>5.4</td>\n",
       "      <td>[2.6, 6.9, 12.1]</td>\n",
       "      <td>9.2</td>\n",
       "      <td>24.7</td>\n",
       "      <td>77.6</td>\n",
       "      <td>[[1, 9], [8, 9], [1, 8]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040509</th>\n",
       "      <td>[3, 16, 5, 15, 10, 14, 13, 8, 4, 11, 17, 1, 12...</td>\n",
       "      <td>[16, 3, 10]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[1.1, 1.7, 3.3]</td>\n",
       "      <td>5.1</td>\n",
       "      <td>[2.4, 7.3, 10.7]</td>\n",
       "      <td>6.9</td>\n",
       "      <td>27.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>[[3, 16], [10, 16], [3, 10]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040510</th>\n",
       "      <td>[6, 3, 8, 2, 5, 4, 7, 1, 9]</td>\n",
       "      <td>[8, 2, 6]</td>\n",
       "      <td>10.3</td>\n",
       "      <td>[2.8, 2.7, 1.5]</td>\n",
       "      <td>54.4</td>\n",
       "      <td>[11.3, 6.4, 7.7]</td>\n",
       "      <td>96.4</td>\n",
       "      <td>60.8</td>\n",
       "      <td>480.5</td>\n",
       "      <td>[[2, 8], [6, 8], [2, 6]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040511</th>\n",
       "      <td>[2, 10, 4, 13, 6, 1, 9, 8, 7, 12, 5, 3, 14, 11]</td>\n",
       "      <td>[14, 13, 1]</td>\n",
       "      <td>9.1</td>\n",
       "      <td>[3.9, 2.0, 10.2]</td>\n",
       "      <td>31.1</td>\n",
       "      <td>[11.7, 54.6, 33.5]</td>\n",
       "      <td>56.2</td>\n",
       "      <td>307.8</td>\n",
       "      <td>1154.7</td>\n",
       "      <td>[[13, 14], [1, 14], [1, 13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202210040512</th>\n",
       "      <td>[8, 3, 2, 7, 1, 4, 5, 6]</td>\n",
       "      <td>[2, 1, 8]</td>\n",
       "      <td>5.7</td>\n",
       "      <td>[1.4, 1.5, 1.1]</td>\n",
       "      <td>18.5</td>\n",
       "      <td>[4.6, 2.2, 2.3]</td>\n",
       "      <td>37.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>87.1</td>\n",
       "      <td>[[1, 2], [2, 8], [1, 8]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020501</th>\n",
       "      <td>[3, 5, 4, 7, 2, 6, 1]</td>\n",
       "      <td>[5, 3, 2]</td>\n",
       "      <td>1.2</td>\n",
       "      <td>[1.1, 1.4]</td>\n",
       "      <td>1.9</td>\n",
       "      <td>[1.2, 2.2, 2.5]</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>[[3, 5], [2, 5], [2, 3]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020502</th>\n",
       "      <td>[8, 4, 7, 1, 6, 5, 2, 3]</td>\n",
       "      <td>[7, 4, 8]</td>\n",
       "      <td>5.1</td>\n",
       "      <td>[1.1, 1.1, 1.1]</td>\n",
       "      <td>4.7</td>\n",
       "      <td>[1.6, 1.5, 1.1]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>[[4, 7], [7, 8], [4, 8]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020503</th>\n",
       "      <td>[11, 10, 9, 3, 7, 1, 8, 2, 4, 5, 12, 6]</td>\n",
       "      <td>[7, 10, 8]</td>\n",
       "      <td>3.5</td>\n",
       "      <td>[1.3, 1.5, 1.8]</td>\n",
       "      <td>6.3</td>\n",
       "      <td>[2.2, 4.3, 4.3]</td>\n",
       "      <td>11.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>61.8</td>\n",
       "      <td>[[7, 10], [7, 8], [8, 10]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020504</th>\n",
       "      <td>[1, 8, 6, 7, 2, 10, 13, 12, 5, 11, 3, 4, 9, 14]</td>\n",
       "      <td>[6, 8, 1]</td>\n",
       "      <td>7.7</td>\n",
       "      <td>[1.6, 1.1, 1.1]</td>\n",
       "      <td>7.2</td>\n",
       "      <td>[2.6, 3.7, 1.7]</td>\n",
       "      <td>23.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>53.8</td>\n",
       "      <td>[[6, 8], [1, 6], [1, 8]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020505</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[6, 3, 5]</td>\n",
       "      <td>5.3</td>\n",
       "      <td>[1.7, 1.1]</td>\n",
       "      <td>3.9</td>\n",
       "      <td>[1.7, 3.0, 1.8]</td>\n",
       "      <td>11.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>41.4</td>\n",
       "      <td>[[3, 6], [5, 6], [3, 5]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020506</th>\n",
       "      <td>[10, 6, 7, 4, 8, 9, 11, 2, 5, 1, 14, 13, 12]</td>\n",
       "      <td>[7, 11, 10]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[1.6, 2.1, 2.2]</td>\n",
       "      <td>19.4</td>\n",
       "      <td>[7.1, 5.2, 7.8]</td>\n",
       "      <td>34.3</td>\n",
       "      <td>40.2</td>\n",
       "      <td>204.1</td>\n",
       "      <td>[[7, 11], [7, 10], [10, 11]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020507</th>\n",
       "      <td>[7, 4, 1, 9, 11, 6, 8, 10, 13, 5, 2, 12, 14, 3]</td>\n",
       "      <td>[4, 10, 13]</td>\n",
       "      <td>1.5</td>\n",
       "      <td>[1.1, 1.6, 2.0]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[2.5, 3.6, 8.4]</td>\n",
       "      <td>5.7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>35.7</td>\n",
       "      <td>[[4, 10], [4, 13], [10, 13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020508</th>\n",
       "      <td>[9, 12, 1, 5, 7, 6, 11, 8, 10, 4, 14, 2, 13, 3]</td>\n",
       "      <td>[9, 12, 7]</td>\n",
       "      <td>2.8</td>\n",
       "      <td>[1.2, 2.3, 1.3]</td>\n",
       "      <td>15.2</td>\n",
       "      <td>[4.6, 2.1, 6.2]</td>\n",
       "      <td>21.5</td>\n",
       "      <td>14.9</td>\n",
       "      <td>80.9</td>\n",
       "      <td>[[9, 12], [7, 9], [7, 12]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020509</th>\n",
       "      <td>[2, 7, 13, 8, 12, 4, 5, 1, 9, 11, 6, 10, 14, 3]</td>\n",
       "      <td>[2, 4, 8]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[1.7, 5.2, 1.9]</td>\n",
       "      <td>56.8</td>\n",
       "      <td>[18.3, 3.2, 18.0]</td>\n",
       "      <td>90.3</td>\n",
       "      <td>68.5</td>\n",
       "      <td>474.7</td>\n",
       "      <td>[[2, 4], [2, 8], [4, 8]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020510</th>\n",
       "      <td>[13, 6, 11, 10, 8, 1, 12, 2, 5, 4, 9, 3, 7, 14]</td>\n",
       "      <td>[12, 11, 13]</td>\n",
       "      <td>10.4</td>\n",
       "      <td>[3.4, 2.5, 1.9]</td>\n",
       "      <td>36.9</td>\n",
       "      <td>[14.0, 8.2, 6.4]</td>\n",
       "      <td>86.2</td>\n",
       "      <td>44.8</td>\n",
       "      <td>308.3</td>\n",
       "      <td>[[11, 12], [12, 13], [11, 13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020511</th>\n",
       "      <td>[10, 12, 11, 9, 5, 6, 3, 4, 1, 8, 13, 14, 7, 2]</td>\n",
       "      <td>[13, 8, 9]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[2.1, 6.3, 2.2]</td>\n",
       "      <td>70.5</td>\n",
       "      <td>[20.7, 7.4, 28.4]</td>\n",
       "      <td>111.0</td>\n",
       "      <td>136.6</td>\n",
       "      <td>712.3</td>\n",
       "      <td>[[8, 13], [9, 13], [8, 9]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202201020512</th>\n",
       "      <td>[3, 6, 1, 5, 7, 10, 2, 13, 9, 8, 14, 11, 12, 4]</td>\n",
       "      <td>[5, 13, 9]</td>\n",
       "      <td>3.5</td>\n",
       "      <td>[2.0, 4.9, 3.7]</td>\n",
       "      <td>47.9</td>\n",
       "      <td>[17.0, 13.5, 36.5]</td>\n",
       "      <td>68.6</td>\n",
       "      <td>225.2</td>\n",
       "      <td>1081.1</td>\n",
       "      <td>[[5, 13], [5, 9], [9, 13]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      pred_list  \\\n",
       "202204030501  [15, 8, 14, 12, 2, 7, 9, 10, 6, 4, 11, 3, 1, 5...   \n",
       "202204030502  [1, 15, 7, 13, 3, 14, 5, 10, 8, 11, 6, 2, 12, ...   \n",
       "202204030503   [1, 7, 12, 9, 15, 5, 13, 14, 2, 4, 11, 3, 10, 8]   \n",
       "202204030504    [3, 11, 10, 7, 6, 1, 4, 9, 8, 2, 5, 13, 14, 12]   \n",
       "202204030505        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]   \n",
       "202204030506  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "202204030507  [18, 14, 15, 12, 16, 5, 13, 11, 10, 4, 3, 7, 2...   \n",
       "202204030508  [1, 12, 8, 15, 9, 7, 13, 11, 4, 5, 10, 6, 14, ...   \n",
       "202204030509  [14, 10, 6, 9, 4, 7, 11, 8, 12, 13, 2, 5, 1, 3...   \n",
       "202204030510  [2, 7, 1, 13, 5, 15, 11, 12, 4, 6, 8, 3, 10, 9...   \n",
       "202204030511  [10, 4, 7, 1, 8, 14, 5, 3, 6, 2, 11, 9, 13, 12...   \n",
       "202204030512  [5, 4, 6, 8, 12, 1, 18, 3, 15, 7, 10, 11, 14, ...   \n",
       "202210040501                           [7, 1, 6, 2, 4, 5, 3, 8]   \n",
       "202210040502    [4, 2, 14, 12, 8, 6, 5, 1, 3, 10, 7, 9, 13, 11]   \n",
       "202210040503  [15, 12, 10, 2, 9, 1, 14, 6, 16, 11, 4, 18, 7,...   \n",
       "202210040504  [1, 9, 10, 16, 5, 4, 7, 6, 13, 2, 15, 8, 14, 3...   \n",
       "202210040505                        [1, 2, 3, 4, 5, 6, 7, 8, 9]   \n",
       "202210040506  [4, 11, 10, 8, 17, 5, 12, 6, 15, 14, 16, 2, 9,...   \n",
       "202210040507  [11, 7, 13, 12, 6, 8, 15, 10, 1, 2, 4, 3, 9, 1...   \n",
       "202210040508        [5, 8, 13, 3, 1, 7, 4, 10, 2, 9, 11, 6, 12]   \n",
       "202210040509  [3, 16, 5, 15, 10, 14, 13, 8, 4, 11, 17, 1, 12...   \n",
       "202210040510                        [6, 3, 8, 2, 5, 4, 7, 1, 9]   \n",
       "202210040511    [2, 10, 4, 13, 6, 1, 9, 8, 7, 12, 5, 3, 14, 11]   \n",
       "202210040512                           [8, 3, 2, 7, 1, 4, 5, 6]   \n",
       "202201020501                              [3, 5, 4, 7, 2, 6, 1]   \n",
       "202201020502                           [8, 4, 7, 1, 6, 5, 2, 3]   \n",
       "202201020503            [11, 10, 9, 3, 7, 1, 8, 2, 4, 5, 12, 6]   \n",
       "202201020504    [1, 8, 6, 7, 2, 10, 13, 12, 5, 11, 3, 4, 9, 14]   \n",
       "202201020505                              [1, 2, 3, 4, 5, 6, 7]   \n",
       "202201020506       [10, 6, 7, 4, 8, 9, 11, 2, 5, 1, 14, 13, 12]   \n",
       "202201020507    [7, 4, 1, 9, 11, 6, 8, 10, 13, 5, 2, 12, 14, 3]   \n",
       "202201020508    [9, 12, 1, 5, 7, 6, 11, 8, 10, 4, 14, 2, 13, 3]   \n",
       "202201020509    [2, 7, 13, 8, 12, 4, 5, 1, 9, 11, 6, 10, 14, 3]   \n",
       "202201020510    [13, 6, 11, 10, 8, 1, 12, 2, 5, 4, 9, 3, 7, 14]   \n",
       "202201020511    [10, 12, 11, 9, 5, 6, 3, 4, 1, 8, 13, 14, 7, 2]   \n",
       "202201020512    [3, 6, 1, 5, 7, 10, 2, 13, 9, 8, 14, 11, 12, 4]   \n",
       "\n",
       "             actual_rank_list tansho_odds      fukusho_odds umaren_odds  \\\n",
       "202204030501      [15, 8, 12]         3.0   [1.2, 1.1, 2.2]         2.8   \n",
       "202204030502       [15, 5, 1]         5.8   [1.8, 6.8, 1.3]        88.7   \n",
       "202204030503       [7, 9, 14]         6.9   [2.1, 4.4, 3.2]        58.4   \n",
       "202204030504      [10, 13, 9]         5.6   [2.0, 6.3, 1.8]        82.4   \n",
       "202204030505       [10, 2, 7]         7.5   [1.5, 1.8, 1.1]        31.1   \n",
       "202204030506       [2, 6, 11]         6.6   [1.9, 2.5, 1.4]        42.2   \n",
       "202204030507      [12, 16, 4]         6.5   [2.0, 1.8, 2.2]        19.9   \n",
       "202204030508      [9, 13, 12]         4.6   [2.0, 5.8, 1.7]        69.7   \n",
       "202204030509       [8, 13, 6]         1.7   [1.1, 4.6, 1.4]        23.8   \n",
       "202204030510      [13, 11, 5]         3.8   [1.5, 1.9, 2.2]        11.3   \n",
       "202204030511      [6, 14, 12]         6.6  [2.3, 2.5, 10.3]        28.3   \n",
       "202204030512        [4, 5, 2]         2.7   [1.5, 3.3, 7.1]        26.2   \n",
       "202210040501        [7, 2, 1]         3.4   [1.1, 1.1, 1.1]         2.7   \n",
       "202210040502       [4, 14, 3]         1.6  [1.1, 1.4, 16.3]         3.3   \n",
       "202210040503     [15, 12, 14]         1.7   [1.1, 2.5, 5.1]         8.5   \n",
       "202210040504        [5, 7, 1]        11.4   [2.7, 2.9, 1.4]        66.6   \n",
       "202210040505        [2, 9, 3]         6.4   [1.7, 1.3, 7.0]         8.2   \n",
       "202210040506       [4, 5, 11]         2.1   [1.2, 2.4, 1.5]        12.1   \n",
       "202210040507        [7, 2, 1]         1.5   [1.1, 2.5, 1.6]        11.2   \n",
       "202210040508        [9, 1, 8]         2.9   [1.4, 1.5, 4.4]         5.4   \n",
       "202210040509      [16, 3, 10]         2.0   [1.1, 1.7, 3.3]         5.1   \n",
       "202210040510        [8, 2, 6]        10.3   [2.8, 2.7, 1.5]        54.4   \n",
       "202210040511      [14, 13, 1]         9.1  [3.9, 2.0, 10.2]        31.1   \n",
       "202210040512        [2, 1, 8]         5.7   [1.4, 1.5, 1.1]        18.5   \n",
       "202201020501        [5, 3, 2]         1.2        [1.1, 1.4]         1.9   \n",
       "202201020502        [7, 4, 8]         5.1   [1.1, 1.1, 1.1]         4.7   \n",
       "202201020503       [7, 10, 8]         3.5   [1.3, 1.5, 1.8]         6.3   \n",
       "202201020504        [6, 8, 1]         7.7   [1.6, 1.1, 1.1]         7.2   \n",
       "202201020505        [6, 3, 5]         5.3        [1.7, 1.1]         3.9   \n",
       "202201020506      [7, 11, 10]         4.6   [1.6, 2.1, 2.2]        19.4   \n",
       "202201020507      [4, 10, 13]         1.5   [1.1, 1.6, 2.0]         4.6   \n",
       "202201020508       [9, 12, 7]         2.8   [1.2, 2.3, 1.3]        15.2   \n",
       "202201020509        [2, 4, 8]         4.0   [1.7, 5.2, 1.9]        56.8   \n",
       "202201020510     [12, 11, 13]        10.4   [3.4, 2.5, 1.9]        36.9   \n",
       "202201020511       [13, 8, 9]         5.0   [2.1, 6.3, 2.2]        70.5   \n",
       "202201020512       [5, 13, 9]         3.5   [2.0, 4.9, 3.7]        47.9   \n",
       "\n",
       "                       wide_odds umatan_odds sanrenpuku_odds sanrentan_odds  \\\n",
       "202204030501     [1.6, 4.7, 3.5]         7.3             8.3           38.0   \n",
       "202204030502   [25.0, 3.0, 14.0]       170.0            50.2          435.9   \n",
       "202204030503   [16.5, 8.9, 25.5]       109.5           164.0          942.7   \n",
       "202204030504   [28.2, 5.6, 17.8]       124.4            93.0          706.4   \n",
       "202204030505     [6.4, 2.5, 3.0]        58.0             9.3          106.7   \n",
       "202204030506    [12.3, 4.9, 5.5]        69.0            40.0          266.0   \n",
       "202204030507     [6.8, 7.2, 7.5]        32.6            39.6          247.6   \n",
       "202204030508   [20.4, 3.9, 13.2]        94.9            57.9          473.8   \n",
       "202204030509    [8.1, 2.1, 18.7]        29.8            32.5          136.6   \n",
       "202204030510     [4.5, 5.8, 8.3]        19.8            29.9          123.7   \n",
       "202204030511  [11.0, 56.1, 48.5]        58.7           439.0         2315.1   \n",
       "202204030512   [9.4, 14.3, 73.1]        38.4           195.7          784.9   \n",
       "202210040501     [1.2, 1.9, 1.5]         7.0             2.7           15.5   \n",
       "202210040502   [1.8, 21.1, 66.7]         5.5           103.9          219.7   \n",
       "202210040503    [3.9, 8.2, 41.8]        11.7            69.8          175.6   \n",
       "202210040504    [22.2, 6.7, 7.0]       181.8            60.4          644.7   \n",
       "202210040505   [3.6, 23.5, 22.6]        21.8            97.5          472.1   \n",
       "202210040506     [5.2, 2.4, 6.9]        17.6            16.7           76.7   \n",
       "202210040507    [4.9, 2.7, 10.0]        12.7            17.9           51.8   \n",
       "202210040508    [2.6, 6.9, 12.1]         9.2            24.7           77.6   \n",
       "202210040509    [2.4, 7.3, 10.7]         6.9            27.2           70.0   \n",
       "202210040510    [11.3, 6.4, 7.7]        96.4            60.8          480.5   \n",
       "202210040511  [11.7, 54.6, 33.5]        56.2           307.8         1154.7   \n",
       "202210040512     [4.6, 2.2, 2.3]        37.5             6.9           87.1   \n",
       "202201020501     [1.2, 2.2, 2.5]         2.5             2.8            8.4   \n",
       "202201020502     [1.6, 1.5, 1.1]        12.0             2.0           18.3   \n",
       "202201020503     [2.2, 4.3, 4.3]        11.4            13.7           61.8   \n",
       "202201020504     [2.6, 3.7, 1.7]        23.3             6.7           53.8   \n",
       "202201020505     [1.7, 3.0, 1.8]        11.5             6.9           41.4   \n",
       "202201020506     [7.1, 5.2, 7.8]        34.3            40.2          204.1   \n",
       "202201020507     [2.5, 3.6, 8.4]         5.7            16.5           35.7   \n",
       "202201020508     [4.6, 2.1, 6.2]        21.5            14.9           80.9   \n",
       "202201020509   [18.3, 3.2, 18.0]        90.3            68.5          474.7   \n",
       "202201020510    [14.0, 8.2, 6.4]        86.2            44.8          308.3   \n",
       "202201020511   [20.7, 7.4, 28.4]       111.0           136.6          712.3   \n",
       "202201020512  [17.0, 13.5, 36.5]        68.6           225.2         1081.1   \n",
       "\n",
       "                                   wide_comb  \n",
       "202204030501    [[8, 15], [12, 15], [8, 12]]  \n",
       "202204030502      [[5, 15], [1, 15], [1, 5]]  \n",
       "202204030503      [[7, 9], [7, 14], [9, 14]]  \n",
       "202204030504    [[10, 13], [9, 10], [9, 13]]  \n",
       "202204030505      [[2, 10], [7, 10], [2, 7]]  \n",
       "202204030506      [[2, 6], [2, 11], [6, 11]]  \n",
       "202204030507    [[12, 16], [4, 12], [4, 16]]  \n",
       "202204030508    [[9, 13], [9, 12], [12, 13]]  \n",
       "202204030509      [[8, 13], [6, 8], [6, 13]]  \n",
       "202204030510    [[11, 13], [5, 13], [5, 11]]  \n",
       "202204030511    [[6, 14], [6, 12], [12, 14]]  \n",
       "202204030512        [[4, 5], [2, 4], [2, 5]]  \n",
       "202210040501        [[2, 7], [1, 7], [1, 2]]  \n",
       "202210040502      [[4, 14], [3, 4], [3, 14]]  \n",
       "202210040503  [[12, 15], [14, 15], [12, 14]]  \n",
       "202210040504        [[5, 7], [1, 5], [1, 7]]  \n",
       "202210040505        [[2, 9], [2, 3], [3, 9]]  \n",
       "202210040506      [[4, 5], [4, 11], [5, 11]]  \n",
       "202210040507        [[2, 7], [1, 7], [1, 2]]  \n",
       "202210040508        [[1, 9], [8, 9], [1, 8]]  \n",
       "202210040509    [[3, 16], [10, 16], [3, 10]]  \n",
       "202210040510        [[2, 8], [6, 8], [2, 6]]  \n",
       "202210040511    [[13, 14], [1, 14], [1, 13]]  \n",
       "202210040512        [[1, 2], [2, 8], [1, 8]]  \n",
       "202201020501        [[3, 5], [2, 5], [2, 3]]  \n",
       "202201020502        [[4, 7], [7, 8], [4, 8]]  \n",
       "202201020503      [[7, 10], [7, 8], [8, 10]]  \n",
       "202201020504        [[6, 8], [1, 6], [1, 8]]  \n",
       "202201020505        [[3, 6], [5, 6], [3, 5]]  \n",
       "202201020506    [[7, 11], [7, 10], [10, 11]]  \n",
       "202201020507    [[4, 10], [4, 13], [10, 13]]  \n",
       "202201020508      [[9, 12], [7, 9], [7, 12]]  \n",
       "202201020509        [[2, 4], [2, 8], [4, 8]]  \n",
       "202201020510  [[11, 12], [12, 13], [11, 13]]  \n",
       "202201020511      [[8, 13], [9, 13], [8, 9]]  \n",
       "202201020512      [[5, 13], [5, 9], [9, 13]]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b97e7-5e69-4334-a268-c7a57eaa10d8",
   "metadata": {},
   "source": [
    "# 日付に注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e00c431-6a37-4f54-bfd3-7a1cc01780cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2022/12/31'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ec390-bc7f-4821-8417-76382d034041",
   "metadata": {},
   "source": [
    "# Results scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "131add0a-4ac5-4133-b242-3fa2109a4762",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa6e00bd01f47d69ea0abffc9bad6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# race_id_list = results.index.astype('str')\n",
    "\n",
    "results_tmp = Results.scrape(race_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ac189-894a-48ac-adb2-4e731640bc5c",
   "metadata": {},
   "source": [
    "# Horse_results scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fb495b3-1044-4b5a-afdc-cdf1b60aa6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed1feb75d5e4e47b85b8b8afc57eee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "horse_id_list = results_tmp['horse_id'].astype(str).unique()\n",
    "horse_results_tmp = HorseResults.scrape(horse_id_list)\n",
    "\n",
    "# save_path = '/Users/rince/Desktop/Horse/Data/horse_2020.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1569216-aa8f-40a3-8303-5d54a442b00e",
   "metadata": {},
   "source": [
    "# Peds scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56d56e6b-7a60-4721-a111-892aafa204d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cc57fbe15b450dae9bd6a9f34a9eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0646fb23cf4c06b67ce5668bcecadc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peds_2021 = Peds.scrape(horse_id_list)\n",
    "pe_2021 = Peds(peds_2021)\n",
    "pe_2021.regularize_peds()\n",
    "peds_tmp = pe_2021.peds_re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1db0da-3505-4825-8408-e7dd58205c96",
   "metadata": {},
   "source": [
    "# Return scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56a4d97d-94cc-477f-b643-5144c7173613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e61be692b04a7cb55e7ad2997d87ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "returns_tmp = Return.scrape(race_id_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e175b9a-1a2d-4d5d-a5e2-e771c86dd8d2",
   "metadata": {},
   "source": [
    "# update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "428fa2b8-2058-4c1d-af05-ec10e9f3768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = update_data(load_csv(path_win+'results.csv'),results_tmp)\n",
    "new_horse_results = update_data(load_csv(path_win+'horse_results.csv'),horse_results_tmp)\n",
    "new_peds = update_data(load_csv(path_win+'peds.csv'),peds_tmp)\n",
    "returns = load_csv(path_win+'return.csv')\n",
    "returns.rename(columns={'0':0,'1':1,'2':2,'3':3},inplace=True)\n",
    "returns_tmp.rename(columns={'0':0,'1':1,'2':2,'3':3},inplace=True)\n",
    "new_return = update_data(returns,returns_tmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77364dd-545a-43d4-97aa-070ca0595356",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "875dc8e7-f696-4b78-933d-4f62f3603430",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results.to_csv(path_win+'results.csv')\n",
    "new_horse_results.to_csv(path_win+'horse_results.csv')\n",
    "new_peds.to_csv(path_win+'peds.csv')\n",
    "new_return.to_csv(path_win+'return.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb0ca11-eae4-4d5e-b833-3184f6e85f85",
   "metadata": {},
   "source": [
    "# 重要度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f0ed3-8651-4105-aa14-83bfa45b20c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importances = pd.DataFrame(\n",
    "{'features' : x_train.columns, 'importances' : lgb_rank.feature_importance()})\n",
    "print(importances.sort_values('importances', ascending=False)[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc1142-ff9b-4568-80b8-18ef0d9010c1",
   "metadata": {},
   "source": [
    "# fastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea29d7bf-5052-44dc-ac80-dea59ed65444",
   "metadata": {},
   "source": [
    "流れ\n",
    "1. fasttext用の血統データの学習データを作る (血統の情報のみ, index ヘッダはいらない)\n",
    "2. fasttext学習\n",
    "3. 学習モデルを使って, 血統データをベクトル化\n",
    "4. ベクトル化して r.data_cに concat\n",
    "5. 学習\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d375b9-e292-4d4a-97c2-905e3060419f",
   "metadata": {},
   "source": [
    "教師あり, 教師なしでも生成されるベクトルは等しい"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de5229f-9b05-4bc1-820a-0e275a1d6c8f",
   "metadata": {},
   "source": [
    "# model_ft 作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f0c62-72c2-4a2e-b45e-b0b4d37c2e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 相対パスしかできない\n",
    "# dim : 出力の次元\n",
    "# minn : n_gramの最小単位\n",
    "# maxn : n_gramの最大単位\n",
    "path_ft = '/Users/rince/Desktop/Horse/code/horse/peds_ft.txt'\n",
    "# 上書き保存OK\n",
    "peds.to_csv(path_ft,header=False,index=False,sep=',')\n",
    "model_ft = ft.train_unsupervised(path_ft,dim=62,minn=2,maxn=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd9030-310c-414d-8c91-6178159c00e6",
   "metadata": {},
   "source": [
    "model[model.words[1]] と model.get_input_vector(ind=1) は等価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b23af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_ = [1,2,3,4,True,4]\n",
    "lis2_ = [2,3,4,5,False,5]\n",
    "dic_ = {\n",
    "}\n",
    "dic_['a'] = lis_\n",
    "dic_['b'] = lis2_\n",
    "\n",
    "df_ = pd.DataFrame(dic_).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f9f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0cc9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.rename(columns={0:'profit',1:'is_atari',2:'is_buy',3:'actual_rank',4:'not_buy_reason',5:'is_error'})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6ca01a9d29b8f49b2398e47ff0a4f0d82a4b97eff954d8fa800ff949016a671"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
